{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f28cb98721bd49299b614b45698d8e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_909ad1f202af4131bbe704acf6cd1283",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0195aa0fbd844ea2b61cfed9a62364b8",
              "IPY_MODEL_b06988ed4ac34846aab02925b5132e74",
              "IPY_MODEL_3761e831ee7442c4a277d5e145505e3d"
            ]
          }
        },
        "909ad1f202af4131bbe704acf6cd1283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0195aa0fbd844ea2b61cfed9a62364b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9117d85fd7e24cc29d1c951e60d8e02a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_423a1ea338064bd0a084c44a3ee2903c"
          }
        },
        "b06988ed4ac34846aab02925b5132e74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1325f5f4873c4b2e86a11e8d1b1109ff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9940f2b2c4947ac9671b45c78a68f1d"
          }
        },
        "3761e831ee7442c4a277d5e145505e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d55e60deac1241a7922a85d38eb25e4a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 11.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0189f447a4ea4f32a977a7b06936b5bc"
          }
        },
        "9117d85fd7e24cc29d1c951e60d8e02a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "423a1ea338064bd0a084c44a3ee2903c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1325f5f4873c4b2e86a11e8d1b1109ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9940f2b2c4947ac9671b45c78a68f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d55e60deac1241a7922a85d38eb25e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0189f447a4ea4f32a977a7b06936b5bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e87d0c1316be4dbaa32f9afc715dc5aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_22e2c46bf70c44fcb4eaa89b46f6dfaf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0c7a53d5ad5743768d6935b7e020735f",
              "IPY_MODEL_b462e4e1f1124b59a985bae5e5921db3",
              "IPY_MODEL_58ebafdb17954a42bed032a758f76228"
            ]
          }
        },
        "22e2c46bf70c44fcb4eaa89b46f6dfaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c7a53d5ad5743768d6935b7e020735f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_45b1e27dbe8d4cea8d571403dcd21726",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d2f92276f964dbb9dbef4fb70ad5b5d"
          }
        },
        "b462e4e1f1124b59a985bae5e5921db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d2e9fad34f9b4d0cbdc3f00f88e1d3e8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40ef4044c88b465fb97e66aac54f92df"
          }
        },
        "58ebafdb17954a42bed032a758f76228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c74e2d0f0055473990f8413a52bfa93d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 45.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6db7b81db82941f1a8d0998f7b106a01"
          }
        },
        "45b1e27dbe8d4cea8d571403dcd21726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d2f92276f964dbb9dbef4fb70ad5b5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2e9fad34f9b4d0cbdc3f00f88e1d3e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40ef4044c88b465fb97e66aac54f92df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c74e2d0f0055473990f8413a52bfa93d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6db7b81db82941f1a8d0998f7b106a01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b28d0d8fae7407e90326b4272bf29da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1750f09e359a46fa934abdc2bfd7f504",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a25918ad194948149f54ff850e6dae32",
              "IPY_MODEL_0b9257b9a2614fdcb5ea2f95d258af53",
              "IPY_MODEL_9dbac74cbad14d908b1c60e2fd745d5d"
            ]
          }
        },
        "1750f09e359a46fa934abdc2bfd7f504": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a25918ad194948149f54ff850e6dae32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bf1682e4b13744a8bb1b40df2b9c0b61",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff000ca229ff4466892ffd7af9887328"
          }
        },
        "0b9257b9a2614fdcb5ea2f95d258af53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dc05294954344dbeaa12ec4027492d1a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6161b7eb03b346279226f7cd3328ea1e"
          }
        },
        "9dbac74cbad14d908b1c60e2fd745d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2c98d46ec72b4096baaff42dbfcf9acc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 591kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_91dc95fd89cc45c0a419b6f1ae86c6b6"
          }
        },
        "bf1682e4b13744a8bb1b40df2b9c0b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff000ca229ff4466892ffd7af9887328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc05294954344dbeaa12ec4027492d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6161b7eb03b346279226f7cd3328ea1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c98d46ec72b4096baaff42dbfcf9acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "91dc95fd89cc45c0a419b6f1ae86c6b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFOTiqrtNvyy"
      },
      "source": [
        "# Install Transformers Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hkhc10wNrGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3afcf072-156e-4103-93e7-a869c079e4c5"
      },
      "source": [
        "!pip install transformers==3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==3\n",
            "  Downloading transformers-3.0.0-py3-none-any.whl (754 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 23.0 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 419 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 430 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 440 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 450 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 460 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 471 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 481 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 491 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 501 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 512 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 522 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 532 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 542 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 552 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 563 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 573 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 583 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 593 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 604 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 614 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 624 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 634 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 645 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 655 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 665 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 675 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 686 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 696 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 706 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 716 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 727 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 737 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 747 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 754 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "  Downloading tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 29.2 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 34.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 31.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.62.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.96 tokenizers-0.8.0rc4 transformers-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4giRzM7NtHJ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKd-Tj3hOMsZ"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDHFbFuJ31XK"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwJrQFQgN_BE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "334b6649-3061-4e6b-9183-a8ce747fa0f9"
      },
      "source": [
        "df = pd.read_csv(\"/content/train_new_descriptorname.csv\")\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Clostridium difficile Diarrhea,microbiology En...</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abnormalities, Drug-Induced Pregnancy Complica...</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Emigration and Immigration Tuberculin Test Tub...</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fibromyalgia,therapy</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Anxiety,physiopathology Raynaud Disease,physio...</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text label\n",
              "0  Clostridium difficile Diarrhea,microbiology En...     C\n",
              "1  Abnormalities, Drug-Induced Pregnancy Complica...     B\n",
              "2  Emigration and Immigration Tuberculin Test Tub...     B\n",
              "3                              Fibromyalgia,therapy      A\n",
              "4  Anxiety,physiopathology Raynaud Disease,physio...     C"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUWsPh9o33KG"
      },
      "source": [
        "\n",
        "df_=df.copy()\n",
        "df_['label'] =df_['label'].replace(8,0)\n",
        "df['label'] = df_['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzPPOrVQWiW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bbfbf95-187a-45c6-8d86-65b722fe7d62"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(781, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbKfdNe5WIl7",
        "outputId": "1c38e085-3f42-41de-b74c-fffc39cb5d3e"
      },
      "source": [
        "df = df[:391]\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(391, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "676DPU1BOPdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f86c58-4f30-4f51-c843-588805d4a385"
      },
      "source": [
        "# check class distribution\n",
        "df['label'].value_counts(normalize = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6    0.263427\n",
              "7    0.248082\n",
              "5    0.225064\n",
              "3    0.084399\n",
              "0    0.076726\n",
              "4    0.040921\n",
              "2    0.033248\n",
              "1    0.028133\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKfWnApvOoE7"
      },
      "source": [
        "# Split train dataset into train, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfhSPF5jOWb7"
      },
      "source": [
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'],\n",
        "                                                                    random_state=2018,\n",
        "                                                                    test_size=0.3,\n",
        "                                                                    stratify=df['label'])\n",
        "\n",
        "# we will use temp_text and temp_labels to create validation and test set\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
        "                                                                random_state=2018,\n",
        "                                                                test_size=0.5,\n",
        "                                                                stratify=temp_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7hsdLoCO7uB"
      },
      "source": [
        "# Import BERT Model and BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1kY3gZjO2RE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "f28cb98721bd49299b614b45698d8e3f",
            "909ad1f202af4131bbe704acf6cd1283",
            "0195aa0fbd844ea2b61cfed9a62364b8",
            "b06988ed4ac34846aab02925b5132e74",
            "3761e831ee7442c4a277d5e145505e3d",
            "9117d85fd7e24cc29d1c951e60d8e02a",
            "423a1ea338064bd0a084c44a3ee2903c",
            "1325f5f4873c4b2e86a11e8d1b1109ff",
            "d9940f2b2c4947ac9671b45c78a68f1d",
            "d55e60deac1241a7922a85d38eb25e4a",
            "0189f447a4ea4f32a977a7b06936b5bc",
            "e87d0c1316be4dbaa32f9afc715dc5aa",
            "22e2c46bf70c44fcb4eaa89b46f6dfaf",
            "0c7a53d5ad5743768d6935b7e020735f",
            "b462e4e1f1124b59a985bae5e5921db3",
            "58ebafdb17954a42bed032a758f76228",
            "45b1e27dbe8d4cea8d571403dcd21726",
            "6d2f92276f964dbb9dbef4fb70ad5b5d",
            "d2e9fad34f9b4d0cbdc3f00f88e1d3e8",
            "40ef4044c88b465fb97e66aac54f92df",
            "c74e2d0f0055473990f8413a52bfa93d",
            "6db7b81db82941f1a8d0998f7b106a01",
            "4b28d0d8fae7407e90326b4272bf29da",
            "1750f09e359a46fa934abdc2bfd7f504",
            "a25918ad194948149f54ff850e6dae32",
            "0b9257b9a2614fdcb5ea2f95d258af53",
            "9dbac74cbad14d908b1c60e2fd745d5d",
            "bf1682e4b13744a8bb1b40df2b9c0b61",
            "ff000ca229ff4466892ffd7af9887328",
            "dc05294954344dbeaa12ec4027492d1a",
            "6161b7eb03b346279226f7cd3328ea1e",
            "2c98d46ec72b4096baaff42dbfcf9acc",
            "91dc95fd89cc45c0a419b6f1ae86c6b6"
          ]
        },
        "outputId": "ac037ad3-aad4-4429-b19a-0d1d43b4400b"
      },
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f28cb98721bd49299b614b45698d8e3f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e87d0c1316be4dbaa32f9afc715dc5aa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b28d0d8fae7407e90326b4272bf29da",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zOKeOMeO-DT"
      },
      "source": [
        "# sample data\n",
        "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
        "\n",
        "# encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAH73n39PHLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3862ee3-a8c4-48a4-8510-42f1f8f21e1a"
      },
      "source": [
        "# output\n",
        "print(sent_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wIYaWI_Prg8"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKwbpeN_PMiu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "de54aee1-f2a5-4aaf-af98-24198060da61"
      },
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-768d0d74d590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get length of all the messages in the train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_text' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXcswEIRPvGe"
      },
      "source": [
        "max_seq_len = 40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk5S7DWaP2t6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "d452b98a-703b-40d8-90bc-e2bc37ed0ce5"
      },
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d42d72a742f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# tokenize and encode sequences in the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m tokens_train = tokenizer.batch_encode_plus(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpad_to_max_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsm8bkRZQTw9"
      },
      "source": [
        "# Convert Integer Sequences to Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR-lXwmzQPd6"
      },
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov1cOBlcRLuk"
      },
      "source": [
        "# Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUy9JKFYQYLp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dece2da9-38ba-43aa-ebcd-332a0c6824ac"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
        "\n",
        "print(\"create DataLoaders\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "create DataLoaders\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2HZc5ZYRV28"
      },
      "source": [
        "# Freeze BERT Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHZ0MC00RQA_"
      },
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7ahGBUWRi3X"
      },
      "source": [
        "# Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3iEtGyYRd0A"
      },
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "\n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert\n",
        "\n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "\n",
        "      # dense layer 8 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,8)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model\n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
        "\n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "\n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBAJJVuJRliv"
      },
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taXS0IilRn9J"
      },
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CDpoMQR_rK"
      },
      "source": [
        "# Find Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izY5xH5eR7Ur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "487b4a08-642b-4c0d-bea0-55f48033686c"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
        "\n",
        "print(class_wts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.625      4.265625   3.79166667 1.48369565 3.10227273 0.55942623\n",
            " 0.47395833 0.50183824]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1WvfY2vSGKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78914967-c6ed-42c5-e669-424434c32d41"
      },
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "print(weights)\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights)\n",
        "\n",
        "# number of training epochs\n",
        "epochs = 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.6250, 4.2656, 3.7917, 1.4837, 3.1023, 0.5594, 0.4740, 0.5018],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik8Oc7doqPrC"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My4CA0qaShLq"
      },
      "source": [
        "# Fine-Tune BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rskLk8R_SahS"
      },
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "\n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "\n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients\n",
        "    model.zero_grad()\n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "    print(preds)\n",
        "    print(labels)\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGXovFDlSxB5"
      },
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "\n",
        "  print(\"\\nEvaluating...\")\n",
        "\n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "\n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "\n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "\n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "\n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "      print(loss)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader)\n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KZEgxRRTLXG"
      },
      "source": [
        "# Start Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1USGTntS3TS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0e063d2-24ac-49f7-9ca3-7576c3235b4c"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "\n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "\n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "\n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "tensor([[-2.1384, -2.1475, -2.0496, -2.2044, -1.9495, -1.9547, -1.8687, -2.4304],\n",
            "        [-2.1272, -2.1307, -2.1464, -2.2591, -1.9292, -1.9686, -1.7978, -2.4063],\n",
            "        [-2.1769, -2.1874, -2.0253, -2.1587, -1.9740, -2.0117, -1.8726, -2.2969],\n",
            "        [-2.0961, -2.0737, -2.1624, -2.2536, -1.9807, -1.9493, -1.9072, -2.2787],\n",
            "        [-2.0746, -2.2262, -2.0676, -2.2514, -2.0036, -2.0419, -1.9426, -2.0654],\n",
            "        [-2.0556, -2.0554, -2.1774, -2.3211, -1.9623, -2.0021, -1.9262, -2.1967],\n",
            "        [-2.0149, -2.0156, -2.2513, -2.2188, -1.9503, -2.0774, -1.8715, -2.3222],\n",
            "        [-2.1747, -2.1401, -2.1345, -2.1838, -1.8760, -1.9926, -1.8794, -2.3477],\n",
            "        [-2.1150, -2.1654, -2.1064, -2.2169, -1.9362, -2.0728, -1.8853, -2.1877],\n",
            "        [-2.1354, -2.0921, -2.1524, -2.2686, -1.9251, -1.9908, -1.8285, -2.3477],\n",
            "        [-2.1626, -2.1461, -2.1019, -2.2128, -1.9738, -1.9587, -1.9512, -2.1686],\n",
            "        [-2.2423, -2.0492, -2.1364, -2.2687, -1.9048, -2.0185, -1.8119, -2.3191],\n",
            "        [-2.1343, -2.1565, -2.0557, -2.1932, -1.9497, -1.9988, -1.8646, -2.3687],\n",
            "        [-2.1044, -2.0780, -2.1502, -2.2213, -1.9185, -2.0642, -1.8972, -2.2612],\n",
            "        [-2.2200, -2.1875, -2.0158, -2.1715, -1.9734, -1.9940, -1.8979, -2.2354],\n",
            "        [-2.0850, -2.0710, -2.1723, -2.1658, -1.8381, -2.0024, -2.0070, -2.3803],\n",
            "        [-2.1911, -2.1468, -2.1491, -2.2072, -1.8576, -2.0028, -1.8354, -2.3622],\n",
            "        [-2.0826, -2.1806, -2.0614, -2.1887, -1.9317, -2.0150, -1.9630, -2.2592],\n",
            "        [-2.0752, -2.2216, -2.1038, -2.2392, -1.8851, -2.0060, -1.9622, -2.2018],\n",
            "        [-2.0965, -2.2077, -2.1517, -2.1516, -1.9891, -2.0344, -1.8903, -2.1545],\n",
            "        [-2.1388, -2.1474, -2.1132, -2.1977, -1.9127, -1.9564, -1.9351, -2.3021],\n",
            "        [-2.1061, -2.1765, -2.0750, -2.2411, -1.9047, -2.0274, -1.9578, -2.1960],\n",
            "        [-2.1322, -2.1257, -2.0987, -2.1161, -1.9438, -2.0281, -1.9114, -2.3399],\n",
            "        [-2.0075, -2.1004, -2.2890, -2.1959, -1.9114, -2.0460, -1.7647, -2.4977],\n",
            "        [-2.1389, -2.1316, -2.0891, -2.2084, -1.9599, -1.9998, -1.9613, -2.1805],\n",
            "        [-2.1603, -2.1093, -2.1795, -2.1579, -1.9091, -2.0050, -1.9089, -2.2670],\n",
            "        [-2.1846, -2.0988, -2.0864, -2.2837, -1.8720, -1.9952, -1.9061, -2.2987],\n",
            "        [-2.1107, -2.2901, -2.0605, -2.3195, -1.9432, -2.0334, -1.8665, -2.0950],\n",
            "        [-2.1284, -2.1477, -2.0823, -2.1832, -1.8993, -2.0476, -1.8942, -2.3255],\n",
            "        [-2.2262, -2.1062, -2.0723, -2.1341, -2.0164, -2.0505, -1.7697, -2.3652],\n",
            "        [-2.2153, -2.2103, -2.0839, -2.0340, -1.9620, -2.0615, -1.8175, -2.3468],\n",
            "        [-2.1118, -2.1228, -2.0766, -2.2329, -1.9308, -2.0058, -1.9190, -2.2989]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 6, 4, 0, 3, 5, 6, 5, 3, 3, 5, 0, 5, 7, 5, 7, 6, 2, 7, 1, 7, 5, 4, 2,\n",
            "        7, 5, 6, 6, 7, 3, 4, 6], device='cuda:0')\n",
            "tensor([[-2.5343, -2.3248, -1.6116, -2.0689, -1.2717, -2.5999, -2.5161, -2.7873],\n",
            "        [-2.5551, -2.3610, -1.7608, -1.9850, -1.1772, -2.7227, -2.4522, -2.8342],\n",
            "        [-2.6249, -2.1113, -1.8454, -1.9078, -1.6400, -2.1200, -2.2829, -2.4755],\n",
            "        [-2.6754, -2.3417, -1.6089, -2.1330, -1.1271, -2.8609, -2.5432, -2.8722],\n",
            "        [-2.6179, -2.3533, -1.7097, -1.9705, -1.2293, -2.6586, -2.4259, -2.8012],\n",
            "        [-2.5646, -2.1841, -1.6877, -1.9700, -1.3721, -2.4653, -2.4740, -2.7606],\n",
            "        [-2.6309, -2.4255, -1.6134, -1.9599, -1.1558, -2.8676, -2.5287, -3.0351],\n",
            "        [-2.4414, -2.1806, -1.8302, -1.9067, -1.7403, -2.0952, -2.3216, -2.3600],\n",
            "        [-2.5858, -2.2269, -1.6458, -2.0694, -1.3161, -2.5556, -2.4238, -2.7603],\n",
            "        [-2.4253, -2.1433, -1.7791, -1.9342, -1.7502, -2.1769, -2.1609, -2.5434],\n",
            "        [-2.5129, -2.5452, -1.7383, -2.0962, -1.0393, -2.8695, -2.5610, -2.9165],\n",
            "        [-2.5491, -2.3129, -1.7887, -1.9590, -1.2221, -2.5634, -2.4652, -2.8468],\n",
            "        [-2.5616, -2.3496, -1.7403, -1.9892, -1.1939, -2.6701, -2.4240, -2.9133],\n",
            "        [-2.4944, -2.3080, -1.7314, -1.9944, -1.3199, -2.4347, -2.4306, -2.7792],\n",
            "        [-2.2769, -2.1426, -2.2576, -2.0232, -1.9784, -1.9276, -1.8336, -2.3069],\n",
            "        [-2.8052, -2.3557, -1.6701, -2.0526, -1.0740, -3.0297, -2.4001, -3.0499],\n",
            "        [-2.5516, -2.4590, -1.7153, -2.0627, -1.2177, -2.5428, -2.4006, -2.7446],\n",
            "        [-2.6821, -2.3006, -1.5882, -2.1133, -1.2103, -2.7412, -2.4625, -2.8396],\n",
            "        [-2.4795, -2.3239, -1.6682, -1.9491, -1.2986, -2.6291, -2.4276, -2.9180],\n",
            "        [-2.5496, -2.1460, -1.7225, -2.0185, -1.4003, -2.4245, -2.3890, -2.7073],\n",
            "        [-2.4897, -2.0992, -1.7206, -1.9493, -1.6894, -2.1753, -2.4252, -2.4473],\n",
            "        [-2.5530, -2.2379, -1.8233, -1.9900, -1.2978, -2.4912, -2.3750, -2.6837],\n",
            "        [-2.6306, -2.3965, -1.6635, -1.9809, -1.2031, -2.6111, -2.5109, -2.9078],\n",
            "        [-2.3475, -2.0834, -1.9590, -1.8655, -1.9155, -2.0859, -2.1256, -2.3726],\n",
            "        [-2.4089, -2.1287, -1.8677, -2.0204, -1.5434, -2.2946, -2.2217, -2.5116],\n",
            "        [-2.4262, -2.2437, -1.7832, -2.0982, -1.3546, -2.4152, -2.3675, -2.6080],\n",
            "        [-2.3406, -2.2283, -1.7734, -2.0448, -1.5727, -2.2907, -2.2735, -2.4624],\n",
            "        [-2.6068, -2.3768, -1.5962, -2.0751, -1.1699, -2.8340, -2.4587, -2.9864],\n",
            "        [-2.5904, -2.2489, -1.7360, -2.0236, -1.2576, -2.5917, -2.4749, -2.6926],\n",
            "        [-2.4939, -2.3489, -1.7473, -1.9742, -1.3761, -2.3563, -2.4100, -2.6356],\n",
            "        [-2.7337, -2.4601, -1.6143, -2.0413, -1.0696, -2.8659, -2.5541, -3.1502],\n",
            "        [-2.5525, -2.0829, -1.8299, -1.9515, -1.5802, -2.1822, -2.3686, -2.4923]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 2, 3, 2, 4, 6, 5, 2, 3, 3, 5, 5, 7, 7, 6, 5, 5, 0, 7, 0, 4, 6, 3, 5,\n",
            "        3, 0, 5, 6, 7, 7, 7, 5], device='cuda:0')\n",
            "tensor([[-2.5605, -2.8720, -1.1737, -2.0029, -1.5365, -2.5545, -2.7255, -2.7551],\n",
            "        [-2.5884, -3.2218, -1.0826, -1.9691, -1.3981, -2.9216, -2.8958, -2.9854],\n",
            "        [-2.6517, -3.2382, -1.0296, -2.0004, -1.4400, -2.8819, -2.9114, -2.9865],\n",
            "        [-2.5572, -2.5667, -1.4490, -1.7123, -1.6201, -2.2996, -2.6797, -2.7545],\n",
            "        [-2.4592, -2.2691, -1.7823, -1.6333, -1.9820, -2.0780, -2.2380, -2.5523],\n",
            "        [-2.6465, -3.0028, -1.1749, -1.7881, -1.5116, -2.6765, -2.9110, -2.8210],\n",
            "        [-2.7483, -3.2777, -1.0108, -1.9516, -1.5461, -2.6716, -2.8851, -2.9150],\n",
            "        [-2.3138, -2.1766, -2.5127, -2.0179, -2.5283, -1.8485, -1.4231, -2.3491],\n",
            "        [-2.7835, -3.0610, -0.9351, -2.0709, -1.6054, -2.8295, -2.8208, -2.9317],\n",
            "        [-2.4594, -2.5807, -1.4797, -1.6600, -1.7384, -2.2622, -2.5843, -2.7243],\n",
            "        [-2.6213, -3.0252, -1.0618, -1.9961, -1.4967, -2.7836, -2.7444, -3.0561],\n",
            "        [-2.4957, -2.7656, -1.2312, -1.9501, -1.5597, -2.5818, -2.7253, -2.6729],\n",
            "        [-2.5494, -2.7052, -1.1429, -1.7710, -1.7022, -2.5444, -2.8505, -3.0508],\n",
            "        [-2.4830, -2.4913, -1.5554, -1.6259, -1.8096, -2.1557, -2.5541, -2.6798],\n",
            "        [-2.5453, -2.7331, -1.2526, -1.7344, -1.7258, -2.3572, -2.7604, -2.8422],\n",
            "        [-2.4391, -2.6613, -1.4463, -1.8402, -1.6268, -2.3709, -2.4788, -2.5917],\n",
            "        [-2.3884, -2.7913, -1.3230, -1.8560, -1.6313, -2.3981, -2.7652, -2.5940],\n",
            "        [-2.8412, -3.2090, -0.8928, -1.9946, -1.6098, -2.9140, -2.9290, -3.0360],\n",
            "        [-2.7227, -2.7757, -1.1853, -1.8078, -1.6768, -2.5171, -2.7442, -2.6539],\n",
            "        [-2.8501, -3.2611, -0.9633, -1.9135, -1.5420, -2.7533, -2.9704, -3.0867],\n",
            "        [-2.6910, -3.2775, -0.9850, -2.0875, -1.4689, -2.8558, -2.9223, -2.8910],\n",
            "        [-2.6038, -2.8706, -1.2384, -1.6746, -1.6661, -2.4417, -2.8608, -2.8320],\n",
            "        [-2.8474, -3.2238, -1.0437, -2.0807, -1.3572, -2.8678, -2.8736, -2.9090],\n",
            "        [-2.4652, -2.7294, -1.2646, -1.8624, -1.5699, -2.6252, -2.6891, -2.7543],\n",
            "        [-2.5397, -2.8105, -1.3241, -1.7706, -1.6726, -2.3330, -2.7005, -2.6210],\n",
            "        [-2.7479, -3.3798, -1.0236, -1.9853, -1.3577, -2.9274, -2.9760, -3.1358],\n",
            "        [-2.8883, -3.3953, -0.8969, -1.9930, -1.4709, -3.1081, -3.0397, -3.1135],\n",
            "        [-2.6506, -3.2878, -1.0197, -2.0174, -1.3814, -3.1087, -3.0117, -2.9324],\n",
            "        [-2.6921, -2.8161, -1.1105, -1.8159, -1.6930, -2.5438, -2.7900, -2.8758],\n",
            "        [-2.5069, -2.3530, -1.5835, -1.6584, -1.8793, -2.1352, -2.4685, -2.6302],\n",
            "        [-2.7308, -3.1434, -1.0620, -1.8581, -1.5676, -2.6502, -2.8648, -2.9225],\n",
            "        [-2.6075, -2.9643, -1.0012, -2.1434, -1.5223, -2.8405, -2.8206, -2.9221]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 7, 7, 1, 5, 6, 0, 6, 7, 5, 5, 5, 7, 5, 0, 7, 6, 7, 5, 7, 0, 5, 2, 5,\n",
            "        7, 7, 6, 5, 7, 1, 6, 5], device='cuda:0')\n",
            "tensor([[-2.4100, -2.6080, -1.1858, -1.8154, -2.1117, -2.1745, -2.9184, -2.5321],\n",
            "        [-2.2425, -2.7573, -1.1996, -1.8612, -2.0106, -2.2396, -2.8778, -2.5656],\n",
            "        [-2.3601, -2.2651, -1.6153, -1.6800, -2.0262, -2.0649, -2.5377, -2.5402],\n",
            "        [-2.4086, -3.3424, -0.8573, -2.2830, -1.9769, -2.3622, -3.2126, -2.5844],\n",
            "        [-2.1811, -3.0952, -1.1438, -2.1027, -1.8802, -2.5092, -2.7142, -2.2931],\n",
            "        [-2.4501, -2.0811, -1.9476, -1.6782, -2.0986, -1.8964, -2.1434, -2.6652],\n",
            "        [-2.3156, -3.0691, -1.1657, -2.0868, -1.7610, -2.3250, -2.7867, -2.4333],\n",
            "        [-2.3577, -3.1863, -1.0307, -2.1157, -1.7660, -2.4364, -3.0319, -2.5256],\n",
            "        [-2.3405, -2.8952, -1.1357, -2.0319, -1.8301, -2.4527, -2.7976, -2.4220],\n",
            "        [-2.3047, -3.3500, -0.9840, -2.0363, -1.8930, -2.3829, -3.0957, -2.6221],\n",
            "        [-2.3563, -3.3663, -0.8759, -2.2546, -1.8620, -2.5452, -3.2292, -2.5783],\n",
            "        [-2.2258, -3.3634, -0.9436, -2.2818, -1.8160, -2.5916, -2.9891, -2.5488],\n",
            "        [-2.2459, -2.7188, -1.3821, -1.8539, -1.9983, -2.0952, -2.6505, -2.3934],\n",
            "        [-2.3914, -3.0779, -0.9295, -2.0848, -2.0752, -2.4151, -3.0450, -2.5146],\n",
            "        [-2.4142, -2.6842, -1.0338, -1.9295, -2.0919, -2.2943, -3.0047, -2.6945],\n",
            "        [-2.2647, -3.3643, -0.9354, -2.1949, -1.8607, -2.5817, -3.1281, -2.4922],\n",
            "        [-2.2757, -3.3158, -0.9251, -2.4075, -1.7264, -2.5690, -3.0302, -2.6369],\n",
            "        [-2.4518, -2.6407, -1.3150, -1.6673, -1.9526, -2.2415, -2.7053, -2.6555],\n",
            "        [-2.3881, -2.7231, -1.0289, -1.8962, -2.1735, -2.3138, -2.9361, -2.6701],\n",
            "        [-2.4568, -3.1091, -0.9047, -2.1935, -1.9991, -2.4241, -2.9626, -2.5540],\n",
            "        [-2.4385, -3.4651, -0.8734, -2.1098, -1.9677, -2.5730, -3.0026, -2.5654],\n",
            "        [-2.2702, -2.9644, -1.1555, -2.0261, -1.8504, -2.4268, -2.7993, -2.3860],\n",
            "        [-2.3636, -3.4757, -0.9564, -2.1724, -1.8075, -2.5787, -2.8791, -2.5170],\n",
            "        [-2.3814, -2.8653, -1.0381, -2.0039, -1.9630, -2.3978, -2.9621, -2.5431],\n",
            "        [-2.3684, -2.9830, -1.1883, -1.8805, -1.8356, -2.3099, -2.8604, -2.4957],\n",
            "        [-2.4028, -3.1000, -0.9516, -2.1350, -1.9320, -2.5918, -2.8702, -2.4806],\n",
            "        [-2.1039, -3.2766, -0.7970, -2.6653, -1.8112, -2.9031, -3.2225, -2.7831],\n",
            "        [-2.4680, -2.4198, -1.1681, -1.9165, -2.0142, -2.1901, -2.8970, -2.6925],\n",
            "        [-2.5815, -3.2634, -0.8233, -2.1681, -1.9796, -2.6649, -3.0155, -2.5777],\n",
            "        [-2.3309, -3.1612, -0.9023, -2.2880, -1.8406, -2.6671, -3.0921, -2.5291],\n",
            "        [-2.2422, -2.7087, -1.1994, -1.9006, -2.0697, -2.1912, -2.9214, -2.4717],\n",
            "        [-2.2522, -2.5198, -1.4937, -1.6454, -2.0670, -2.0091, -2.7946, -2.5892]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 5, 0, 5, 5, 4, 6, 6, 1, 6, 7, 5, 0, 0, 6, 6, 4, 6, 7, 5, 5, 6, 7, 5,\n",
            "        6, 6, 7, 6, 7, 4, 7, 5], device='cuda:0')\n",
            "tensor([[-1.9466, -2.9853, -1.3430, -2.4931, -1.9630, -2.1301, -2.8547, -1.9231],\n",
            "        [-2.0597, -3.3236, -1.1590, -2.3254, -1.9893, -2.1999, -2.8986, -2.1017],\n",
            "        [-2.0206, -2.9164, -1.1794, -2.4125, -2.0036, -2.2194, -2.8221, -2.1783],\n",
            "        [-1.9382, -2.9567, -1.3982, -2.1727, -1.9348, -2.0932, -2.7600, -2.1883],\n",
            "        [-2.0667, -2.6516, -1.4103, -1.9531, -2.0801, -1.9877, -2.8364, -2.3392],\n",
            "        [-1.9543, -3.1098, -1.3479, -2.3317, -1.8378, -2.2515, -3.0013, -1.9471],\n",
            "        [-2.1805, -2.9668, -1.3359, -2.0644, -1.8225, -2.2799, -2.7846, -2.1197],\n",
            "        [-2.0784, -2.4874, -1.4221, -2.0621, -2.0792, -2.0171, -2.8080, -2.2545],\n",
            "        [-2.2951, -2.2948, -1.5672, -1.7704, -2.1013, -1.8812, -2.8150, -2.4655],\n",
            "        [-1.8813, -3.0462, -1.2971, -2.3894, -1.9624, -2.1516, -2.7928, -2.1455],\n",
            "        [-2.0427, -2.4023, -1.5029, -1.9781, -2.0615, -1.9841, -2.8124, -2.3626],\n",
            "        [-1.9607, -2.9337, -1.3200, -2.2163, -2.0044, -2.2315, -2.7050, -2.1127],\n",
            "        [-1.9241, -2.5458, -1.5310, -2.0600, -2.0499, -1.9677, -2.7363, -2.3179],\n",
            "        [-2.0887, -3.3233, -1.0668, -2.5763, -2.0687, -2.1964, -2.8475, -2.0844],\n",
            "        [-1.9317, -2.9010, -1.2530, -2.3042, -2.0105, -2.2558, -2.8889, -2.1176],\n",
            "        [-2.1183, -3.3951, -0.9513, -2.7253, -2.0867, -2.3280, -3.0046, -2.0930],\n",
            "        [-2.0316, -3.2181, -1.1679, -2.5232, -1.8578, -2.3857, -2.7863, -2.0564],\n",
            "        [-2.0555, -2.6630, -1.3624, -2.0897, -2.0547, -2.0083, -2.9091, -2.2481],\n",
            "        [-1.9463, -2.9258, -1.2121, -2.1620, -2.1376, -2.1251, -2.9656, -2.2825],\n",
            "        [-1.9608, -3.2290, -1.0427, -2.6427, -2.0801, -2.2943, -3.0976, -2.0788],\n",
            "        [-1.8936, -2.7929, -1.1542, -2.5048, -2.1279, -2.3579, -2.9035, -2.0981],\n",
            "        [-1.9713, -2.7554, -1.3938, -2.1195, -2.0876, -2.0655, -2.7684, -2.1593],\n",
            "        [-1.9839, -3.3325, -1.1526, -2.4089, -1.8155, -2.3199, -2.9742, -2.2172],\n",
            "        [-1.8972, -2.6683, -1.3541, -2.2125, -2.1234, -2.1133, -2.9190, -2.1321],\n",
            "        [-1.9306, -3.1228, -1.2512, -2.3218, -1.9567, -2.2001, -2.7383, -2.2088],\n",
            "        [-2.0006, -3.1600, -1.3338, -2.4480, -2.0045, -2.1765, -2.8472, -1.7945],\n",
            "        [-2.0667, -3.4223, -1.0962, -2.3449, -1.9851, -2.2064, -3.0976, -2.1358],\n",
            "        [-2.1758, -2.7332, -1.3608, -2.0403, -2.0628, -2.0759, -2.7640, -2.1249],\n",
            "        [-2.1912, -2.1339, -1.5672, -1.8134, -2.1243, -2.0014, -2.6878, -2.5847],\n",
            "        [-2.2161, -3.2753, -1.0736, -2.5852, -1.9984, -2.5058, -2.8105, -1.8409],\n",
            "        [-1.9221, -3.3430, -1.1677, -2.5606, -1.9295, -2.2245, -2.9979, -2.0651],\n",
            "        [-2.1152, -2.4782, -1.3168, -2.0450, -2.1281, -1.9880, -2.8795, -2.4544]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([2, 6, 7, 7, 5, 0, 7, 7, 6, 0, 6, 7, 5, 5, 0, 7, 6, 6, 0, 3, 2, 2, 7, 6,\n",
            "        3, 6, 6, 3, 5, 3, 3, 6], device='cuda:0')\n",
            "tensor([[-1.6537, -3.2529, -1.4498, -2.6372, -2.3850, -2.1556, -2.9365, -1.5953],\n",
            "        [-1.9010, -2.4167, -1.5781, -1.9895, -2.2345, -1.9897, -2.6643, -2.2557],\n",
            "        [-1.9517, -2.6863, -1.3358, -2.1044, -2.2396, -2.1670, -2.8600, -2.0660],\n",
            "        [-1.7785, -3.3408, -1.2254, -2.3019, -2.3295, -2.1004, -3.0748, -1.9947],\n",
            "        [-1.6947, -2.8413, -1.2461, -2.3964, -2.3645, -2.1840, -2.9298, -2.1259],\n",
            "        [-1.6452, -2.9869, -1.4729, -2.2718, -2.2737, -2.0961, -2.7935, -1.9869],\n",
            "        [-1.7279, -3.5074, -1.1862, -2.3796, -2.3870, -2.2566, -3.0292, -1.9008],\n",
            "        [-1.7141, -2.7760, -1.2713, -2.3456, -2.4608, -2.0705, -2.9139, -2.1581],\n",
            "        [-1.7335, -2.8776, -1.5080, -2.1837, -2.1806, -2.1439, -2.6894, -2.0026],\n",
            "        [-1.8170, -2.6731, -1.4849, -2.1554, -2.4720, -1.9949, -2.8396, -1.9163],\n",
            "        [-1.7054, -2.9617, -1.3969, -2.1201, -2.3656, -2.1436, -2.7780, -2.0724],\n",
            "        [-1.8071, -3.1218, -1.2571, -2.1874, -2.4113, -2.3306, -2.7977, -1.9156],\n",
            "        [-1.7579, -3.3550, -1.1779, -2.3093, -2.3993, -2.0432, -2.9912, -2.1644],\n",
            "        [-1.8016, -2.6230, -1.5378, -2.0754, -2.1854, -2.1150, -2.6706, -2.1225],\n",
            "        [-2.0004, -2.3079, -1.5547, -1.9308, -2.2814, -1.9393, -2.6226, -2.4036],\n",
            "        [-1.7756, -2.7410, -1.6781, -2.0060, -2.2490, -1.9958, -2.7649, -1.9628],\n",
            "        [-1.7856, -3.0908, -1.4899, -2.2123, -2.2325, -2.2004, -2.6924, -1.7942],\n",
            "        [-1.6193, -3.3870, -1.1980, -2.5583, -2.3510, -2.2389, -3.0639, -1.9636],\n",
            "        [-1.8743, -2.7243, -1.4984, -2.0219, -2.2303, -1.9837, -2.7344, -2.1623],\n",
            "        [-1.7192, -3.1431, -1.3823, -2.2981, -2.3097, -2.1709, -2.9172, -1.8406],\n",
            "        [-1.7821, -3.2423, -1.1734, -2.5323, -2.4469, -2.3476, -2.8508, -1.8084],\n",
            "        [-1.8280, -3.3320, -1.2576, -2.7045, -2.3443, -2.2416, -2.7440, -1.6832],\n",
            "        [-2.2265, -2.1112, -1.9699, -1.6486, -2.2462, -1.7205, -2.5462, -2.5761],\n",
            "        [-1.7367, -3.1462, -1.4658, -2.2219, -2.2928, -2.1057, -2.8008, -1.8446],\n",
            "        [-1.6648, -2.9613, -1.5121, -2.1893, -2.3105, -2.0650, -2.7281, -2.0009],\n",
            "        [-1.6665, -2.8539, -1.5146, -2.0829, -2.3640, -2.0987, -2.7583, -2.0483],\n",
            "        [-1.8099, -3.3811, -1.1948, -2.4520, -2.3468, -2.2699, -2.9690, -1.8135],\n",
            "        [-1.8305, -2.8207, -1.4836, -2.2130, -2.1775, -2.0778, -2.6890, -1.9846],\n",
            "        [-1.6287, -3.3446, -1.2295, -2.5731, -2.3248, -2.2272, -2.8485, -1.9932],\n",
            "        [-1.7415, -3.3616, -1.0992, -2.3725, -2.3635, -2.5344, -2.8985, -2.0014],\n",
            "        [-1.9172, -2.8798, -1.4656, -2.0408, -2.2253, -1.9712, -2.6942, -2.1116],\n",
            "        [-1.6417, -3.2147, -1.2834, -2.3802, -2.3222, -2.1910, -2.9842, -1.9941]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 7, 6, 6, 7, 7, 6, 6, 5, 5, 3, 7, 4, 6, 6, 5, 7, 7, 5, 3, 6, 1, 5, 0,\n",
            "        7, 3, 7, 7, 7, 1, 6, 7], device='cuda:0')\n",
            "tensor([[-1.6246, -2.5813, -1.7020, -2.1631, -2.8788, -2.1066, -2.6771, -1.6960],\n",
            "        [-1.6423, -2.5778, -1.6403, -2.0772, -2.4970, -2.0979, -2.6480, -1.9990],\n",
            "        [-1.7753, -2.4258, -1.8793, -1.9712, -2.3139, -2.0412, -2.4332, -2.0124],\n",
            "        [-1.6117, -2.7291, -1.8522, -2.0683, -2.4141, -2.1142, -2.5691, -1.8011],\n",
            "        [-1.7738, -2.2643, -1.9261, -1.8823, -2.5164, -1.9314, -2.5367, -2.0905],\n",
            "        [-2.1462, -1.9538, -2.0071, -1.7539, -2.3321, -1.7472, -2.4569, -2.5662],\n",
            "        [-1.5499, -3.0788, -1.6685, -2.2014, -2.4905, -2.2029, -2.6364, -1.7283],\n",
            "        [-1.6556, -3.0473, -1.5877, -2.4698, -2.7427, -2.3061, -2.6108, -1.4481],\n",
            "        [-1.9391, -2.0966, -1.9490, -1.8262, -2.4218, -1.9483, -2.4153, -2.2142],\n",
            "        [-1.5545, -2.8249, -1.8307, -2.2089, -2.4999, -2.1476, -2.7049, -1.6423],\n",
            "        [-1.9401, -2.3165, -1.9068, -1.7361, -2.2581, -1.9668, -2.4203, -2.3067],\n",
            "        [-1.5638, -3.1549, -1.4819, -2.2943, -2.6435, -2.1435, -2.7986, -1.7677],\n",
            "        [-1.7344, -2.9200, -1.5029, -2.1152, -2.2898, -2.1425, -2.7128, -1.9558],\n",
            "        [-1.6600, -2.7938, -1.6084, -2.2605, -2.5865, -2.0431, -2.6820, -1.7671],\n",
            "        [-1.5740, -2.7462, -1.7170, -2.1867, -2.5771, -2.1299, -2.5741, -1.7979],\n",
            "        [-1.7128, -2.8884, -1.7176, -2.1239, -2.6763, -2.2180, -2.5199, -1.5760],\n",
            "        [-1.6538, -2.9103, -1.6631, -2.1318, -2.5604, -2.0604, -2.6138, -1.7831],\n",
            "        [-1.7617, -2.9715, -1.6460, -2.4412, -2.8132, -2.3450, -2.7213, -1.2892],\n",
            "        [-1.5577, -2.9642, -1.6862, -2.2711, -2.5667, -2.3376, -2.5469, -1.6211],\n",
            "        [-1.6419, -2.9598, -1.7096, -2.0283, -2.4618, -2.0869, -2.6447, -1.8220],\n",
            "        [-1.6776, -2.2317, -1.9188, -2.0485, -2.4341, -2.0401, -2.4143, -2.0955],\n",
            "        [-2.7423, -1.9436, -2.3602, -1.7499, -1.9772, -1.7642, -1.7867, -3.0598],\n",
            "        [-1.6149, -3.1041, -1.4884, -2.2917, -2.6566, -2.2831, -2.7329, -1.6492],\n",
            "        [-1.6256, -2.7921, -1.7830, -2.2670, -2.2345, -2.1016, -2.4436, -1.8707],\n",
            "        [-1.7240, -3.0613, -1.5654, -2.1661, -2.6905, -2.1392, -2.6889, -1.6214],\n",
            "        [-1.5017, -3.1242, -1.7666, -2.2141, -2.4748, -2.1632, -2.6865, -1.6828],\n",
            "        [-1.8301, -2.1116, -1.6762, -1.9677, -2.5992, -1.9923, -2.6704, -2.1916],\n",
            "        [-1.4882, -2.5069, -1.7090, -2.2176, -2.5933, -2.0600, -2.6592, -2.0360],\n",
            "        [-1.6744, -3.1437, -1.4669, -2.2945, -2.5351, -2.2766, -2.6468, -1.6861],\n",
            "        [-1.5560, -3.0400, -1.6424, -2.0850, -2.4968, -2.1847, -2.8224, -1.7776],\n",
            "        [-1.6585, -2.6829, -1.7531, -2.1706, -2.4670, -2.1479, -2.5526, -1.7463],\n",
            "        [-1.7153, -2.2516, -1.7625, -2.0033, -2.4858, -1.9242, -2.6028, -2.2534]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 0, 6, 6, 6, 0, 6, 7, 6, 5, 6, 7, 1, 6, 6, 7, 7, 7, 0, 0, 5, 6, 6, 7,\n",
            "        7, 3, 1, 7, 5, 6, 6, 7], device='cuda:0')\n",
            "tensor([[-1.5877, -2.2724, -2.0876, -2.1571, -2.8771, -2.2643, -2.5158, -1.5516],\n",
            "        [-1.6277, -2.1756, -2.2104, -2.0979, -2.7137, -2.0207, -2.3491, -1.8116],\n",
            "        [-1.6170, -2.6320, -2.0054, -2.3047, -2.6802, -2.6604, -2.3640, -1.3369],\n",
            "        [-1.7378, -2.4984, -2.2520, -2.0889, -2.5300, -2.0871, -2.2490, -1.5913],\n",
            "        [-1.7518, -2.0824, -2.1456, -2.0029, -2.4829, -1.9293, -2.3568, -2.0675],\n",
            "        [-1.6276, -2.4220, -1.9272, -2.1157, -2.8408, -2.0444, -2.3346, -1.8075],\n",
            "        [-1.4119, -1.9749, -2.1843, -2.3104, -2.7702, -2.1394, -2.5352, -1.9232],\n",
            "        [-1.6428, -2.3550, -1.9850, -2.2057, -2.6497, -2.2521, -2.2750, -1.6849],\n",
            "        [-1.4670, -2.9104, -1.8578, -2.3556, -2.8948, -2.4837, -2.6327, -1.3726],\n",
            "        [-1.3848, -2.7660, -2.1399, -2.4223, -2.8785, -2.3669, -2.5005, -1.3931],\n",
            "        [-1.3876, -2.4279, -2.0845, -2.3615, -2.7469, -2.2691, -2.4607, -1.6578],\n",
            "        [-1.4601, -2.5701, -1.9649, -2.3805, -2.7920, -2.2774, -2.5118, -1.5436],\n",
            "        [-1.5579, -2.3260, -2.1174, -2.0512, -2.7495, -2.0079, -2.3610, -1.8953],\n",
            "        [-1.4131, -2.3637, -2.2445, -2.3203, -2.9310, -2.3306, -2.3656, -1.5425],\n",
            "        [-1.6720, -1.8379, -2.0954, -2.0217, -2.6990, -2.1670, -2.4250, -2.0615],\n",
            "        [-1.8676, -1.7484, -2.0409, -1.9956, -2.6959, -2.0442, -2.4076, -2.1320],\n",
            "        [-1.4706, -2.3866, -2.1402, -2.0706, -2.7756, -2.2021, -2.4923, -1.7207],\n",
            "        [-1.6631, -1.9357, -2.0133, -2.0794, -2.6371, -2.1766, -2.4257, -2.0088],\n",
            "        [-1.6427, -1.9570, -2.1431, -2.0042, -2.7112, -2.1597, -2.3922, -1.9665],\n",
            "        [-1.9756, -1.7549, -1.9600, -1.9033, -2.5999, -1.9252, -2.3602, -2.4776],\n",
            "        [-1.7652, -1.7732, -2.0433, -1.9242, -2.7773, -1.9920, -2.3987, -2.3645],\n",
            "        [-1.6277, -2.6386, -2.0932, -2.3084, -2.8467, -2.3471, -2.4081, -1.3250],\n",
            "        [-1.8372, -1.8411, -2.0651, -1.9690, -2.5282, -1.9736, -2.3623, -2.2757],\n",
            "        [-1.7078, -1.9660, -2.0358, -1.9490, -2.7906, -2.1127, -2.4112, -2.0119],\n",
            "        [-1.4937, -2.2227, -2.1845, -2.0698, -2.8480, -2.0455, -2.4826, -1.8475],\n",
            "        [-1.6348, -2.4736, -2.0785, -2.2831, -2.7266, -2.2566, -2.3036, -1.4978],\n",
            "        [-1.4941, -2.3560, -2.1343, -2.3488, -3.1121, -2.2444, -2.3623, -1.5040],\n",
            "        [-1.5946, -2.1287, -2.1745, -1.9249, -2.6071, -2.1366, -2.3823, -2.0074],\n",
            "        [-1.7249, -2.0377, -2.0421, -1.9997, -2.7615, -2.0636, -2.3758, -1.9435],\n",
            "        [-1.3779, -2.6094, -1.9544, -2.4391, -2.8615, -2.2668, -2.6219, -1.5514],\n",
            "        [-2.1262, -1.6928, -2.3387, -1.6552, -2.4338, -1.8183, -2.3106, -2.8138],\n",
            "        [-1.5332, -2.0022, -2.2060, -2.2624, -2.8519, -2.1873, -2.3591, -1.7696]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 5, 6, 6, 5, 7, 7, 3, 5, 7, 3, 7, 7, 5, 6, 5, 6, 6, 3, 6, 0, 5, 5, 5,\n",
            "        5, 4, 7, 3, 5, 6, 6, 7], device='cuda:0')\n",
            "tensor([[-1.5689, -2.0935, -2.5059, -2.1112, -3.0025, -2.2078, -2.2465, -1.6074],\n",
            "        [-1.7425, -2.1843, -2.5766, -1.9152, -2.6745, -1.8875, -2.1525, -1.8811],\n",
            "        [-2.0364, -1.6212, -2.4693, -1.8819, -2.5963, -1.8552, -2.0423, -2.6009],\n",
            "        [-2.9194, -2.0371, -2.6208, -2.1366, -1.9494, -1.8309, -1.2549, -3.2940],\n",
            "        [-1.6796, -2.0270, -2.4330, -2.0870, -2.8230, -2.0759, -2.2562, -1.7128],\n",
            "        [-1.7161, -2.1997, -2.6293, -2.0171, -2.9869, -2.0943, -2.2156, -1.5071],\n",
            "        [-1.5627, -2.3990, -2.6081, -2.2716, -3.1182, -2.4534, -2.2942, -1.2320],\n",
            "        [-1.7380, -2.1568, -2.3653, -2.0421, -2.5776, -2.2205, -2.2811, -1.6191],\n",
            "        [-1.5927, -2.2584, -2.6566, -2.2995, -3.0558, -2.1997, -2.2845, -1.3400],\n",
            "        [-1.7363, -2.2395, -2.4526, -2.1374, -3.0067, -2.2972, -2.1522, -1.3981],\n",
            "        [-1.6872, -2.5007, -2.8460, -2.3253, -3.0515, -2.6004, -2.2599, -1.0464],\n",
            "        [-1.5328, -2.4678, -2.6315, -2.2144, -3.1210, -2.2087, -2.3190, -1.3250],\n",
            "        [-1.6956, -1.9255, -2.5211, -2.0661, -2.9590, -2.0598, -2.2073, -1.7469],\n",
            "        [-1.5156, -1.9965, -2.5654, -2.1951, -3.1338, -2.0336, -2.1349, -1.8104],\n",
            "        [-1.7279, -2.2343, -2.6261, -2.0792, -2.8625, -2.1936, -2.2263, -1.4217],\n",
            "        [-1.6530, -2.2621, -2.6766, -2.2054, -3.0375, -2.4218, -2.1329, -1.3087],\n",
            "        [-1.6807, -1.8476, -2.4910, -2.1150, -3.0183, -2.0535, -2.1470, -1.8409]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 3, 7, 5, 4, 5, 6, 5, 5, 7, 6, 5, 6, 6, 6, 6, 5], device='cuda:0')\n",
            "\n",
            "Evaluating...\n",
            "tensor(2.1452, device='cuda:0')\n",
            "tensor(2.1208, device='cuda:0')\n",
            "\n",
            "Training Loss: 2.230\n",
            "Validation Loss: 2.133\n",
            "\n",
            " Epoch 2 / 10\n",
            "tensor([[-1.7910, -2.3415, -2.7361, -1.8842, -2.6201, -2.1020, -2.0526, -1.6253],\n",
            "        [-2.9858, -2.0702, -2.6147, -2.2869, -1.9995, -1.7854, -1.1782, -3.2806],\n",
            "        [-1.9173, -2.2257, -2.8861, -2.0709, -2.8850, -2.2989, -1.8356, -1.3967],\n",
            "        [-1.8654, -2.4241, -3.0371, -2.0403, -3.0789, -2.3057, -1.9992, -1.2124],\n",
            "        [-1.9297, -2.1534, -2.7783, -2.0830, -3.0780, -2.2187, -1.9328, -1.3765],\n",
            "        [-1.9237, -2.1892, -3.0054, -2.3025, -3.3776, -2.2877, -1.9986, -1.1356],\n",
            "        [-1.9325, -1.9118, -2.9615, -2.1696, -2.9916, -2.1152, -1.8667, -1.5326],\n",
            "        [-2.0694, -2.2745, -2.9992, -2.1883, -3.1660, -2.2462, -1.7854, -1.2267],\n",
            "        [-1.7629, -2.2736, -2.8253, -2.2561, -2.8632, -2.1454, -1.9213, -1.4232],\n",
            "        [-2.0598, -2.4133, -2.6807, -2.0562, -2.5441, -2.3408, -1.8378, -1.3760],\n",
            "        [-1.8181, -2.1572, -2.8456, -2.2875, -3.0787, -2.2683, -1.9034, -1.3324],\n",
            "        [-1.8209, -1.9734, -2.8029, -2.0345, -2.9851, -1.8959, -2.0721, -1.7086],\n",
            "        [-1.8402, -2.4311, -2.9564, -2.1839, -3.0779, -2.0152, -1.9768, -1.3064],\n",
            "        [-1.8797, -1.9371, -2.4458, -1.9317, -2.8903, -1.7646, -2.0545, -2.1480],\n",
            "        [-1.8468, -2.1854, -2.8703, -2.1555, -2.7421, -1.8930, -1.7523, -1.7786],\n",
            "        [-1.8751, -1.9278, -2.7938, -2.0130, -3.0901, -2.0385, -1.9346, -1.6809],\n",
            "        [-2.1024, -2.1716, -2.9412, -2.2192, -3.1157, -2.4897, -1.8778, -1.1328],\n",
            "        [-2.0286, -2.1671, -2.8167, -2.0094, -2.8714, -2.0853, -1.8586, -1.4991],\n",
            "        [-1.9437, -1.7211, -2.8189, -2.1550, -2.9956, -1.9811, -1.9030, -1.7998],\n",
            "        [-1.8395, -2.0227, -3.0108, -2.1009, -3.1897, -2.0056, -1.8295, -1.6047],\n",
            "        [-1.8330, -2.1156, -3.0329, -1.9788, -2.9400, -1.8765, -1.9508, -1.6877],\n",
            "        [-1.8769, -2.1129, -2.8088, -1.9505, -2.8330, -2.0331, -1.8985, -1.6927],\n",
            "        [-1.9433, -2.1333, -2.8255, -2.2770, -3.0798, -2.3447, -1.8540, -1.2802],\n",
            "        [-1.9300, -2.0331, -2.7028, -1.8992, -2.7308, -1.6553, -2.0268, -2.1265],\n",
            "        [-1.9344, -2.1840, -2.7983, -1.8699, -2.6325, -1.7744, -2.1120, -1.7996],\n",
            "        [-2.3256, -1.6700, -2.5981, -1.9054, -2.4069, -1.6879, -1.8430, -2.8557],\n",
            "        [-2.3766, -1.7307, -2.3602, -1.9674, -2.3533, -1.7560, -1.7303, -2.9813],\n",
            "        [-1.9373, -2.2437, -3.0340, -2.0923, -3.1508, -2.1550, -1.8692, -1.3267],\n",
            "        [-1.8985, -2.2283, -3.0132, -2.1482, -3.1629, -2.3084, -1.8771, -1.2662],\n",
            "        [-1.8745, -1.9347, -2.7533, -1.9177, -2.7667, -1.9226, -1.9060, -2.0125],\n",
            "        [-1.8867, -2.1814, -3.0186, -2.1224, -3.0466, -2.3837, -1.9506, -1.2552],\n",
            "        [-1.8518, -2.5331, -2.7876, -2.0385, -3.0987, -2.0271, -1.9010, -1.4041]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 7, 7, 7, 5, 0, 6, 5, 0, 1, 2, 7, 5, 0, 6, 6, 2, 7, 7, 6, 7, 6, 7, 5,\n",
            "        7, 5, 6, 6, 7, 5, 6, 3], device='cuda:0')\n",
            "tensor([[-2.0865, -1.9451, -3.0220, -1.9766, -3.0995, -1.8857, -1.7232, -1.7698],\n",
            "        [-1.9724, -1.9853, -2.9719, -2.0938, -3.1139, -1.8694, -1.8216, -1.6676],\n",
            "        [-2.0024, -2.1176, -2.9834, -1.9418, -2.8123, -1.7764, -1.7742, -1.8861],\n",
            "        [-2.2494, -2.2259, -3.1057, -1.9770, -3.0037, -1.9073, -1.6824, -1.5175],\n",
            "        [-2.1018, -1.6210, -3.0096, -1.9924, -2.8598, -1.7360, -1.8920, -2.2063],\n",
            "        [-2.0154, -2.2272, -3.0029, -2.0170, -2.9898, -1.9769, -1.6823, -1.6022],\n",
            "        [-2.0215, -2.2567, -3.0064, -1.9488, -2.7437, -1.8867, -1.6978, -1.7605],\n",
            "        [-1.9261, -2.1142, -2.8105, -2.0125, -2.6981, -1.7649, -1.8431, -1.9458],\n",
            "        [-2.1661, -2.0855, -2.8655, -2.0186, -3.1886, -2.2718, -1.5319, -1.5566],\n",
            "        [-1.8732, -1.9820, -2.7905, -2.1917, -2.7712, -1.8827, -1.7335, -1.9377],\n",
            "        [-2.0955, -2.2197, -2.6871, -1.8819, -2.6684, -1.8421, -1.7036, -1.9799],\n",
            "        [-2.1452, -1.8736, -3.0123, -2.2327, -2.7398, -2.0860, -1.7479, -1.5604],\n",
            "        [-2.2756, -2.0853, -2.9988, -2.1971, -3.2589, -2.6662, -1.5697, -1.2175],\n",
            "        [-1.9701, -2.1715, -2.9041, -2.0463, -2.8983, -1.7151, -1.7793, -1.8407],\n",
            "        [-2.0980, -2.1342, -2.8155, -1.8564, -2.6491, -1.8387, -1.8779, -1.8313],\n",
            "        [-1.9490, -2.1127, -2.8718, -2.0717, -2.8734, -1.8954, -1.6996, -1.8043],\n",
            "        [-2.2040, -2.0790, -2.7066, -1.6317, -2.6582, -1.7409, -1.8675, -2.2799],\n",
            "        [-2.5074, -1.7492, -2.5890, -1.9702, -2.4101, -1.6853, -1.6536, -2.7561],\n",
            "        [-1.9999, -1.7828, -2.8482, -2.0204, -2.8680, -1.8816, -1.7747, -2.0616],\n",
            "        [-2.0567, -1.9712, -3.0596, -2.2090, -3.0406, -1.9117, -1.6197, -1.7009],\n",
            "        [-2.1928, -1.6863, -3.0258, -2.2111, -3.0996, -2.1385, -1.6610, -1.6490],\n",
            "        [-2.0394, -1.9917, -3.2526, -2.0166, -3.1976, -1.9977, -1.7523, -1.5523],\n",
            "        [-1.9986, -1.9838, -3.2456, -1.8453, -2.6767, -1.6763, -1.8442, -2.1541],\n",
            "        [-2.0150, -1.8495, -2.8520, -2.0092, -2.9197, -1.8846, -1.8139, -1.9060],\n",
            "        [-2.1634, -1.9588, -2.9576, -2.0190, -2.8060, -1.7793, -1.6168, -2.0283],\n",
            "        [-2.3953, -1.9246, -3.0393, -2.0917, -3.3807, -2.3504, -1.7093, -1.2686],\n",
            "        [-2.0973, -2.0454, -2.8962, -1.8757, -2.8375, -1.6545, -1.7157, -2.2090],\n",
            "        [-2.2044, -1.7180, -2.8192, -2.0536, -2.9477, -1.7125, -1.6409, -2.3471],\n",
            "        [-2.1808, -2.0689, -3.1737, -2.1167, -3.0512, -2.0951, -1.7082, -1.3988],\n",
            "        [-2.0473, -2.0350, -2.7645, -1.9472, -2.8486, -1.7922, -1.7130, -2.0426],\n",
            "        [-2.1412, -1.7451, -2.8488, -2.0101, -2.7570, -1.6740, -1.7085, -2.4786],\n",
            "        [-2.1079, -2.0690, -2.8722, -1.7849, -2.9805, -1.7567, -1.8745, -1.8905]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 6, 5, 6, 5, 6, 6, 0, 7, 7, 6, 4, 1, 7, 5, 7, 3, 6, 7, 5, 4, 0, 1, 6,\n",
            "        3, 7, 5, 7, 0, 6, 5, 2], device='cuda:0')\n",
            "tensor([[-2.1833, -1.9035, -2.9690, -2.0012, -2.9027, -2.0612, -1.6727, -1.7046],\n",
            "        [-2.2162, -1.9121, -3.0235, -1.9950, -2.8764, -2.1983, -1.6128, -1.6508],\n",
            "        [-2.3043, -1.9369, -2.8426, -1.9640, -2.7201, -1.6557, -1.6545, -2.2123],\n",
            "        [-2.3136, -1.7679, -3.1125, -2.0394, -3.0369, -1.9152, -1.4620, -2.0500],\n",
            "        [-2.4897, -1.7255, -3.2013, -2.4216, -3.2827, -2.0878, -1.2996, -1.7408],\n",
            "        [-1.9101, -1.8277, -2.9912, -2.0843, -2.8386, -1.8985, -1.7245, -2.0404],\n",
            "        [-2.4297, -1.9449, -3.1556, -1.9888, -3.0455, -2.4091, -1.4588, -1.5165],\n",
            "        [-1.9706, -2.4301, -2.8618, -1.9401, -2.6817, -1.7846, -1.7937, -1.7774],\n",
            "        [-2.6223, -1.7776, -3.0690, -2.1879, -3.1801, -2.2360, -1.4549, -1.5241],\n",
            "        [-2.1989, -1.7572, -2.8846, -2.1257, -2.7449, -2.2519, -1.6461, -1.7200],\n",
            "        [-2.2980, -2.1463, -2.8286, -1.9775, -2.7088, -2.0095, -1.5865, -1.7159],\n",
            "        [-2.0710, -2.4493, -3.0331, -1.9615, -2.6131, -1.7969, -1.6081, -1.8365],\n",
            "        [-2.2695, -1.6632, -3.1443, -2.2774, -3.2011, -2.3192, -1.5008, -1.6123],\n",
            "        [-2.3124, -2.1025, -2.9192, -2.1085, -2.9170, -1.8102, -1.5970, -1.6972],\n",
            "        [-2.2108, -1.7931, -3.0239, -2.1108, -2.8060, -2.0635, -1.5480, -1.8705],\n",
            "        [-2.2617, -1.5853, -2.9763, -2.3792, -2.7768, -2.0696, -1.5420, -1.9318],\n",
            "        [-2.3634, -1.6253, -3.0806, -2.3072, -3.1230, -2.0206, -1.5123, -1.7922],\n",
            "        [-2.4390, -2.0829, -2.9828, -2.2488, -3.2088, -2.1674, -1.4044, -1.4627],\n",
            "        [-2.0404, -2.1523, -3.0583, -2.0578, -2.9409, -2.2203, -1.6126, -1.5217],\n",
            "        [-2.3266, -1.7477, -2.9505, -2.0025, -2.8055, -1.7056, -1.6696, -2.2034],\n",
            "        [-2.4885, -1.6952, -3.0597, -1.8368, -2.8760, -1.5581, -1.6345, -2.7298],\n",
            "        [-2.1734, -1.9660, -2.8739, -2.1960, -3.0020, -2.1946, -1.3605, -1.8274],\n",
            "        [-2.2320, -1.7096, -3.0620, -2.3491, -3.2972, -2.3127, -1.4265, -1.6431],\n",
            "        [-2.3899, -2.0635, -3.2717, -1.8899, -3.0631, -1.9835, -1.5067, -1.6802],\n",
            "        [-2.2206, -1.7776, -2.8411, -2.2127, -2.8253, -2.3908, -1.5379, -1.6661],\n",
            "        [-2.0289, -1.8954, -3.1235, -2.1205, -2.6812, -1.8840, -1.6203, -1.9952],\n",
            "        [-2.2362, -1.6957, -2.7965, -2.0314, -2.6609, -1.7265, -1.6831, -2.4778],\n",
            "        [-2.3287, -1.9161, -3.0897, -1.9586, -2.8867, -2.0825, -1.5862, -1.6942],\n",
            "        [-2.2482, -1.8027, -3.1941, -2.0833, -3.2040, -1.8201, -1.6198, -1.8111],\n",
            "        [-2.3687, -1.7020, -2.6613, -2.0087, -2.7668, -1.5854, -1.6521, -2.8019],\n",
            "        [-2.2027, -1.6080, -2.6624, -1.9992, -2.7581, -1.7529, -1.8547, -2.3989],\n",
            "        [-2.5259, -2.0642, -3.2335, -2.0495, -3.0896, -2.0649, -1.4706, -1.5018]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 6, 5, 2, 2, 5, 4, 6, 2, 4, 3, 5, 6, 7, 7, 6, 7, 3, 7, 6, 4, 5, 5, 6,\n",
            "        7, 0, 5, 6, 5, 6, 0, 7], device='cuda:0')\n",
            "tensor([[-2.0545, -1.7947, -2.8392, -2.3260, -2.8502, -2.1546, -1.4989, -1.8817],\n",
            "        [-2.0537, -2.1686, -2.7848, -2.0197, -2.3623, -1.8038, -1.7581, -2.0271],\n",
            "        [-2.4513, -1.9452, -2.9915, -1.9924, -2.7459, -2.0442, -1.3821, -1.9694],\n",
            "        [-2.5619, -1.6052, -3.0158, -2.2228, -2.9501, -2.0382, -1.4056, -1.9889],\n",
            "        [-2.1798, -1.7469, -2.8941, -2.1666, -2.6879, -2.0143, -1.5348, -2.0734],\n",
            "        [-2.4068, -1.9013, -3.0725, -2.0761, -2.8781, -2.0403, -1.4484, -1.7860],\n",
            "        [-2.2792, -1.9159, -3.0254, -2.1620, -2.9577, -2.0936, -1.3878, -1.8203],\n",
            "        [-2.2787, -1.6333, -2.5812, -2.2279, -2.6959, -1.8599, -1.6143, -2.3364],\n",
            "        [-2.4553, -1.8434, -2.6723, -2.1130, -2.6502, -2.3247, -1.4854, -1.7657],\n",
            "        [-2.3561, -1.6689, -2.7763, -2.3041, -3.0260, -2.0535, -1.5432, -1.8070],\n",
            "        [-2.4542, -2.1856, -2.8771, -2.1292, -2.7393, -2.1911, -1.2642, -1.7864],\n",
            "        [-2.2954, -1.8087, -2.9023, -2.1394, -2.8675, -2.2186, -1.3592, -1.9637],\n",
            "        [-2.0060, -1.8580, -3.0887, -2.1241, -2.7382, -1.8063, -1.5957, -2.1833],\n",
            "        [-2.3394, -1.9775, -2.8749, -2.0730, -2.8848, -2.2298, -1.3484, -1.8332],\n",
            "        [-2.3583, -1.4677, -2.8831, -2.3446, -2.9888, -2.1425, -1.4876, -2.0442],\n",
            "        [-2.2725, -1.5843, -2.9720, -2.3239, -2.9896, -1.9615, -1.4859, -2.0753],\n",
            "        [-2.4215, -1.6110, -2.8830, -2.2396, -2.9108, -1.6772, -1.6026, -2.2411],\n",
            "        [-2.4196, -1.7110, -2.9667, -2.2188, -2.9815, -2.0493, -1.4054, -1.9289],\n",
            "        [-2.2221, -1.8303, -2.8945, -2.2507, -3.0310, -2.0208, -1.4633, -1.8431],\n",
            "        [-2.1551, -1.8982, -3.0169, -1.9958, -2.7262, -1.8998, -1.5987, -2.0235],\n",
            "        [-2.3338, -1.7140, -2.9983, -2.2387, -2.8976, -2.1250, -1.4183, -1.8988],\n",
            "        [-2.2733, -1.7892, -2.9928, -2.0225, -2.5999, -1.7999, -1.5783, -2.2872],\n",
            "        [-2.2248, -1.5395, -2.8274, -2.3722, -2.8066, -1.7147, -1.6402, -2.4011],\n",
            "        [-2.4299, -1.7557, -2.9668, -2.2615, -2.9601, -2.2738, -1.3468, -1.7797],\n",
            "        [-2.5239, -1.8075, -2.9686, -2.3160, -2.9204, -1.9879, -1.4247, -1.7471],\n",
            "        [-2.4118, -1.7657, -2.6825, -2.1597, -2.5858, -2.1624, -1.4788, -1.9861],\n",
            "        [-2.3318, -2.1333, -2.9959, -2.0115, -2.7641, -2.0009, -1.4448, -1.7920],\n",
            "        [-2.5188, -1.8897, -3.0248, -2.1675, -2.7170, -1.9869, -1.3540, -1.9387],\n",
            "        [-2.2106, -1.8126, -2.9128, -2.1294, -2.5632, -1.9333, -1.5346, -2.1486],\n",
            "        [-2.5611, -1.5377, -3.1503, -2.3789, -3.3404, -2.0207, -1.2619, -2.1093],\n",
            "        [-2.1763, -1.7422, -2.8999, -2.0047, -2.6964, -1.7036, -1.6829, -2.4492],\n",
            "        [-2.1779, -1.9465, -2.8116, -2.1125, -2.7886, -2.0715, -1.5063, -1.8730]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([0, 5, 0, 7, 5, 6, 0, 6, 6, 7, 7, 0, 5, 5, 0, 5, 7, 6, 2, 7, 5, 7, 5, 0,\n",
            "        5, 4, 6, 6, 1, 7, 5, 6], device='cuda:0')\n",
            "tensor([[-2.1381, -1.7766, -2.7699, -2.0854, -2.6449, -1.6506, -1.6961, -2.5302],\n",
            "        [-2.3438, -1.6829, -2.8476, -2.2906, -2.8480, -1.9757, -1.4459, -2.0646],\n",
            "        [-2.5101, -1.9937, -2.9227, -2.0609, -2.7788, -1.9708, -1.3329, -1.9932],\n",
            "        [-2.0680, -1.9675, -3.3049, -1.9376, -2.4605, -1.6258, -1.6496, -2.5418],\n",
            "        [-2.2841, -1.6851, -2.7642, -2.2463, -2.8012, -2.0214, -1.4777, -2.0995],\n",
            "        [-2.2320, -1.8309, -2.7694, -2.1997, -2.7485, -2.1199, -1.3612, -2.1333],\n",
            "        [-2.1521, -1.7658, -2.7539, -2.2542, -2.6060, -1.8038, -1.5753, -2.3164],\n",
            "        [-2.1031, -1.7359, -2.5961, -2.3737, -2.7469, -2.0414, -1.5557, -2.0481],\n",
            "        [-2.3565, -1.8206, -2.7791, -2.2968, -2.7948, -1.7814, -1.4923, -2.0695],\n",
            "        [-2.2723, -2.0889, -2.9085, -2.0456, -2.6424, -2.2238, -1.3543, -1.8858],\n",
            "        [-2.1415, -1.7002, -2.8259, -2.3137, -2.6339, -2.0613, -1.4894, -2.1445],\n",
            "        [-2.1079, -1.5591, -2.6618, -2.3791, -2.7889, -1.9901, -1.5795, -2.2880],\n",
            "        [-2.0523, -2.1275, -2.7299, -2.0489, -2.6043, -1.7231, -1.6828, -2.1201],\n",
            "        [-2.2106, -1.6885, -2.7694, -2.2840, -2.7682, -1.8359, -1.5578, -2.2244],\n",
            "        [-1.9650, -1.7293, -2.7217, -2.2672, -2.4758, -2.0576, -1.6360, -2.2399],\n",
            "        [-2.2163, -1.8350, -2.8665, -2.5936, -2.8312, -2.0084, -1.3348, -1.9424],\n",
            "        [-2.2591, -1.7947, -2.9557, -2.2265, -2.6773, -1.8761, -1.4409, -2.2002],\n",
            "        [-2.3982, -2.2579, -2.8986, -1.8138, -2.4149, -1.3340, -1.7088, -2.9463],\n",
            "        [-2.1371, -1.6500, -2.8867, -2.3833, -2.7797, -2.2517, -1.4686, -1.9351],\n",
            "        [-2.2221, -1.6262, -2.7704, -2.3889, -2.8891, -1.9669, -1.4168, -2.2772],\n",
            "        [-2.2118, -1.8585, -2.7887, -2.2220, -2.6724, -1.8898, -1.5292, -2.0573],\n",
            "        [-2.5876, -1.9331, -3.1121, -2.2453, -2.4380, -1.4533, -1.3087, -3.2601],\n",
            "        [-2.6142, -1.8452, -2.7436, -2.2486, -2.7487, -1.9519, -1.3393, -2.0337],\n",
            "        [-2.2544, -1.9521, -2.6268, -2.3435, -2.7422, -2.0637, -1.5094, -1.7582],\n",
            "        [-2.1226, -2.0099, -2.6562, -2.0787, -2.6605, -1.6849, -1.5979, -2.3724],\n",
            "        [-2.0004, -2.3060, -2.7942, -1.9449, -2.5308, -1.6824, -1.6792, -2.2180],\n",
            "        [-2.1874, -1.6752, -2.6485, -2.1811, -2.5915, -1.6980, -1.7188, -2.5308],\n",
            "        [-3.0426, -2.7092, -3.2813, -2.4828, -2.2051, -1.5786, -0.8661, -3.5936],\n",
            "        [-2.1542, -1.8733, -2.6518, -2.2729, -2.4128, -1.9590, -1.5744, -2.1274],\n",
            "        [-2.0886, -2.0219, -2.7550, -2.0149, -2.5865, -1.8708, -1.6224, -2.1197],\n",
            "        [-2.1077, -1.7376, -2.6016, -2.3384, -2.6620, -1.8678, -1.6007, -2.2455],\n",
            "        [-2.0389, -1.7491, -2.9707, -2.0875, -2.4829, -1.9761, -1.6783, -2.1906]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 7, 5, 6, 7, 6, 5, 7, 5, 0, 7, 7, 7, 3, 4, 7, 0, 3, 5, 6, 3, 5, 5, 7,\n",
            "        2, 6, 6, 6, 5, 0, 0, 3], device='cuda:0')\n",
            "tensor([[-1.7362, -2.0215, -2.6976, -2.2288, -2.4918, -1.9175, -1.7170, -2.2350],\n",
            "        [-1.9003, -2.0914, -2.7038, -2.1586, -2.6225, -1.5843, -1.7407, -2.3923],\n",
            "        [-1.9060, -2.1454, -2.6066, -2.2176, -2.2932, -1.9230, -1.7111, -2.0884],\n",
            "        [-2.1342, -2.4590, -2.6686, -1.8586, -2.0713, -1.7982, -1.7950, -2.1789],\n",
            "        [-1.9036, -2.4281, -2.8291, -2.2051, -2.4804, -1.5275, -1.5670, -2.4770],\n",
            "        [-2.2859, -1.8732, -2.6642, -2.0968, -2.3121, -1.6106, -1.6120, -2.9211],\n",
            "        [-1.9688, -1.8720, -2.5676, -2.2000, -2.5514, -1.9623, -1.6417, -2.2360],\n",
            "        [-2.1176, -2.0638, -2.8547, -1.9835, -2.5393, -1.3381, -1.8274, -2.8925],\n",
            "        [-2.2073, -1.7561, -2.6983, -2.2805, -2.5726, -2.1905, -1.4367, -2.1053],\n",
            "        [-1.9687, -2.1441, -2.8114, -2.1490, -2.4702, -1.7944, -1.5576, -2.2533],\n",
            "        [-2.2021, -1.7882, -2.7027, -2.3277, -2.5019, -1.9893, -1.4809, -2.1942],\n",
            "        [-2.2050, -1.7738, -2.8147, -2.2759, -2.6336, -1.9901, -1.5222, -2.0348],\n",
            "        [-1.8826, -1.8579, -2.7036, -2.2835, -2.4567, -1.9865, -1.6488, -2.2280],\n",
            "        [-2.2879, -1.6751, -2.5710, -2.5168, -2.5345, -2.2140, -1.4087, -2.1118],\n",
            "        [-2.1159, -1.9097, -2.5757, -2.4438, -2.4957, -1.9329, -1.5425, -2.0604],\n",
            "        [-2.1137, -1.6170, -2.7537, -2.3889, -2.5650, -1.9027, -1.5093, -2.5489],\n",
            "        [-3.0826, -2.7185, -3.5746, -2.4622, -2.2338, -1.5385, -0.8488, -3.6823],\n",
            "        [-1.9949, -1.9785, -2.5933, -2.2565, -2.4622, -1.8194, -1.6648, -2.2108],\n",
            "        [-1.9938, -1.8296, -2.6460, -2.3602, -2.6691, -2.1517, -1.5197, -2.0128],\n",
            "        [-1.9145, -2.0456, -2.7783, -2.0948, -2.4725, -1.7354, -1.7531, -2.2622],\n",
            "        [-2.0528, -2.2236, -2.7736, -1.9487, -2.5600, -1.4263, -1.7641, -2.6641],\n",
            "        [-2.2544, -1.9957, -2.7881, -2.1603, -2.4792, -1.4337, -1.5613, -2.9916],\n",
            "        [-2.0126, -2.0301, -2.8082, -2.0955, -2.4603, -1.8886, -1.5561, -2.2628],\n",
            "        [-2.0601, -1.9977, -2.5588, -2.1352, -2.3699, -1.6158, -1.8226, -2.4364],\n",
            "        [-1.8947, -1.9605, -2.5939, -2.1590, -2.5152, -1.8752, -1.7438, -2.2105],\n",
            "        [-1.9129, -1.7146, -2.5609, -2.4091, -2.5999, -2.0250, -1.6248, -2.2831],\n",
            "        [-1.8230, -1.9589, -2.5830, -2.2741, -2.3192, -1.9481, -1.6735, -2.4022],\n",
            "        [-1.8548, -1.8360, -2.6127, -2.2190, -2.3939, -1.9648, -1.7577, -2.3216],\n",
            "        [-1.7993, -2.1886, -2.6046, -2.0972, -2.3519, -1.8498, -1.8691, -2.1281],\n",
            "        [-2.2239, -1.8541, -2.4860, -2.0588, -2.4745, -1.5085, -1.8823, -2.7079],\n",
            "        [-2.0644, -1.7991, -2.7557, -2.2993, -2.5112, -1.8145, -1.5622, -2.4080],\n",
            "        [-2.0146, -1.9455, -2.6953, -2.1791, -2.3966, -2.0552, -1.5265, -2.2381]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 5, 7, 6, 6, 5, 7, 5, 7, 3, 3, 6, 7, 3, 5, 5, 1, 7, 3, 5, 3, 6, 7, 6,\n",
            "        6, 7, 3, 5, 7, 3, 6, 6], device='cuda:0')\n",
            "tensor([[-1.9626, -1.9576, -2.6343, -2.1218, -2.6176, -1.6277, -1.7537, -2.4740],\n",
            "        [-1.9233, -1.9176, -2.6129, -2.1699, -2.4721, -1.8868, -1.7519, -2.2072],\n",
            "        [-1.7352, -2.1567, -2.4766, -2.0959, -2.4721, -1.8459, -1.8305, -2.3198],\n",
            "        [-1.8862, -1.9325, -2.5827, -2.2707, -2.4679, -1.6901, -1.7592, -2.4852],\n",
            "        [-1.9611, -2.0567, -2.6188, -2.2163, -2.3622, -1.5584, -1.7171, -2.7294],\n",
            "        [-2.0308, -2.1145, -2.5902, -1.9517, -2.2337, -1.8120, -1.7743, -2.3972],\n",
            "        [-1.9139, -2.5186, -2.6923, -1.9363, -2.1711, -1.6463, -1.8444, -2.3536],\n",
            "        [-1.8289, -2.1021, -2.7211, -2.0155, -2.3089, -1.7954, -1.7887, -2.4586],\n",
            "        [-1.9690, -2.1202, -2.5690, -2.1515, -2.0922, -2.0243, -1.7272, -2.1698],\n",
            "        [-2.0880, -1.9733, -2.4749, -2.0806, -2.2262, -1.9348, -1.7154, -2.3458],\n",
            "        [-1.9950, -1.9337, -2.6493, -2.2528, -2.3810, -1.7743, -1.6757, -2.3608],\n",
            "        [-1.8664, -2.3162, -2.4036, -2.1494, -2.3774, -1.8879, -1.7152, -2.1574],\n",
            "        [-1.8154, -2.1716, -2.5716, -2.0555, -2.2439, -2.1359, -1.6416, -2.2931],\n",
            "        [-2.0122, -1.9264, -2.3847, -2.1634, -2.3692, -2.0743, -1.7008, -2.1906],\n",
            "        [-2.0604, -2.1603, -2.4751, -2.1471, -2.4805, -1.8371, -1.6777, -2.0672],\n",
            "        [-2.0084, -1.9020, -2.4682, -2.2441, -2.4696, -2.0655, -1.5826, -2.2169],\n",
            "        [-1.7601, -2.1862, -2.7003, -1.9438, -2.3588, -1.7954, -1.8724, -2.3976],\n",
            "        [-1.8312, -1.9901, -2.6634, -2.3498, -2.4350, -1.8959, -1.6976, -2.1447],\n",
            "        [-1.7903, -2.0851, -2.7347, -2.0754, -2.3575, -1.7631, -1.8692, -2.3231],\n",
            "        [-2.0899, -1.7487, -2.5464, -2.2317, -2.4569, -2.1366, -1.5499, -2.2968],\n",
            "        [-2.2080, -2.0837, -2.5632, -2.1197, -2.3829, -2.0051, -1.5193, -2.0980],\n",
            "        [-1.9712, -1.8161, -2.6356, -2.1239, -2.5124, -1.8440, -1.7837, -2.3073],\n",
            "        [-1.8219, -2.0280, -2.6536, -2.2154, -2.4183, -1.9693, -1.6823, -2.1838],\n",
            "        [-2.1447, -1.7449, -2.5176, -2.2215, -2.1341, -2.2885, -1.6040, -2.3199],\n",
            "        [-2.0416, -2.3825, -2.6132, -2.0785, -2.3720, -1.5909, -1.7135, -2.2812],\n",
            "        [-1.8381, -2.0990, -2.5762, -2.1365, -2.4471, -1.8427, -1.7784, -2.2041],\n",
            "        [-1.9721, -2.0609, -2.6120, -2.1355, -2.3123, -1.7281, -1.7462, -2.3986],\n",
            "        [-1.8743, -2.0687, -2.5087, -2.0177, -2.3487, -1.9626, -1.8220, -2.2241],\n",
            "        [-2.0594, -1.8093, -2.2861, -2.2179, -2.4211, -2.1493, -1.6971, -2.2109],\n",
            "        [-1.9625, -2.0844, -2.6343, -2.1893, -2.3860, -1.9543, -1.6309, -2.1043],\n",
            "        [-1.9568, -2.1433, -2.7643, -2.0971, -2.3089, -1.7128, -1.7501, -2.2819],\n",
            "        [-1.7600, -2.0421, -2.4727, -2.2498, -2.4433, -2.0133, -1.6221, -2.4020]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 6, 7, 6, 6, 5, 6, 6, 3, 4, 6, 7, 5, 7, 3, 6, 7, 7, 6, 0, 0, 4, 7, 4,\n",
            "        7, 2, 6, 5, 5, 7, 5, 7], device='cuda:0')\n",
            "tensor([[-2.0145, -1.8317, -2.3746, -2.2626, -2.2059, -2.1111, -1.7870, -2.2017],\n",
            "        [-1.8232, -2.1690, -2.3651, -2.0905, -2.1314, -1.9799, -1.9009, -2.2982],\n",
            "        [-1.8103, -2.1371, -2.4820, -2.1962, -2.0091, -1.9750, -1.9324, -2.2450],\n",
            "        [-1.9772, -2.3054, -2.7611, -1.9633, -2.2449, -1.5702, -1.7302, -2.7026],\n",
            "        [-2.0209, -2.2276, -2.3615, -2.0946, -2.2024, -2.1195, -1.7781, -1.9472],\n",
            "        [-1.6108, -2.4564, -2.6756, -2.0166, -2.1064, -1.7791, -2.0677, -2.3474],\n",
            "        [-1.8459, -2.3241, -2.3609, -2.1516, -2.0726, -1.9096, -1.7892, -2.3803],\n",
            "        [-1.7141, -2.2870, -2.7779, -1.9831, -2.1847, -1.9151, -1.8553, -2.2803],\n",
            "        [-1.7181, -2.6014, -2.5359, -2.0898, -2.0558, -2.0505, -1.9234, -1.9608],\n",
            "        [-1.8350, -2.3506, -2.4189, -2.1133, -2.1921, -1.8055, -1.8540, -2.2776],\n",
            "        [-1.7939, -2.3285, -2.2983, -2.0467, -2.2450, -1.9655, -2.0263, -2.0494],\n",
            "        [-1.9557, -2.1600, -2.3587, -1.9651, -2.2867, -1.7689, -1.9644, -2.3418],\n",
            "        [-1.9385, -2.1203, -2.5873, -1.8507, -2.0917, -1.9655, -1.9020, -2.3980],\n",
            "        [-1.9734, -2.0506, -2.7374, -2.0262, -2.4743, -1.6092, -1.6891, -2.7057],\n",
            "        [-1.6242, -2.2069, -2.6628, -2.1153, -2.1476, -1.8686, -1.9758, -2.3776],\n",
            "        [-1.9097, -2.4861, -2.7219, -1.9634, -2.1534, -1.6369, -1.7983, -2.4504],\n",
            "        [-1.7794, -2.4671, -2.4138, -2.1955, -2.0790, -1.9769, -1.8556, -2.0737],\n",
            "        [-1.8177, -2.3523, -2.5827, -1.9688, -2.0701, -1.8862, -1.8937, -2.3134],\n",
            "        [-2.0659, -2.0928, -2.7960, -1.9498, -2.2888, -1.5005, -1.8332, -2.7760],\n",
            "        [-1.9575, -2.6340, -2.4924, -1.9532, -2.0379, -1.8033, -1.8626, -2.1879],\n",
            "        [-1.9193, -2.2895, -2.5648, -2.1104, -2.0417, -2.1538, -1.7393, -2.0225],\n",
            "        [-2.0393, -2.2907, -2.7139, -1.9698, -2.3598, -1.4945, -1.7592, -2.6318],\n",
            "        [-2.2704, -1.9519, -2.5569, -2.0794, -2.3520, -1.5184, -1.6745, -2.9853],\n",
            "        [-1.9925, -2.0404, -2.3068, -2.2687, -2.0426, -2.1453, -1.8326, -2.0881],\n",
            "        [-1.7753, -2.2963, -2.7580, -1.9701, -1.9365, -1.9384, -1.9254, -2.3739],\n",
            "        [-1.9243, -2.3559, -2.6183, -2.0702, -2.1966, -1.9092, -1.7270, -2.0961],\n",
            "        [-1.8312, -2.4095, -2.6272, -2.1225, -2.2003, -1.8265, -1.7574, -2.1746],\n",
            "        [-1.8831, -2.3388, -2.8052, -1.8114, -2.1096, -1.7516, -1.9722, -2.3688],\n",
            "        [-1.9792, -2.4698, -2.4082, -1.9961, -2.1533, -1.8418, -1.7222, -2.3222],\n",
            "        [-1.9529, -2.4728, -2.6772, -1.9913, -1.8157, -2.0871, -1.7589, -2.2116],\n",
            "        [-1.8175, -2.4842, -2.5358, -1.9988, -2.0636, -1.9707, -1.9013, -2.0895],\n",
            "        [-1.7864, -2.3842, -2.4092, -2.1822, -1.9701, -1.9424, -1.9444, -2.1918]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([1, 6, 7, 3, 5, 6, 6, 7, 7, 7, 7, 6, 6, 5, 5, 6, 5, 3, 5, 5, 6, 5, 7, 1,\n",
            "        6, 7, 7, 5, 5, 7, 5, 6], device='cuda:0')\n",
            "tensor([[-1.9400, -2.4236, -2.6928, -1.8581, -1.9915, -1.7265, -1.9970, -2.3655],\n",
            "        [-2.0905, -2.2516, -2.5154, -2.0716, -1.9870, -2.1285, -1.8841, -1.8564],\n",
            "        [-1.9538, -2.0013, -2.6244, -2.1688, -2.0973, -1.9224, -1.8672, -2.1829],\n",
            "        [-2.0589, -2.2096, -2.4901, -2.1627, -1.7838, -2.0113, -1.8722, -2.2151],\n",
            "        [-1.8299, -2.2970, -2.4648, -2.1449, -2.1883, -1.8126, -1.8987, -2.1910],\n",
            "        [-1.7347, -2.4482, -2.4538, -2.0342, -2.0231, -1.9460, -2.0538, -2.1456],\n",
            "        [-1.9035, -2.2583, -2.2944, -2.1977, -1.8816, -2.0946, -1.9721, -2.1208],\n",
            "        [-1.7714, -2.1674, -2.5641, -2.0282, -1.9880, -1.9230, -2.0539, -2.3487],\n",
            "        [-1.8123, -2.4655, -2.7101, -1.9213, -2.0831, -1.7464, -1.9250, -2.3647],\n",
            "        [-2.0820, -2.5886, -2.3824, -2.0538, -2.0223, -1.8350, -1.9329, -1.9455],\n",
            "        [-2.0395, -2.5543, -2.4973, -1.7432, -1.9941, -1.8596, -2.0270, -2.1957],\n",
            "        [-1.9617, -2.4041, -2.8044, -1.8068, -2.1346, -1.4947, -2.0174, -2.6780],\n",
            "        [-1.7519, -2.3794, -2.5804, -2.0217, -2.2019, -1.8639, -1.8483, -2.2768],\n",
            "        [-2.0059, -2.4473, -2.7689, -1.8262, -1.8683, -1.7622, -2.0239, -2.3331],\n",
            "        [-1.7200, -2.6034, -2.4651, -2.1100, -2.0730, -1.7179, -2.0504, -2.2374],\n",
            "        [-1.8320, -2.3482, -2.5480, -2.0119, -2.0770, -1.8200, -1.9744, -2.2422],\n",
            "        [-1.8797, -2.2405, -2.4858, -2.0359, -2.0033, -2.0430, -2.0688, -1.9932]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([3, 0, 6, 7, 6, 6, 3, 1, 4, 6, 3, 6, 5, 6, 6, 7, 5], device='cuda:0')\n",
            "\n",
            "Evaluating...\n",
            "tensor(2.0542, device='cuda:0')\n",
            "tensor(2.0340, device='cuda:0')\n",
            "\n",
            "Training Loss: 2.166\n",
            "Validation Loss: 2.044\n",
            "\n",
            " Epoch 3 / 10\n",
            "tensor([[-1.8470, -2.4210, -2.3634, -1.9821, -1.7663, -2.0433, -2.2281, -2.1778],\n",
            "        [-1.8514, -2.2865, -2.6110, -1.9884, -2.1806, -1.7076, -1.8898, -2.4579],\n",
            "        [-1.9953, -2.3263, -2.9078, -1.7698, -2.0583, -1.6206, -1.9034, -2.7043],\n",
            "        [-2.0661, -2.2825, -2.3847, -2.0828, -1.7596, -2.0184, -2.0344, -2.1299],\n",
            "        [-1.7780, -2.4012, -2.6645, -1.9499, -1.7723, -2.0576, -2.1252, -2.1947],\n",
            "        [-2.1403, -2.1170, -2.5780, -1.8600, -1.9909, -1.9355, -1.9147, -2.2821],\n",
            "        [-1.9946, -2.3805, -2.7047, -1.7252, -2.2140, -1.6591, -1.9742, -2.4311],\n",
            "        [-2.0718, -2.4805, -2.5944, -1.9604, -1.8255, -1.7741, -1.9183, -2.3310],\n",
            "        [-2.2844, -1.8462, -2.7819, -1.8949, -2.1359, -1.6297, -1.8181, -2.9640],\n",
            "        [-2.1064, -2.3601, -2.6808, -1.6449, -2.1018, -1.6423, -1.9019, -2.8592],\n",
            "        [-1.9450, -2.2471, -2.3675, -1.8790, -2.0077, -2.0631, -2.0440, -2.1715],\n",
            "        [-1.9736, -2.2853, -2.4914, -1.7720, -1.7139, -2.3113, -2.1712, -2.1786],\n",
            "        [-2.0683, -2.3095, -2.4412, -1.9276, -1.8563, -2.2009, -1.8446, -2.1481],\n",
            "        [-1.9761, -2.4087, -2.5562, -1.8407, -1.8851, -1.8856, -2.0908, -2.2253],\n",
            "        [-2.2553, -2.6431, -2.4761, -1.6478, -2.1340, -1.7689, -1.8069, -2.3599],\n",
            "        [-1.8852, -2.4204, -2.6716, -1.8776, -1.7754, -2.1376, -2.0345, -2.1278],\n",
            "        [-2.1111, -2.5911, -2.5614, -1.6013, -1.5812, -2.2871, -2.2263, -2.2079],\n",
            "        [-2.4214, -2.3630, -2.8268, -1.5456, -2.2788, -1.4206, -1.8515, -3.1301],\n",
            "        [-2.0530, -2.5478, -2.3652, -1.8684, -1.5880, -2.1542, -2.2902, -2.0915],\n",
            "        [-1.9622, -2.0857, -2.5083, -2.0041, -2.2142, -1.7212, -1.9884, -2.3642],\n",
            "        [-1.8383, -2.4557, -2.5340, -2.0455, -2.0992, -1.9306, -1.8976, -2.0485],\n",
            "        [-1.9631, -2.4589, -2.3679, -1.8991, -1.6056, -2.3443, -2.1540, -2.1373],\n",
            "        [-1.9449, -2.2998, -2.6344, -1.8745, -2.1217, -1.5939, -2.0675, -2.5003],\n",
            "        [-1.8549, -2.5995, -2.7408, -1.7972, -2.0576, -1.6073, -2.0962, -2.4323],\n",
            "        [-1.9897, -2.2993, -2.4549, -2.0255, -1.9106, -2.0815, -1.9813, -2.0062],\n",
            "        [-1.8846, -2.0199, -2.6913, -1.9796, -2.0272, -1.7876, -2.1910, -2.3162],\n",
            "        [-2.1358, -2.3125, -2.9909, -1.6062, -2.1333, -1.5736, -1.8784, -2.9303],\n",
            "        [-2.1135, -2.0417, -2.3850, -1.9950, -1.9699, -2.0700, -2.0374, -2.0775],\n",
            "        [-2.0027, -1.9806, -2.6377, -1.8117, -2.3043, -1.7457, -1.9636, -2.5583],\n",
            "        [-1.9398, -2.4141, -2.6328, -1.6627, -1.9988, -1.8272, -2.1595, -2.3690],\n",
            "        [-1.9747, -2.5383, -2.6491, -1.7135, -1.9513, -1.8674, -2.0667, -2.2253],\n",
            "        [-2.1439, -2.6973, -2.4690, -1.7151, -2.0875, -1.4601, -2.0994, -2.6303]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([3, 7, 5, 7, 3, 6, 7, 0, 5, 3, 6, 0, 3, 5, 6, 6, 5, 5, 3, 6, 5, 7, 7, 5,\n",
            "        6, 6, 6, 1, 7, 0, 3, 5], device='cuda:0')\n",
            "tensor([[-2.0733, -2.1496, -2.7624, -1.6428, -2.2384, -1.6003, -2.1014, -2.6540],\n",
            "        [-2.0436, -2.1865, -2.5035, -1.6937, -1.8585, -2.0430, -2.2694, -2.2674],\n",
            "        [-2.0105, -2.4150, -2.5630, -1.5517, -2.0163, -1.9218, -2.1834, -2.3477],\n",
            "        [-1.9419, -2.6366, -2.5718, -1.6227, -1.8887, -2.0417, -2.0958, -2.2334],\n",
            "        [-2.1270, -2.8515, -2.7340, -1.5957, -2.3204, -1.5763, -1.8739, -2.3348],\n",
            "        [-1.9568, -2.2702, -2.6230, -1.8380, -1.5638, -2.0742, -2.2689, -2.4622],\n",
            "        [-2.1541, -2.7363, -2.6917, -1.6329, -2.1160, -1.7810, -1.7947, -2.2934],\n",
            "        [-2.0668, -2.5387, -2.6748, -1.6803, -1.8247, -2.1106, -2.0821, -2.0243],\n",
            "        [-2.0980, -2.4574, -2.5315, -1.5484, -2.0142, -2.0409, -2.1353, -2.1373],\n",
            "        [-2.0725, -2.4371, -2.7477, -1.5707, -2.0127, -1.7172, -2.1774, -2.4280],\n",
            "        [-2.0553, -2.0313, -2.5952, -1.9074, -1.9539, -2.0772, -2.0745, -2.0788],\n",
            "        [-2.1811, -2.3987, -2.5463, -1.5004, -1.8815, -2.1981, -2.2120, -2.1038],\n",
            "        [-1.9704, -2.2984, -2.7060, -1.7053, -2.0204, -1.9244, -1.9963, -2.3303],\n",
            "        [-2.1937, -2.3543, -2.4599, -1.7117, -2.2352, -1.6733, -1.9958, -2.3327],\n",
            "        [-1.9203, -2.4198, -2.6285, -1.6290, -2.0234, -1.8634, -2.1677, -2.3602],\n",
            "        [-1.9636, -2.1814, -2.5896, -1.7851, -1.8991, -2.0354, -2.1602, -2.2228],\n",
            "        [-2.1015, -2.2065, -2.5887, -1.6267, -1.8819, -2.0166, -2.0823, -2.4546],\n",
            "        [-2.0714, -2.4953, -2.6727, -1.5988, -2.2335, -1.5472, -2.0523, -2.6327],\n",
            "        [-1.9096, -2.3230, -2.6050, -1.6965, -1.9877, -1.9077, -2.0711, -2.4631],\n",
            "        [-2.0083, -2.4001, -2.7858, -1.6742, -1.9148, -1.9003, -2.0884, -2.2524],\n",
            "        [-2.9193, -1.8252, -2.8712, -2.4086, -2.0565, -1.5641, -1.3522, -3.1598],\n",
            "        [-2.2094, -2.1221, -2.5571, -1.5653, -1.8409, -2.1010, -2.2835, -2.2929],\n",
            "        [-2.0501, -2.5634, -2.8567, -1.5586, -1.9390, -1.8316, -2.1798, -2.2139],\n",
            "        [-2.1305, -2.0433, -2.6930, -1.7021, -1.8697, -2.0941, -2.2100, -2.1665],\n",
            "        [-2.1001, -2.4839, -2.6659, -1.5273, -1.7463, -2.1772, -2.3510, -2.0842],\n",
            "        [-2.0858, -2.4038, -2.6894, -1.5977, -2.2758, -1.6407, -1.9654, -2.5450],\n",
            "        [-1.9454, -2.0629, -2.7749, -1.6908, -1.9324, -1.9394, -2.2016, -2.4763],\n",
            "        [-2.1498, -2.5431, -2.4788, -1.5955, -1.9315, -1.9457, -2.0861, -2.2421],\n",
            "        [-2.1935, -2.1627, -2.4602, -1.6253, -2.2142, -1.7659, -2.0515, -2.4964],\n",
            "        [-1.9001, -2.3517, -2.5996, -1.6912, -1.8348, -1.9736, -2.2303, -2.4020],\n",
            "        [-1.9485, -2.4800, -2.5186, -1.6290, -1.7764, -2.0460, -2.1770, -2.4627],\n",
            "        [-1.9837, -2.5005, -2.8474, -1.5194, -1.9767, -1.9850, -2.0670, -2.2917]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 1, 6, 7, 7, 5, 7, 7, 7, 5, 2, 6, 0, 2, 6, 7, 6, 4, 7, 6, 6, 5, 6, 4,\n",
            "        3, 5, 5, 7, 3, 6, 6, 3], device='cuda:0')\n",
            "tensor([[-2.2656, -1.8235, -2.7347, -1.4888, -1.9178, -2.3519, -2.2835, -2.3009],\n",
            "        [-2.1105, -1.9375, -2.6878, -1.6335, -1.6546, -2.5840, -2.3524, -2.2099],\n",
            "        [-2.0845, -2.1552, -2.6363, -1.5485, -1.8528, -2.2713, -2.2170, -2.2382],\n",
            "        [-2.1723, -2.3912, -2.6053, -1.4836, -1.9072, -2.0712, -2.1595, -2.2637],\n",
            "        [-2.1711, -2.1194, -2.5100, -1.6615, -2.1911, -1.7392, -2.0184, -2.5981],\n",
            "        [-2.1288, -2.0971, -2.6430, -1.6983, -2.0583, -1.8435, -1.9656, -2.5500],\n",
            "        [-2.0575, -2.4404, -2.3286, -1.6429, -1.9609, -2.0302, -2.1022, -2.3024],\n",
            "        [-2.3520, -2.0900, -2.3641, -1.5123, -1.8234, -2.2835, -2.3095, -2.2635],\n",
            "        [-2.1964, -2.4502, -2.5044, -1.5223, -1.9088, -1.9098, -2.0217, -2.6066],\n",
            "        [-2.4278, -2.0937, -2.5836, -1.4140, -1.7104, -2.4584, -2.2475, -2.3243],\n",
            "        [-2.1574, -2.4406, -2.7354, -1.4464, -1.9226, -2.0250, -2.1444, -2.2863],\n",
            "        [-2.0053, -2.0028, -2.4079, -1.7742, -1.8913, -2.1164, -2.1177, -2.5366],\n",
            "        [-2.2693, -2.3328, -2.5946, -1.4059, -1.8004, -2.0387, -2.3151, -2.4584],\n",
            "        [-2.3419, -2.2272, -2.8227, -1.6246, -1.7034, -2.1394, -2.0086, -2.2478],\n",
            "        [-2.3162, -2.2744, -2.7039, -1.4496, -1.7308, -2.3575, -2.2174, -2.1525],\n",
            "        [-2.3250, -2.0641, -2.6117, -1.5161, -1.7244, -2.2323, -2.2687, -2.3720],\n",
            "        [-2.6507, -1.9294, -2.4353, -1.4863, -1.8861, -2.2490, -2.3059, -2.1755],\n",
            "        [-2.9577, -2.1067, -3.0361, -2.2512, -2.1440, -1.5992, -1.1883, -3.0130],\n",
            "        [-2.1215, -2.2528, -2.4752, -1.4936, -1.8704, -2.2576, -2.3161, -2.2163],\n",
            "        [-2.2948, -2.1550, -2.5957, -1.4713, -1.5711, -2.5089, -2.4243, -2.2889],\n",
            "        [-2.0615, -1.9943, -2.5601, -1.7339, -1.8967, -2.0190, -2.2458, -2.3639],\n",
            "        [-2.0775, -2.7501, -2.7741, -1.3186, -2.1381, -1.7310, -2.0826, -2.7915],\n",
            "        [-2.2633, -2.1880, -2.4990, -1.5431, -1.8112, -2.2014, -2.3640, -2.1218],\n",
            "        [-2.2690, -2.3483, -2.4357, -1.5796, -1.9960, -1.9141, -1.9958, -2.4279],\n",
            "        [-1.9899, -2.2237, -2.6889, -1.5526, -2.0490, -1.8919, -2.1379, -2.5527],\n",
            "        [-2.1557, -2.1072, -2.5276, -1.5385, -1.9034, -2.2275, -2.3634, -2.1448],\n",
            "        [-1.9776, -2.4073, -2.8323, -1.5098, -2.0192, -1.9796, -2.2013, -2.2057],\n",
            "        [-2.1664, -1.9601, -2.6540, -1.6662, -1.6775, -2.2513, -2.2695, -2.4105],\n",
            "        [-2.0419, -2.3966, -2.3975, -1.5993, -1.8923, -2.0568, -2.1376, -2.4114],\n",
            "        [-2.2896, -2.0863, -2.7597, -1.4620, -1.7749, -2.3535, -2.3436, -2.1292],\n",
            "        [-2.3840, -2.0247, -2.5753, -1.7507, -2.1294, -1.7042, -1.9344, -2.5174],\n",
            "        [-2.1128, -1.8158, -2.7495, -1.6565, -1.7935, -2.1694, -2.2724, -2.5522]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([0, 7, 7, 3, 6, 6, 0, 7, 4, 7, 5, 7, 5, 6, 2, 5, 5, 7, 6, 6, 6, 6, 5, 3,\n",
            "        0, 0, 3, 1, 6, 6, 0, 1], device='cuda:0')\n",
            "tensor([[-2.2167, -1.9078, -2.6775, -1.5319, -1.8569, -2.4175, -2.2837, -2.2022],\n",
            "        [-2.2673, -1.8676, -2.6302, -1.4429, -1.8971, -2.3415, -2.3245, -2.4124],\n",
            "        [-1.9175, -2.1588, -2.6472, -1.5733, -1.8936, -2.1979, -2.3287, -2.2987],\n",
            "        [-2.3622, -1.8136, -2.5919, -1.5992, -1.8920, -2.2788, -2.1868, -2.2993],\n",
            "        [-2.1791, -1.8260, -2.4487, -1.6569, -1.8432, -2.4522, -2.3022, -2.2614],\n",
            "        [-2.1454, -1.7694, -2.4044, -1.6968, -1.9437, -2.2768, -2.2955, -2.3809],\n",
            "        [-2.0591, -1.6965, -2.2583, -1.9445, -2.0622, -2.2044, -2.2550, -2.3111],\n",
            "        [-2.2462, -1.9186, -2.5179, -1.6390, -2.2244, -1.8157, -2.0459, -2.6248],\n",
            "        [-2.0753, -2.2245, -2.5671, -1.5130, -1.7696, -2.2564, -2.4834, -2.2003],\n",
            "        [-2.3600, -1.8656, -2.5190, -1.6682, -1.7355, -2.5646, -2.2481, -2.0974],\n",
            "        [-2.3763, -1.9302, -2.7127, -1.7486, -2.1903, -1.6508, -1.8621, -2.7726],\n",
            "        [-2.3016, -1.9098, -2.8044, -1.5985, -2.1032, -1.7494, -2.0025, -2.8455],\n",
            "        [-2.3806, -1.6404, -2.2932, -1.6638, -1.6854, -2.4677, -2.5054, -2.6390],\n",
            "        [-2.9432, -1.9821, -3.1913, -2.1924, -2.1211, -1.5103, -1.2721, -3.3316],\n",
            "        [-2.4028, -2.2233, -2.3298, -1.8584, -2.1949, -1.6604, -1.7373, -2.6506],\n",
            "        [-2.1436, -1.6715, -2.4289, -1.6918, -2.0311, -2.3599, -2.3917, -2.2502],\n",
            "        [-2.6437, -1.7260, -2.5409, -1.4947, -1.7082, -2.6004, -2.3044, -2.3799],\n",
            "        [-2.2836, -1.8063, -2.6363, -1.6421, -1.7723, -2.2887, -2.2328, -2.4075],\n",
            "        [-2.1226, -1.8761, -2.4822, -1.6185, -1.9390, -2.4161, -2.2928, -2.1962],\n",
            "        [-2.3882, -2.4319, -2.4637, -1.4161, -1.5787, -2.5343, -2.4569, -2.1096],\n",
            "        [-2.1968, -2.4423, -2.7999, -1.3958, -1.8956, -2.0999, -2.0963, -2.3246],\n",
            "        [-2.4641, -2.2219, -2.5257, -1.4485, -2.1757, -1.9336, -1.9950, -2.3286],\n",
            "        [-2.0547, -2.3601, -2.6745, -1.5052, -1.6461, -2.2277, -2.4540, -2.3025],\n",
            "        [-2.2212, -2.3113, -2.4046, -1.5353, -1.8719, -2.2227, -2.1763, -2.1973],\n",
            "        [-2.2150, -2.0108, -2.5921, -1.7040, -2.1800, -1.7186, -1.9871, -2.6491],\n",
            "        [-2.2654, -1.9351, -2.1276, -1.6570, -1.8730, -2.6398, -2.3013, -2.1474],\n",
            "        [-2.3906, -2.1385, -2.3314, -1.4861, -1.8923, -2.1668, -2.1232, -2.4978],\n",
            "        [-2.2039, -1.9341, -2.5042, -1.5878, -1.8600, -2.1863, -2.2584, -2.4484],\n",
            "        [-2.3324, -2.0862, -2.4468, -1.4404, -1.9856, -2.2979, -2.0718, -2.3896],\n",
            "        [-2.1763, -2.1981, -2.5822, -1.3966, -1.8775, -2.3175, -2.3053, -2.2899],\n",
            "        [-2.0638, -2.1590, -2.4910, -1.5163, -1.8201, -2.3054, -2.3363, -2.3348],\n",
            "        [-2.1645, -1.9417, -2.5007, -1.5396, -1.8596, -2.3125, -2.2651, -2.4457]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 7, 5, 4, 7, 6, 7, 5, 7, 7, 5, 6, 1, 3, 7, 7, 6, 6, 5, 7, 6, 7, 6, 5,\n",
            "        5, 7, 6, 0, 6, 0, 0, 6], device='cuda:0')\n",
            "tensor([[-2.1311, -1.5648, -2.5406, -1.8086, -2.2746, -2.1748, -2.1178, -2.3784],\n",
            "        [-2.1514, -2.2197, -2.5262, -1.4796, -2.0917, -2.0710, -2.0867, -2.3677],\n",
            "        [-2.1074, -2.2181, -2.5677, -1.4760, -1.9671, -2.2174, -2.3027, -2.1574],\n",
            "        [-2.1622, -1.5950, -2.6905, -1.7742, -1.8753, -2.2853, -2.1823, -2.5675],\n",
            "        [-2.2072, -1.5691, -2.2610, -1.7701, -1.9662, -2.5491, -2.3427, -2.3753],\n",
            "        [-2.2289, -2.0128, -2.3997, -1.5434, -1.9084, -2.3284, -2.3794, -2.1543],\n",
            "        [-2.1251, -2.0830, -2.5474, -1.5960, -2.0221, -2.1195, -2.1085, -2.2913],\n",
            "        [-2.1519, -1.6014, -2.5969, -1.7301, -2.1979, -2.2827, -2.2090, -2.2304],\n",
            "        [-2.3117, -1.8823, -2.3786, -1.7692, -2.0445, -2.2124, -2.1969, -1.9988],\n",
            "        [-2.0443, -2.3050, -2.7242, -1.5744, -1.9679, -1.9580, -2.0872, -2.3739],\n",
            "        [-2.1562, -2.1960, -2.4666, -1.5513, -1.9950, -2.1796, -2.0135, -2.3695],\n",
            "        [-2.1373, -2.1197, -2.3913, -1.5043, -1.9642, -2.2156, -2.3048, -2.3110],\n",
            "        [-2.1663, -1.7242, -2.4884, -1.6854, -1.8859, -2.4031, -2.3410, -2.2996],\n",
            "        [-2.2416, -1.5321, -2.4424, -1.7893, -1.9377, -2.6337, -2.3931, -2.1508],\n",
            "        [-1.9537, -2.2159, -2.4997, -1.7467, -2.0157, -2.0886, -2.0779, -2.2032],\n",
            "        [-2.2594, -1.7882, -2.3424, -1.8559, -1.8189, -2.6166, -2.2305, -2.0161],\n",
            "        [-2.2005, -2.0062, -2.3782, -1.5794, -2.1561, -2.2619, -2.2493, -2.0360],\n",
            "        [-2.2913, -1.7931, -2.5183, -1.5247, -1.8329, -2.5812, -2.4100, -2.2193],\n",
            "        [-2.2318, -2.3031, -2.4619, -1.4726, -2.0163, -2.1062, -2.1821, -2.2029],\n",
            "        [-2.2501, -1.7938, -2.5036, -1.5859, -1.5537, -2.7680, -2.5734, -2.3948],\n",
            "        [-3.7386, -1.9947, -4.0720, -2.6498, -2.8425, -1.4967, -0.8182, -3.5370],\n",
            "        [-2.3434, -2.1172, -2.4450, -1.6563, -1.8210, -2.2357, -2.0555, -2.2140],\n",
            "        [-2.0108, -2.1517, -2.6653, -1.6818, -2.0419, -1.8951, -1.9880, -2.5619],\n",
            "        [-2.2946, -2.1283, -2.6093, -1.5225, -1.8241, -2.3213, -2.2082, -2.1287],\n",
            "        [-2.2790, -1.7631, -2.5774, -1.5586, -1.7654, -2.5850, -2.3151, -2.3599],\n",
            "        [-2.1292, -1.8466, -2.6965, -1.6545, -1.8893, -2.6039, -2.2463, -2.0121],\n",
            "        [-2.2703, -1.8710, -2.4478, -1.8083, -1.8418, -2.2597, -2.0746, -2.2653],\n",
            "        [-2.2112, -1.7767, -2.3548, -1.7973, -1.8612, -2.5256, -2.2702, -2.1054],\n",
            "        [-2.2722, -1.8772, -2.4613, -1.5547, -1.9438, -2.3408, -2.1992, -2.3329],\n",
            "        [-2.1912, -2.2971, -2.4359, -1.4395, -2.0108, -2.3777, -2.1983, -2.0757],\n",
            "        [-2.2285, -1.7909, -2.2605, -1.7810, -1.8417, -2.4463, -2.3775, -2.1646],\n",
            "        [-2.1868, -1.5782, -2.3935, -1.7549, -1.8941, -2.4460, -2.3741, -2.4423]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 5, 0, 6, 5, 0, 4, 4, 5, 5, 5, 5, 5, 7, 7, 7, 5, 7, 6, 7, 6, 5, 5, 7,\n",
            "        6, 5, 5, 7, 7, 6, 4, 7], device='cuda:0')\n",
            "tensor([[-2.1779, -1.8942, -2.5096, -1.7070, -1.8422, -2.4180, -2.3967, -2.0025],\n",
            "        [-2.2287, -2.0136, -2.6664, -1.6848, -1.8931, -1.9845, -2.0777, -2.4017],\n",
            "        [-2.2346, -1.8224, -2.3451, -1.7782, -1.7216, -2.7347, -2.4364, -1.9998],\n",
            "        [-2.1051, -1.6127, -2.5277, -1.8908, -2.1359, -2.1325, -2.2209, -2.2746],\n",
            "        [-2.3373, -1.3492, -2.3593, -2.0049, -1.8408, -2.7209, -2.4345, -2.2762],\n",
            "        [-2.0191, -2.0760, -2.5996, -1.7140, -1.8948, -2.0407, -2.0982, -2.4727],\n",
            "        [-2.1784, -1.5866, -2.5083, -1.8757, -1.7844, -2.7748, -2.3249, -2.1249],\n",
            "        [-2.0623, -1.8148, -2.3896, -1.7162, -2.0186, -2.2775, -2.2367, -2.3395],\n",
            "        [-2.0540, -2.1243, -2.4466, -2.0269, -1.7128, -2.2948, -2.0331, -2.1049],\n",
            "        [-2.5338, -1.4455, -2.3244, -2.0055, -1.8237, -2.6620, -2.2849, -2.1238],\n",
            "        [-2.1990, -1.9210, -2.4839, -1.6884, -2.0608, -1.9876, -2.2172, -2.2918],\n",
            "        [-2.0773, -1.6888, -2.4121, -2.0376, -1.9680, -2.4284, -2.2079, -2.0236],\n",
            "        [-2.1219, -2.1702, -2.3541, -1.6907, -2.0041, -2.1620, -2.1799, -2.0896],\n",
            "        [-2.0825, -2.6320, -2.4134, -1.6121, -1.8820, -2.1784, -2.1603, -2.0123],\n",
            "        [-2.0704, -1.7399, -2.5225, -1.8722, -1.9899, -2.3293, -2.1902, -2.1343],\n",
            "        [-2.2094, -1.4460, -2.5084, -2.0367, -1.8017, -2.8168, -2.4131, -2.0517],\n",
            "        [-2.0555, -1.7235, -2.4953, -1.7902, -1.9252, -2.5100, -2.2961, -2.1510],\n",
            "        [-2.0921, -2.1526, -2.6156, -1.5388, -2.0035, -2.1332, -2.0595, -2.3884],\n",
            "        [-2.1464, -2.1755, -2.5473, -1.5851, -2.1775, -1.9423, -2.0245, -2.3272],\n",
            "        [-2.2395, -1.7945, -2.5611, -1.7712, -1.7846, -2.4567, -2.2934, -2.0760],\n",
            "        [-2.2259, -1.4722, -2.3958, -2.0692, -1.7938, -2.7447, -2.3683, -2.1121],\n",
            "        [-2.1752, -1.8118, -2.4021, -1.8220, -1.9533, -2.2543, -2.1581, -2.2206],\n",
            "        [-2.0634, -1.5812, -2.3152, -1.8793, -2.0009, -2.5328, -2.6130, -2.0569],\n",
            "        [-2.0532, -2.3089, -2.6682, -1.6456, -1.8494, -2.1168, -2.1931, -2.1144],\n",
            "        [-2.1932, -1.6489, -2.5976, -1.8294, -1.9012, -2.4340, -2.1815, -2.1958],\n",
            "        [-2.1708, -1.6233, -2.5580, -1.8392, -1.8243, -2.4216, -2.2929, -2.2908],\n",
            "        [-2.0944, -1.7774, -2.5981, -1.7992, -1.7722, -2.3458, -2.3309, -2.2540],\n",
            "        [-2.6558, -1.4821, -2.4737, -1.9842, -1.7285, -2.7703, -2.3545, -1.9262],\n",
            "        [-2.3719, -2.4382, -2.8668, -1.5377, -2.0215, -1.6363, -1.8920, -2.6636],\n",
            "        [-2.0922, -2.2436, -2.4556, -1.7393, -1.9475, -2.1688, -2.2077, -1.9508],\n",
            "        [-2.1304, -1.7848, -2.5926, -1.8172, -1.8579, -2.2796, -2.1934, -2.2424],\n",
            "        [-2.1800, -2.0155, -2.5092, -1.8677, -2.0048, -1.9920, -1.8897, -2.3469]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 5, 7, 7, 1, 6, 6, 0, 6, 7, 6, 0, 6, 7, 7, 3, 6, 5, 6, 6, 2, 0, 7, 6,\n",
            "        5, 4, 5, 4, 6, 6, 6, 6], device='cuda:0')\n",
            "tensor([[-2.2707, -2.3881, -2.6777, -1.5170, -2.2366, -1.7461, -1.8691, -2.5091],\n",
            "        [-2.2452, -1.9816, -2.2265, -1.9747, -1.8803, -2.6598, -2.1028, -1.8023],\n",
            "        [-1.8467, -1.7575, -2.7986, -2.0287, -2.0521, -2.4325, -2.0148, -2.0578],\n",
            "        [-2.0296, -2.0712, -2.6387, -1.7447, -1.8974, -2.1910, -2.0444, -2.2518],\n",
            "        [-2.0242, -2.3257, -2.4360, -1.7793, -2.0688, -1.9700, -1.9554, -2.2387],\n",
            "        [-2.9035, -1.8487, -2.8902, -2.1038, -2.3238, -1.7065, -1.3045, -2.8227],\n",
            "        [-2.1127, -1.6084, -2.6514, -2.1471, -1.7726, -2.4925, -2.1285, -2.1209],\n",
            "        [-2.0009, -2.0326, -2.4287, -1.9922, -1.8149, -2.2077, -2.1754, -2.0966],\n",
            "        [-2.1483, -1.7738, -2.6229, -1.9576, -1.5921, -2.6154, -2.4435, -1.9925],\n",
            "        [-2.1876, -2.3354, -2.5476, -1.7062, -1.9681, -1.9235, -1.8741, -2.3870],\n",
            "        [-1.8957, -2.0791, -2.5168, -1.9855, -2.0930, -2.0130, -2.1012, -2.0597],\n",
            "        [-2.1847, -2.3660, -2.4746, -1.6450, -1.9912, -1.9790, -1.9354, -2.3299],\n",
            "        [-2.3612, -1.4327, -2.4627, -2.2785, -1.7850, -2.3675, -2.0963, -2.3540],\n",
            "        [-2.1934, -1.9252, -2.4642, -1.8255, -2.2944, -1.7756, -2.0090, -2.3853],\n",
            "        [-2.2265, -1.5456, -2.5529, -1.9625, -1.7486, -2.6299, -2.3790, -2.1054],\n",
            "        [-2.0611, -1.8791, -2.4736, -2.0357, -1.8915, -2.2639, -2.0115, -2.1497],\n",
            "        [-2.3190, -2.2072, -2.2754, -1.7623, -1.7646, -2.3294, -1.8726, -2.3552],\n",
            "        [-2.0239, -2.0690, -2.4829, -1.9551, -1.8131, -2.3182, -2.0177, -2.1043],\n",
            "        [-2.1029, -1.8212, -2.6799, -1.8682, -1.8196, -2.1883, -1.9974, -2.4863],\n",
            "        [-2.3628, -1.1005, -2.4071, -2.5114, -1.6238, -3.1381, -2.5874, -2.4510],\n",
            "        [-2.0630, -1.7661, -2.3000, -2.0463, -2.1082, -2.4625, -1.9720, -2.0668],\n",
            "        [-1.8989, -2.0619, -2.7072, -1.8563, -1.6838, -2.3104, -2.1703, -2.2921],\n",
            "        [-2.2003, -1.8897, -2.6285, -1.9542, -1.5454, -2.4569, -2.1537, -2.2138],\n",
            "        [-1.9995, -1.9357, -2.4936, -1.9724, -1.8967, -2.2556, -2.1068, -2.1034],\n",
            "        [-2.1808, -1.6035, -2.4676, -1.9968, -1.7803, -2.5436, -2.3448, -2.1017],\n",
            "        [-2.1844, -2.4908, -2.7376, -1.6680, -2.0698, -1.7880, -1.8280, -2.3328],\n",
            "        [-2.0353, -1.7226, -2.3785, -2.2014, -1.8207, -2.4346, -2.2475, -2.0234],\n",
            "        [-2.1474, -1.6051, -2.3905, -2.2108, -1.6674, -2.8027, -2.4647, -1.9191],\n",
            "        [-2.1863, -1.5290, -2.4345, -2.2730, -1.7774, -2.6012, -2.2818, -2.0031],\n",
            "        [-2.3841, -1.8419, -2.6782, -1.8688, -2.2027, -1.7518, -1.7794, -2.6090],\n",
            "        [-1.9219, -1.8565, -2.5108, -2.1264, -1.8842, -2.4299, -2.1318, -1.9778],\n",
            "        [-2.1468, -2.1817, -2.4417, -1.8568, -1.9161, -2.1412, -1.9163, -2.1604]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 7, 3, 6, 5, 5, 7, 6, 7, 3, 7, 2, 5, 7, 3, 3, 3, 6, 1, 5, 6, 6, 6, 7,\n",
            "        5, 7, 7, 7, 7, 5, 0, 3], device='cuda:0')\n",
            "tensor([[-1.9324, -1.6254, -2.4730, -2.1182, -1.8791, -2.6143, -2.4216, -1.9729],\n",
            "        [-2.2675, -1.5007, -2.0914, -2.3358, -1.9007, -2.9506, -2.3263, -1.8723],\n",
            "        [-2.3186, -1.4414, -2.4354, -2.2463, -1.7178, -2.8934, -2.2865, -2.0012],\n",
            "        [-2.1102, -1.4096, -2.5305, -2.3853, -1.8953, -2.8262, -2.2950, -1.8800],\n",
            "        [-2.0032, -1.6019, -2.5574, -2.3204, -1.9806, -2.3125, -2.1276, -2.0271],\n",
            "        [-1.9220, -1.8325, -2.4433, -2.1113, -1.8857, -2.4234, -2.2206, -1.9890],\n",
            "        [-2.3834, -1.3631, -2.2991, -2.3543, -1.6163, -2.6862, -2.4288, -2.2862],\n",
            "        [-2.3494, -1.4794, -2.5156, -2.0941, -1.7909, -2.6188, -2.2765, -2.0368],\n",
            "        [-1.9895, -1.9588, -2.4142, -2.1257, -1.8400, -2.3502, -2.0397, -2.0467],\n",
            "        [-2.2991, -1.9962, -2.2914, -2.0119, -1.7484, -2.5245, -2.0972, -1.8840],\n",
            "        [-2.2196, -2.2470, -2.4040, -1.8267, -1.8621, -2.1245, -2.0096, -2.0757],\n",
            "        [-2.0731, -2.2504, -2.3441, -1.8817, -1.9536, -2.1019, -1.9330, -2.1904],\n",
            "        [-2.0876, -1.7204, -2.4073, -2.2969, -1.7230, -2.5925, -2.1263, -2.0116],\n",
            "        [-2.1813, -1.6357, -2.3326, -2.2177, -1.5829, -2.8909, -2.4135, -1.9953],\n",
            "        [-2.3514, -1.4298, -2.5002, -2.3842, -1.6619, -2.6812, -2.3485, -1.9849],\n",
            "        [-2.0531, -2.0194, -2.4207, -2.0461, -1.8412, -2.2268, -2.1182, -2.0093],\n",
            "        [-2.1350, -1.5628, -2.5139, -2.1753, -1.7206, -2.8162, -2.3734, -1.9261],\n",
            "        [-2.1923, -1.5034, -2.5192, -2.2675, -1.6225, -2.7680, -2.3281, -2.0859],\n",
            "        [-2.0788, -1.7427, -2.4720, -2.2112, -1.6157, -2.7807, -2.2380, -1.9771],\n",
            "        [-2.5202, -1.9517, -2.6674, -1.9252, -2.2600, -1.6583, -1.6728, -2.5293],\n",
            "        [-2.3072, -1.6759, -2.2586, -2.3133, -1.7200, -2.8076, -2.2115, -1.8267],\n",
            "        [-2.0223, -2.1382, -2.3455, -2.0280, -1.8442, -2.3847, -2.0341, -1.9568],\n",
            "        [-2.0269, -1.9119, -2.3877, -2.0828, -1.9522, -2.4098, -2.1881, -1.8318],\n",
            "        [-2.0508, -1.9476, -2.4192, -1.9142, -1.8812, -2.2958, -2.1342, -2.1129],\n",
            "        [-2.0779, -2.1192, -2.3179, -2.0458, -1.9923, -2.1595, -1.9590, -2.0087],\n",
            "        [-2.1391, -1.9503, -2.2194, -2.0477, -1.7711, -2.5849, -2.1871, -1.9343],\n",
            "        [-2.0540, -1.6309, -2.4200, -2.2042, -1.8780, -2.5734, -2.1464, -2.0350],\n",
            "        [-2.0900, -1.7933, -2.2743, -2.1679, -1.7306, -2.7422, -2.3166, -1.8811],\n",
            "        [-2.2664, -1.9347, -2.5046, -1.9223, -2.2407, -1.8057, -1.8564, -2.3343],\n",
            "        [-2.0138, -2.1583, -2.3982, -1.8731, -1.9813, -2.0901, -2.0410, -2.1628],\n",
            "        [-2.1735, -2.1123, -2.4795, -1.8719, -2.1544, -1.8683, -1.8748, -2.2642],\n",
            "        [-2.3294, -1.4677, -2.2906, -2.3301, -1.7962, -2.5388, -2.2124, -2.1255]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 7, 4, 7, 7, 5, 5, 5, 6, 7, 5, 7, 7, 5, 1, 7, 5, 6, 0, 6, 2, 3, 7, 6,\n",
            "        5, 5, 5, 3, 5, 6, 3, 7], device='cuda:0')\n",
            "tensor([[-1.9899, -1.9445, -2.3712, -2.1682, -2.0365, -2.2015, -2.0791, -1.9219],\n",
            "        [-2.5528, -1.1441, -2.2287, -2.6627, -1.8895, -2.9699, -2.5559, -1.9232],\n",
            "        [-2.2180, -1.6484, -2.2841, -2.3255, -1.9912, -2.4363, -2.0983, -1.8803],\n",
            "        [-2.5077, -1.3821, -2.1187, -2.6109, -1.8072, -3.0469, -2.5080, -1.7104],\n",
            "        [-2.0348, -1.8089, -2.3913, -2.1712, -2.0141, -2.2855, -2.0772, -1.9699],\n",
            "        [-2.1106, -1.6745, -2.3304, -2.3366, -1.8953, -2.5617, -2.2767, -1.7870],\n",
            "        [-2.2961, -1.9591, -2.1578, -2.1672, -1.9717, -2.3773, -2.0822, -1.7625],\n",
            "        [-1.9695, -1.7757, -2.4090, -2.1317, -2.0909, -2.2043, -2.1562, -2.0181],\n",
            "        [-2.1396, -1.4550, -2.4768, -2.4530, -1.9999, -2.3215, -2.1756, -2.0261],\n",
            "        [-2.5361, -1.4560, -2.0244, -2.4779, -1.6736, -2.8584, -2.2480, -2.1111],\n",
            "        [-2.1612, -2.1801, -2.4912, -1.9024, -1.7916, -2.1692, -2.1004, -1.9923],\n",
            "        [-2.4705, -1.6059, -2.1391, -2.5032, -1.9235, -2.7805, -2.2345, -1.6093],\n",
            "        [-2.3014, -2.3802, -2.5268, -1.6763, -2.1841, -1.8151, -1.8359, -2.2491],\n",
            "        [-2.0184, -1.8102, -2.2505, -2.0010, -1.7424, -2.5630, -2.3289, -2.1769],\n",
            "        [-1.9681, -2.1641, -2.4280, -2.0053, -1.7910, -2.2606, -2.1231, -2.0260],\n",
            "        [-2.1457, -1.8036, -2.2408, -2.3006, -1.9454, -2.3836, -2.2374, -1.7728],\n",
            "        [-2.0747, -1.8323, -2.3411, -2.1604, -1.8470, -2.6572, -2.1312, -1.8558]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 4, 5, 5, 7, 6, 0, 2, 6, 6, 6, 2, 6, 2, 6, 5, 0], device='cuda:0')\n",
            "\n",
            "Evaluating...\n",
            "tensor(2.0908, device='cuda:0')\n",
            "tensor(1.9735, device='cuda:0')\n",
            "\n",
            "Training Loss: 2.068\n",
            "Validation Loss: 2.032\n",
            "\n",
            " Epoch 4 / 10\n",
            "tensor([[-2.2041, -1.5806, -1.8924, -2.5097, -1.8727, -2.5313, -2.4358, -2.0326],\n",
            "        [-2.2215, -1.9754, -2.2946, -2.2351, -2.1067, -2.1624, -1.8257, -1.9154],\n",
            "        [-2.3713, -1.5423, -2.1506, -2.6652, -1.8600, -2.4457, -2.3638, -1.7699],\n",
            "        [-2.2060, -1.8537, -2.3075, -2.1451, -1.8478, -2.2869, -2.1942, -1.9240],\n",
            "        [-2.3024, -1.4815, -2.1721, -2.6107, -1.7318, -2.8196, -2.5749, -1.7572],\n",
            "        [-2.4127, -2.5897, -2.3970, -1.7141, -2.3832, -1.7190, -1.7080, -2.1935],\n",
            "        [-2.2846, -1.9737, -2.1749, -2.3493, -1.9796, -2.3380, -2.1431, -1.6183],\n",
            "        [-2.2010, -1.6094, -2.0776, -2.6278, -1.9157, -2.4688, -2.1701, -1.9259],\n",
            "        [-2.4234, -1.6234, -2.2533, -2.1817, -1.8040, -2.4621, -2.3272, -1.9053],\n",
            "        [-2.0885, -1.7303, -2.2131, -2.4118, -1.9516, -2.4010, -2.2043, -1.8523],\n",
            "        [-2.4447, -2.7833, -2.2615, -1.5833, -2.3331, -1.7499, -1.8887, -2.1212],\n",
            "        [-2.3343, -2.1018, -2.2138, -2.2526, -1.8404, -2.3009, -2.1676, -1.6445],\n",
            "        [-2.1757, -1.9108, -2.0790, -2.3326, -1.8546, -2.3714, -2.4034, -1.7365],\n",
            "        [-2.5152, -1.2445, -2.1127, -2.6252, -1.9404, -2.7829, -2.4096, -1.9492],\n",
            "        [-2.4355, -1.7611, -2.1629, -2.4221, -1.9187, -2.3824, -2.2659, -1.6398],\n",
            "        [-2.0692, -1.9417, -2.3281, -2.1734, -2.0843, -2.3135, -2.0861, -1.7631],\n",
            "        [-2.1096, -2.4465, -2.6818, -1.7563, -2.2051, -1.9128, -1.7033, -2.1982],\n",
            "        [-2.3556, -2.7637, -2.1811, -1.7337, -2.3399, -1.9742, -1.7519, -1.9386],\n",
            "        [-2.2943, -1.5583, -2.1172, -2.4807, -1.9441, -2.4454, -2.3924, -1.8116],\n",
            "        [-2.3930, -1.2036, -2.2760, -2.5965, -1.9231, -2.7985, -2.4996, -1.9509],\n",
            "        [-2.2993, -1.6036, -2.1780, -2.3460, -2.0738, -2.2123, -2.1269, -2.0016],\n",
            "        [-2.0613, -2.3693, -2.2883, -2.0153, -1.8910, -2.2821, -2.2784, -1.6660],\n",
            "        [-2.1961, -2.1267, -2.1279, -2.0793, -2.1572, -2.0273, -2.0739, -1.8813],\n",
            "        [-2.0649, -2.1478, -2.2023, -2.0875, -2.0999, -1.9140, -2.0972, -2.0470],\n",
            "        [-2.5031, -1.3940, -1.9918, -2.5407, -2.0987, -2.8358, -2.4992, -1.6533],\n",
            "        [-2.3022, -2.2910, -2.1320, -2.0424, -2.0942, -2.0582, -1.8314, -1.9702],\n",
            "        [-2.5091, -2.6859, -2.5006, -1.5441, -2.2966, -1.6696, -1.7321, -2.4176],\n",
            "        [-2.4998, -1.5886, -2.0942, -2.5325, -2.0451, -2.3804, -2.0959, -1.7944],\n",
            "        [-2.1440, -2.0275, -2.1245, -2.3483, -2.0253, -2.3612, -2.1012, -1.6737],\n",
            "        [-2.1669, -1.6654, -2.1379, -2.2586, -1.9533, -2.3405, -2.2685, -2.0217],\n",
            "        [-2.1767, -1.9561, -2.2681, -2.2178, -1.8198, -2.4988, -2.2756, -1.6829],\n",
            "        [-2.1694, -1.7932, -2.2406, -2.3908, -1.9962, -2.2134, -2.1206, -1.8564]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([3, 7, 6, 5, 5, 7, 5, 7, 6, 7, 5, 7, 7, 1, 6, 0, 6, 7, 6, 1, 5, 7, 3, 5,\n",
            "        7, 7, 6, 7, 0, 5, 6, 7], device='cuda:0')\n",
            "tensor([[-2.1888, -2.0156, -1.9088, -2.4816, -2.1912, -2.2277, -2.2837, -1.6027],\n",
            "        [-2.0688, -1.9742, -2.0507, -2.5311, -2.1891, -2.2227, -2.3259, -1.5675],\n",
            "        [-2.2845, -2.3440, -2.3079, -1.9893, -2.4032, -1.7268, -1.7364, -2.1076],\n",
            "        [-2.1929, -1.5376, -1.9271, -2.6376, -2.2122, -2.2576, -2.4311, -1.8681],\n",
            "        [-2.1376, -1.7765, -2.1011, -2.4285, -2.1159, -2.2359, -2.3324, -1.7267],\n",
            "        [-1.9994, -2.2041, -2.2312, -2.2922, -2.1772, -2.1374, -2.0701, -1.6697],\n",
            "        [-1.8806, -2.1611, -2.2909, -2.0288, -2.1374, -2.2331, -2.1411, -1.8518],\n",
            "        [-2.1753, -1.5573, -2.2004, -2.4875, -2.0427, -2.5022, -2.2284, -1.8167],\n",
            "        [-2.4113, -2.8497, -2.2646, -1.6213, -2.3741, -1.6631, -1.8263, -2.2325],\n",
            "        [-2.1360, -2.0295, -2.0647, -2.2417, -2.1631, -2.1516, -2.1274, -1.7903],\n",
            "        [-2.3872, -1.5725, -2.0053, -2.5539, -2.3145, -2.1963, -2.4518, -1.6501],\n",
            "        [-2.1327, -2.1917, -2.3299, -2.1094, -2.2241, -1.8646, -1.9675, -1.9091],\n",
            "        [-2.2486, -2.4977, -2.2116, -2.0917, -2.1521, -1.7990, -1.7465, -2.0948],\n",
            "        [-2.2404, -2.0378, -2.0866, -2.2257, -2.0071, -2.2688, -2.1534, -1.7302],\n",
            "        [-2.2955, -2.4225, -2.0228, -2.0081, -2.3571, -1.8592, -1.9060, -1.9318],\n",
            "        [-2.1137, -2.7943, -2.2388, -1.9620, -2.2259, -1.9358, -2.0364, -1.6707],\n",
            "        [-2.2648, -2.2852, -2.0938, -2.0507, -2.3503, -1.8472, -1.8939, -1.9730],\n",
            "        [-2.3192, -2.7600, -2.2867, -1.8707, -2.1950, -1.8244, -1.6718, -2.1023],\n",
            "        [-2.2367, -2.3646, -2.1377, -2.0335, -2.3350, -1.8342, -1.8599, -1.9795],\n",
            "        [-2.0695, -2.1846, -2.1998, -2.2453, -2.2746, -2.0896, -2.0810, -1.6443],\n",
            "        [-2.2425, -1.8247, -2.0805, -2.3376, -2.1717, -2.2267, -2.2178, -1.7125],\n",
            "        [-2.0928, -1.8818, -2.1947, -2.4883, -2.1826, -2.5247, -2.2810, -1.4486],\n",
            "        [-1.9929, -1.8590, -2.3063, -2.2073, -2.1168, -2.2169, -2.2126, -1.8359],\n",
            "        [-2.2066, -1.9163, -2.2818, -2.2165, -1.9918, -2.1399, -2.1211, -1.8473],\n",
            "        [-2.2852, -2.1610, -1.9678, -2.2654, -2.0818, -2.1829, -2.0948, -1.7206],\n",
            "        [-2.3102, -2.1917, -2.0401, -2.2423, -2.1971, -1.9785, -1.9897, -1.7917],\n",
            "        [-2.1339, -2.4587, -2.2734, -2.0837, -1.8927, -1.9550, -2.1046, -1.8675],\n",
            "        [-2.3271, -1.6424, -2.0192, -2.3392, -1.9649, -2.4339, -2.4805, -1.7828],\n",
            "        [-2.2885, -1.6336, -1.8341, -2.7451, -2.2775, -2.5660, -2.4356, -1.5491],\n",
            "        [-2.3093, -2.4371, -1.8663, -2.2154, -2.1142, -2.0949, -2.0568, -1.7271],\n",
            "        [-2.2555, -1.9577, -2.0060, -2.4090, -2.0559, -2.2821, -2.1850, -1.6764],\n",
            "        [-2.2145, -2.3823, -1.9359, -2.3150, -2.2562, -2.2133, -2.0868, -1.5269]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 7, 5, 7, 7, 7, 7, 6, 5, 6, 5, 5, 5, 4, 7, 6, 5, 6, 4, 5, 3, 0, 6, 6,\n",
            "        5, 5, 5, 5, 6, 6, 6, 6], device='cuda:0')\n",
            "tensor([[-2.1238, -2.7993, -2.1091, -2.0357, -2.0765, -1.9672, -1.9939, -1.7943],\n",
            "        [-2.4631, -1.9212, -1.8489, -2.4860, -2.1520, -2.2816, -2.4350, -1.5061],\n",
            "        [-2.2143, -2.2114, -2.0897, -2.3551, -2.2286, -2.1174, -2.2606, -1.4684],\n",
            "        [-2.1970, -2.3383, -1.7779, -2.4417, -2.2537, -2.0644, -2.1707, -1.6587],\n",
            "        [-2.6111, -1.9437, -1.9460, -2.4817, -2.0520, -2.1229, -2.1398, -1.6551],\n",
            "        [-2.6202, -2.1044, -2.0178, -2.1191, -2.4079, -1.7919, -1.9269, -1.8974],\n",
            "        [-2.2340, -2.4115, -2.0336, -2.0987, -2.0815, -1.8829, -2.1756, -1.8368],\n",
            "        [-2.4335, -2.7577, -2.2077, -1.8809, -2.3499, -1.6607, -1.8751, -1.9125],\n",
            "        [-2.1501, -2.1795, -2.2031, -2.2476, -2.2023, -2.1082, -2.0185, -1.6637],\n",
            "        [-2.3681, -1.9889, -2.0021, -2.6697, -2.1305, -2.2288, -2.3161, -1.4268],\n",
            "        [-2.4018, -2.0559, -1.9445, -2.6277, -2.3276, -1.9651, -2.1199, -1.5680],\n",
            "        [-2.4515, -1.8464, -2.0668, -2.4124, -2.1771, -1.8924, -2.0019, -1.9612],\n",
            "        [-2.3535, -1.9623, -2.1777, -2.3879, -2.0871, -2.0783, -2.1561, -1.6381],\n",
            "        [-2.5777, -1.8852, -1.8248, -2.8335, -2.0135, -2.0847, -2.2477, -1.6677],\n",
            "        [-2.0177, -2.0593, -2.2468, -2.4375, -2.1348, -1.9105, -2.2540, -1.7422],\n",
            "        [-2.5294, -2.0934, -2.3970, -1.9747, -2.3730, -1.6931, -1.7287, -2.1842],\n",
            "        [-2.3724, -1.7216, -2.0163, -2.4580, -2.1480, -2.1260, -2.2665, -1.7749],\n",
            "        [-2.4641, -3.0318, -2.2364, -1.7635, -2.4201, -1.6733, -1.6822, -2.0721],\n",
            "        [-2.7714, -1.7769, -1.9009, -2.4655, -1.9491, -2.2670, -2.2260, -1.7155],\n",
            "        [-2.4894, -2.8031, -2.1232, -2.1571, -2.3197, -1.9258, -1.6744, -1.6627],\n",
            "        [-2.2286, -1.9361, -2.0549, -2.5281, -2.2403, -2.1714, -2.2523, -1.5393],\n",
            "        [-2.6643, -1.5443, -1.8117, -2.6874, -2.2787, -2.2375, -2.3604, -1.7041],\n",
            "        [-2.3223, -2.1923, -2.3072, -2.2826, -2.2069, -1.8200, -1.8952, -1.7935],\n",
            "        [-2.1401, -2.4613, -2.2309, -2.1174, -2.1912, -1.8901, -1.8609, -1.8913],\n",
            "        [-2.3706, -1.8275, -2.1825, -2.4849, -2.2383, -2.1117, -2.2274, -1.5409],\n",
            "        [-2.4287, -2.1761, -2.2128, -1.9616, -2.3750, -1.7483, -1.9531, -1.9702],\n",
            "        [-2.7695, -2.7878, -2.4831, -1.5164, -2.4947, -1.5266, -1.6675, -2.4740],\n",
            "        [-2.4128, -1.8830, -2.0541, -2.3267, -2.3930, -1.9853, -2.0030, -1.7787],\n",
            "        [-2.2045, -2.3042, -2.1490, -2.1757, -2.2165, -1.8920, -2.1566, -1.6914],\n",
            "        [-2.3751, -2.1287, -2.1574, -2.3299, -2.2573, -2.0937, -2.2433, -1.4225],\n",
            "        [-2.5968, -2.2161, -1.9015, -2.3816, -2.0258, -2.1044, -2.1553, -1.5845],\n",
            "        [-2.3094, -2.1098, -2.0300, -2.2751, -2.0270, -1.8957, -2.1854, -1.8910]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 7, 7, 7, 7, 5, 5, 5, 0, 2, 5, 6, 4, 6, 6, 5, 1, 3, 7, 3, 6, 7, 7, 5,\n",
            "        5, 5, 6, 6, 2, 0, 0, 5], device='cuda:0')\n",
            "tensor([[-2.4026, -2.6870, -2.2773, -2.2891, -2.3684, -1.5459, -1.7945, -1.8045],\n",
            "        [-2.2917, -2.3047, -1.8232, -2.4439, -2.4421, -1.9258, -2.1389, -1.6081],\n",
            "        [-2.3782, -1.8505, -1.8201, -2.6607, -2.0577, -2.0183, -2.2095, -1.9116],\n",
            "        [-2.3758, -2.2122, -1.7351, -2.8205, -2.3131, -1.9347, -2.1459, -1.6032],\n",
            "        [-2.4197, -1.9704, -1.7207, -2.7913, -2.3588, -2.1051, -2.4469, -1.4764],\n",
            "        [-2.1659, -2.8941, -2.1823, -1.8946, -2.1478, -1.6867, -2.0914, -1.9557],\n",
            "        [-2.3108, -1.8272, -1.8752, -2.7246, -2.2809, -2.1182, -2.4498, -1.5498],\n",
            "        [-2.3726, -2.1251, -1.7846, -2.6420, -2.3970, -1.9768, -2.4121, -1.4735],\n",
            "        [-2.0537, -2.5813, -2.2393, -2.1820, -2.1867, -1.8649, -2.0593, -1.7040],\n",
            "        [-2.4007, -1.9848, -1.8138, -2.6285, -2.3624, -1.9202, -2.2175, -1.6762],\n",
            "        [-1.9863, -1.9523, -2.1301, -2.5622, -2.1119, -2.0053, -2.2870, -1.7857],\n",
            "        [-2.1079, -2.3770, -1.8349, -2.4831, -2.3408, -1.8937, -2.2858, -1.6393],\n",
            "        [-1.9557, -2.4827, -1.8795, -2.3570, -2.3424, -1.9582, -2.2556, -1.6839],\n",
            "        [-2.4393, -2.2585, -1.7777, -2.5718, -2.3127, -1.9781, -2.1379, -1.5721],\n",
            "        [-2.5610, -2.4245, -1.9570, -2.1898, -2.2829, -1.7893, -1.9017, -1.8162],\n",
            "        [-2.1969, -2.4565, -2.0022, -2.2717, -2.4031, -1.7699, -2.1128, -1.6968],\n",
            "        [-2.4617, -2.4463, -2.2176, -2.1105, -2.4745, -1.5456, -1.8578, -1.9334],\n",
            "        [-2.1989, -2.6141, -2.1800, -2.0933, -2.2076, -1.7139, -2.0696, -1.8130],\n",
            "        [-2.8837, -2.0776, -2.4242, -2.0390, -2.5412, -1.4948, -1.5648, -2.4310],\n",
            "        [-2.3481, -2.0235, -1.7125, -2.6665, -2.4352, -1.8470, -2.2269, -1.7767],\n",
            "        [-2.2066, -2.0678, -1.9271, -2.4566, -2.1399, -2.0026, -2.3064, -1.7153],\n",
            "        [-2.5634, -1.9327, -1.7747, -2.6557, -2.2746, -2.0962, -2.1462, -1.6309],\n",
            "        [-2.0566, -2.3269, -2.0569, -2.4028, -2.2660, -1.8085, -2.0846, -1.8066],\n",
            "        [-2.4502, -1.5607, -1.7454, -2.9839, -2.3423, -2.0572, -2.3504, -1.8369],\n",
            "        [-2.4109, -2.5849, -1.6880, -2.4317, -2.5137, -1.8320, -2.0223, -1.6677],\n",
            "        [-2.3631, -2.3380, -1.8177, -2.5399, -2.2693, -2.1021, -2.2133, -1.4560],\n",
            "        [-2.7778, -2.7152, -2.2436, -1.8108, -2.6008, -1.5385, -1.7148, -2.0165],\n",
            "        [-3.2532, -3.0352, -2.7385, -1.5137, -2.7909, -1.4064, -1.3981, -2.5894],\n",
            "        [-2.7039, -1.6078, -1.6889, -2.8261, -2.3197, -2.1687, -2.4379, -1.6672],\n",
            "        [-2.6358, -2.3609, -1.8937, -2.5098, -2.1778, -1.7765, -1.8289, -1.8382],\n",
            "        [-2.2281, -2.2144, -1.9157, -2.4630, -2.3312, -1.9595, -2.0660, -1.6829],\n",
            "        [-2.3760, -1.8766, -1.6480, -2.7267, -2.2969, -2.1223, -2.3134, -1.7324]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 6, 3, 6, 2, 0, 5, 7, 6, 6, 7, 3, 0, 7, 6, 7, 5, 6, 5, 7, 6, 4, 7, 1,\n",
            "        4, 7, 5, 6, 6, 6, 3, 0], device='cuda:0')\n",
            "tensor([[-2.5709, -2.2900, -1.9516, -2.2082, -2.3209, -1.6340, -1.9658, -1.9881],\n",
            "        [-2.2548, -2.0513, -1.6856, -2.8108, -2.3087, -1.9032, -2.3229, -1.7454],\n",
            "        [-2.1368, -2.1346, -1.9058, -2.7415, -2.1479, -1.9360, -2.1966, -1.7242],\n",
            "        [-2.6127, -3.0435, -2.4988, -1.8842, -2.4727, -1.4265, -1.6223, -2.0963],\n",
            "        [-2.2209, -2.0516, -1.9178, -2.7248, -2.2573, -1.9666, -2.2414, -1.6115],\n",
            "        [-2.3810, -1.7129, -1.9136, -2.7949, -2.1995, -2.0884, -2.0678, -1.8494],\n",
            "        [-2.1236, -2.3221, -1.9021, -2.5289, -2.5262, -1.7445, -2.0234, -1.7932],\n",
            "        [-2.3254, -2.1642, -1.9355, -2.5644, -2.3013, -1.8574, -1.9165, -1.8154],\n",
            "        [-2.1250, -2.4497, -1.7213, -2.5088, -2.5045, -1.8410, -2.1147, -1.7545],\n",
            "        [-2.3623, -2.4696, -1.7871, -2.2479, -2.3645, -1.6806, -2.0857, -1.9405],\n",
            "        [-2.4580, -1.7358, -1.8801, -2.5862, -1.8916, -2.2150, -2.6770, -1.7065],\n",
            "        [-2.2554, -1.8763, -1.7223, -2.9785, -2.3153, -2.1187, -2.2891, -1.6492],\n",
            "        [-2.0959, -2.3477, -1.7670, -2.6107, -2.3657, -1.8537, -2.1252, -1.7886],\n",
            "        [-2.0990, -2.3600, -2.0221, -2.1499, -2.1175, -1.9354, -2.2842, -1.7863],\n",
            "        [-2.1214, -2.2961, -1.7019, -2.4366, -2.4278, -1.8402, -2.2700, -1.8366],\n",
            "        [-2.2751, -2.0551, -1.6897, -2.4383, -2.2820, -2.1472, -2.1158, -1.8462],\n",
            "        [-2.5978, -1.6649, -1.4416, -3.1795, -2.3443, -2.2470, -2.5831, -1.7090],\n",
            "        [-2.3579, -2.4455, -2.0167, -2.4378, -2.3993, -1.5599, -2.0096, -1.8124],\n",
            "        [-2.1132, -2.3717, -1.6946, -2.5617, -2.2013, -1.8991, -2.1391, -1.9183],\n",
            "        [-2.1626, -2.0356, -1.6893, -2.7718, -2.2529, -1.8640, -2.1786, -2.0112],\n",
            "        [-2.2505, -2.4035, -1.7396, -2.4904, -2.2588, -1.9210, -2.1726, -1.7094],\n",
            "        [-2.2639, -2.5800, -1.8515, -2.3300, -2.3575, -1.6656, -2.0017, -1.9163],\n",
            "        [-2.1982, -2.4239, -1.8395, -2.4421, -2.2231, -1.8555, -2.0865, -1.7971],\n",
            "        [-2.3354, -2.2381, -1.7472, -2.5070, -2.1672, -1.8819, -2.1634, -1.8385],\n",
            "        [-2.2351, -1.7074, -1.8373, -2.6652, -2.2321, -2.1635, -2.1901, -1.9057],\n",
            "        [-2.3140, -2.1631, -1.7268, -2.7029, -2.3229, -1.8495, -2.0991, -1.8114],\n",
            "        [-2.1720, -2.1553, -1.6131, -2.7801, -2.3225, -1.9582, -2.2984, -1.7759],\n",
            "        [-2.5310, -2.9412, -2.1366, -1.8502, -2.4353, -1.4247, -1.8926, -2.1758],\n",
            "        [-2.3023, -2.7872, -2.0216, -2.0888, -2.4362, -1.5114, -2.0543, -1.9255],\n",
            "        [-2.1411, -2.5239, -1.8974, -2.2520, -2.3308, -1.7523, -1.9922, -1.9647],\n",
            "        [-2.2689, -2.7390, -2.2893, -2.0632, -2.2373, -1.5084, -1.9024, -2.0688],\n",
            "        [-2.2660, -2.6915, -1.8211, -2.1805, -2.3905, -1.7509, -2.0937, -1.8005]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 1, 5, 5, 0, 1, 7, 6, 2, 5, 5, 5, 6, 6, 7, 7, 7, 5, 0, 7, 7, 6, 5, 7,\n",
            "        4, 7, 7, 5, 7, 3, 6, 0], device='cuda:0')\n",
            "tensor([[-1.8784, -2.4084, -2.0504, -2.5393, -2.1970, -1.8728, -2.1342, -1.7931],\n",
            "        [-2.5177, -2.6702, -1.8933, -2.1420, -2.3259, -1.5947, -1.9479, -1.9739],\n",
            "        [-2.5918, -2.4018, -2.3819, -2.0177, -2.5785, -1.3194, -1.8112, -2.2770],\n",
            "        [-2.4612, -2.4956, -2.0712, -2.1327, -2.4764, -1.3777, -1.9898, -2.1649],\n",
            "        [-2.5469, -2.2365, -1.8709, -2.4850, -2.0450, -1.7029, -1.9453, -2.0952],\n",
            "        [-2.3661, -2.3434, -1.7142, -2.6709, -2.3736, -1.7532, -2.0760, -1.7774],\n",
            "        [-2.0663, -2.5176, -1.9308, -2.4662, -2.3727, -1.7291, -2.0049, -1.8489],\n",
            "        [-2.6296, -3.1258, -2.1727, -1.7738, -2.4095, -1.3196, -1.8933, -2.3777],\n",
            "        [-2.3489, -1.8365, -1.8423, -2.4958, -1.9052, -1.9946, -2.3829, -2.0624],\n",
            "        [-2.3846, -2.4814, -2.0074, -2.0620, -2.3842, -1.6264, -1.8839, -2.1045],\n",
            "        [-2.2461, -2.0538, -1.8694, -2.5053, -2.0581, -1.9318, -2.3469, -1.8212],\n",
            "        [-2.3243, -1.9964, -1.7351, -2.6033, -2.0864, -1.8745, -2.1816, -2.0755],\n",
            "        [-2.8395, -2.7337, -2.4430, -1.7614, -2.6583, -1.2181, -1.8274, -2.3952],\n",
            "        [-2.0433, -1.9642, -1.7045, -2.6790, -2.2489, -2.2322, -2.3708, -1.7521],\n",
            "        [-2.1405, -1.8909, -1.7011, -2.7487, -2.3353, -2.1534, -2.3062, -1.7577],\n",
            "        [-1.9724, -1.6565, -1.9856, -2.8317, -2.1439, -2.0634, -2.2201, -2.1115],\n",
            "        [-2.7534, -2.4158, -2.1292, -2.1273, -2.5708, -1.3111, -1.8782, -2.2069],\n",
            "        [-2.1219, -2.3765, -1.6177, -2.5388, -2.2551, -1.9411, -2.1666, -1.9172],\n",
            "        [-2.2846, -2.1092, -1.8161, -2.6618, -2.2710, -1.8005, -1.9593, -2.0026],\n",
            "        [-2.3255, -1.7044, -1.7185, -2.7552, -2.1585, -1.9187, -2.2547, -2.2050],\n",
            "        [-2.4395, -2.8220, -1.9484, -2.1927, -2.4225, -1.5495, -1.8044, -2.0130],\n",
            "        [-2.3653, -2.9857, -2.1550, -2.0731, -2.3817, -1.4619, -1.8260, -2.0508],\n",
            "        [-2.2601, -2.1015, -1.6407, -2.5260, -2.3154, -1.9350, -2.1018, -2.0087],\n",
            "        [-2.1051, -2.2345, -1.7942, -2.5194, -2.2324, -1.9154, -2.2506, -1.8051],\n",
            "        [-2.0404, -2.2746, -1.9819, -2.5502, -2.1236, -1.8297, -2.1755, -1.8471],\n",
            "        [-2.4385, -2.6580, -1.8372, -2.3776, -2.2466, -1.6249, -1.9257, -1.9512],\n",
            "        [-2.6331, -2.7548, -2.2455, -1.8556, -2.5542, -1.3683, -1.7819, -2.2858],\n",
            "        [-1.9790, -2.3007, -1.7275, -2.6955, -2.3213, -1.9215, -2.1440, -1.8666],\n",
            "        [-2.1012, -2.9185, -1.8822, -2.2272, -2.2639, -1.7058, -2.0881, -1.8702],\n",
            "        [-2.2858, -1.7384, -1.5778, -2.9394, -2.2264, -2.2418, -2.3690, -1.8617],\n",
            "        [-1.9568, -2.6514, -1.9500, -2.4112, -2.4448, -1.7122, -2.1391, -1.7650],\n",
            "        [-2.4547, -2.8345, -2.0504, -2.1088, -2.3322, -1.5340, -1.8242, -2.0309]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 3, 6, 7, 5, 6, 3, 4, 3, 6, 5, 6, 6, 6, 7, 6, 6, 2, 7, 1, 6, 6, 7, 5,\n",
            "        4, 6, 3, 6, 7, 7, 7, 6], device='cuda:0')\n",
            "tensor([[-1.8434, -2.0023, -1.8559, -2.6374, -2.1384, -2.2176, -2.1952, -1.9605],\n",
            "        [-2.5470, -2.2519, -1.9339, -2.2862, -2.1891, -1.5695, -1.9335, -2.2498],\n",
            "        [-2.5544, -2.7907, -2.2277, -1.8862, -2.4920, -1.3397, -1.8563, -2.2972],\n",
            "        [-1.9679, -2.0142, -1.8968, -2.6241, -2.1638, -1.9527, -2.1588, -2.0247],\n",
            "        [-2.7050, -3.5531, -2.4335, -1.8150, -2.6280, -1.3995, -1.4954, -2.1998],\n",
            "        [-2.0411, -2.3194, -1.5159, -2.7303, -2.3096, -1.9705, -2.2673, -1.9333],\n",
            "        [-2.5163, -2.1142, -1.7253, -2.5302, -2.1088, -1.8794, -1.9481, -2.0864],\n",
            "        [-2.5203, -2.8542, -2.2412, -1.9854, -2.4788, -1.3478, -1.7909, -2.2273],\n",
            "        [-1.9368, -2.2925, -1.8098, -2.5412, -2.0070, -2.1602, -2.2064, -1.8801],\n",
            "        [-2.0352, -2.1775, -1.7458, -2.6291, -2.0838, -2.2469, -2.1264, -1.8331],\n",
            "        [-1.9330, -2.3010, -1.8017, -2.4389, -2.3556, -1.9987, -2.1497, -1.8580],\n",
            "        [-2.0839, -2.4874, -1.8658, -2.4615, -2.2118, -1.7719, -1.9194, -2.0704],\n",
            "        [-2.1630, -1.7405, -1.6216, -3.0700, -2.1242, -2.1649, -2.4518, -1.9299],\n",
            "        [-2.3688, -2.6521, -1.8856, -2.1890, -2.1337, -1.7341, -1.8273, -2.1512],\n",
            "        [-2.1784, -1.6848, -1.5868, -2.7203, -2.2176, -2.2404, -2.4219, -2.0648],\n",
            "        [-2.1618, -2.4540, -2.1000, -2.2517, -2.2258, -1.6776, -1.9490, -2.0096],\n",
            "        [-2.2210, -2.8386, -1.9685, -2.0438, -2.3944, -1.6621, -1.8437, -2.0827],\n",
            "        [-2.2264, -1.6348, -1.6131, -2.8610, -2.0812, -2.3511, -2.3885, -2.0495],\n",
            "        [-2.0465, -2.1311, -1.9300, -2.4868, -2.1780, -1.9719, -2.1644, -1.8547],\n",
            "        [-2.1044, -2.0950, -1.8020, -2.3889, -2.0949, -2.2023, -2.1660, -1.8968],\n",
            "        [-2.2061, -2.1640, -1.9532, -2.4626, -2.0157, -1.9084, -1.9351, -2.1037],\n",
            "        [-2.0488, -1.8240, -1.6132, -2.9525, -2.2403, -2.2179, -2.4484, -1.8543],\n",
            "        [-2.0979, -2.0450, -1.6469, -2.6373, -2.1650, -2.2112, -2.0170, -2.0689],\n",
            "        [-1.9702, -2.3314, -1.9411, -2.2600, -2.1701, -1.9299, -2.0252, -2.0856],\n",
            "        [-2.0823, -2.5814, -1.9964, -2.2054, -2.2387, -1.8123, -1.9096, -1.9977],\n",
            "        [-1.9248, -2.3260, -2.0193, -2.3860, -2.2856, -1.9113, -1.9699, -1.9477],\n",
            "        [-2.3455, -1.5845, -1.6804, -2.8206, -2.1666, -2.1053, -2.3818, -2.0833],\n",
            "        [-2.2192, -2.0070, -1.7530, -2.4981, -2.2320, -2.0135, -2.1587, -1.9303],\n",
            "        [-2.2468, -3.0304, -1.9219, -2.0440, -2.2086, -1.6502, -1.8436, -2.2071],\n",
            "        [-2.5811, -3.0042, -2.4497, -1.5660, -2.6385, -1.3778, -1.8123, -2.3789],\n",
            "        [-2.8993, -2.7124, -2.7853, -1.7963, -2.5160, -1.2800, -1.5659, -2.4863],\n",
            "        [-2.5215, -2.2380, -2.0659, -2.3419, -2.2891, -1.5922, -1.8108, -2.1057]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 0, 3, 5, 5, 7, 7, 7, 3, 7, 3, 5, 7, 6, 7, 5, 6, 0, 3, 3, 6, 7, 0, 3,\n",
            "        7, 7, 2, 3, 0, 5, 6, 7], device='cuda:0')\n",
            "tensor([[-2.0056, -1.9011, -1.9093, -2.5550, -2.0931, -2.1337, -2.1333, -2.0402],\n",
            "        [-2.3003, -1.4601, -2.0714, -2.6993, -1.9051, -2.1753, -2.1964, -2.2954],\n",
            "        [-2.2262, -1.1742, -1.8508, -2.8364, -2.3461, -2.3915, -2.3544, -2.4643],\n",
            "        [-2.6643, -2.2027, -1.8725, -2.2947, -2.2645, -1.6427, -1.8536, -2.1954],\n",
            "        [-2.0405, -2.5136, -1.8301, -2.1636, -2.2127, -1.8184, -2.0365, -2.1930],\n",
            "        [-2.0451, -2.4441, -2.3049, -2.1116, -2.2892, -1.6255, -1.9211, -2.1337],\n",
            "        [-1.9821, -2.3163, -2.1004, -2.1944, -2.0481, -1.8658, -2.0762, -2.1153],\n",
            "        [-1.9152, -1.9795, -1.7504, -2.6076, -2.2111, -2.2394, -2.2305, -1.9410],\n",
            "        [-1.9590, -1.9886, -1.8184, -2.6034, -2.0282, -2.2407, -2.1957, -1.9909],\n",
            "        [-2.2860, -1.8514, -1.5870, -2.5220, -2.2892, -2.2592, -2.2291, -1.9444],\n",
            "        [-1.9177, -1.7202, -1.9452, -2.4770, -2.1610, -2.2034, -2.3325, -2.0844],\n",
            "        [-2.3768, -2.5237, -1.9597, -2.0008, -2.5214, -1.6401, -1.8211, -2.1653],\n",
            "        [-2.2580, -1.6833, -1.8204, -2.6839, -2.3282, -1.9655, -2.1423, -2.0836],\n",
            "        [-2.0323, -2.6290, -2.0591, -1.9908, -2.3873, -1.6655, -1.9409, -2.2246],\n",
            "        [-2.4846, -2.6329, -2.0151, -2.2971, -2.1532, -1.6442, -1.7464, -2.0618],\n",
            "        [-2.8587, -3.2136, -2.4865, -1.5184, -2.7153, -1.3315, -1.7137, -2.4111],\n",
            "        [-2.1129, -2.1823, -1.8429, -2.3571, -2.0974, -2.0755, -2.0357, -2.0067],\n",
            "        [-2.9809, -2.7707, -2.2777, -1.7557, -2.6868, -1.2252, -1.7728, -2.5299],\n",
            "        [-2.1475, -1.9844, -1.7139, -2.4880, -2.0944, -2.1638, -2.1753, -2.0332],\n",
            "        [-2.0520, -1.7692, -1.6589, -2.6648, -2.1194, -2.3357, -2.4072, -2.0086],\n",
            "        [-2.2014, -2.8530, -2.1498, -1.6664, -2.4185, -1.6482, -1.9147, -2.3288],\n",
            "        [-2.1640, -2.2743, -1.9270, -2.4139, -2.1851, -1.9897, -1.8655, -1.9435],\n",
            "        [-2.1406, -2.3424, -1.7692, -2.3848, -2.3578, -1.9190, -1.9596, -1.9559],\n",
            "        [-2.6769, -1.4237, -1.4626, -3.0585, -2.0907, -2.4274, -2.5490, -2.1054],\n",
            "        [-2.2731, -2.8122, -1.9341, -2.1208, -2.3121, -1.8055, -1.7306, -2.0263],\n",
            "        [-2.1248, -2.3412, -1.8363, -2.3409, -2.2729, -1.8466, -2.0123, -2.0083],\n",
            "        [-2.0416, -2.5974, -2.2715, -2.0766, -2.2190, -1.7011, -1.9350, -2.0282],\n",
            "        [-1.9904, -2.4382, -2.1478, -2.1785, -2.2066, -1.7706, -1.9011, -2.1510],\n",
            "        [-2.3649, -2.9716, -2.1362, -1.9914, -2.3161, -1.4717, -1.6764, -2.4654],\n",
            "        [-2.5205, -2.7940, -2.0780, -2.0348, -2.4153, -1.4807, -1.7475, -2.1938],\n",
            "        [-2.4680, -2.9060, -2.0358, -1.8545, -2.2616, -1.7559, -1.7539, -2.0923],\n",
            "        [-2.5162, -2.9221, -2.1484, -1.9148, -2.3849, -1.5171, -1.7016, -2.2301]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 1, 5, 6, 2, 2, 6, 5, 5, 7, 0, 6, 6, 6, 6, 5, 6, 0, 6, 6, 3, 5, 6, 5,\n",
            "        7, 5, 0, 6, 5, 5, 2, 0], device='cuda:0')\n",
            "tensor([[-2.0255, -1.8473, -1.6967, -2.5386, -2.1234, -2.1326, -2.1739, -2.3407],\n",
            "        [-1.8944, -1.6038, -1.6895, -2.6065, -2.1771, -2.3777, -2.4907, -2.2920],\n",
            "        [-1.7047, -1.8680, -1.6756, -2.4598, -2.2976, -2.3521, -2.2472, -2.4110],\n",
            "        [-1.9450, -2.0485, -1.8769, -2.2658, -2.1800, -1.9771, -2.1685, -2.2497],\n",
            "        [-2.2458, -2.1739, -1.7237, -2.2973, -2.0811, -2.1442, -1.9077, -2.1972],\n",
            "        [-2.0133, -1.6078, -1.7495, -2.5990, -2.2980, -2.1899, -2.2954, -2.2557],\n",
            "        [-2.3304, -2.0798, -1.7237, -2.2480, -2.1564, -2.0408, -1.9502, -2.2456],\n",
            "        [-1.8343, -2.5618, -1.7932, -2.2357, -2.3964, -1.9156, -1.9562, -2.2066],\n",
            "        [-2.1364, -1.4885, -1.6250, -2.6598, -2.2329, -2.4386, -2.3855, -2.2750],\n",
            "        [-2.0697, -1.9897, -1.7261, -2.6195, -2.2659, -1.8768, -2.0546, -2.2901],\n",
            "        [-2.7934, -3.3692, -2.3501, -1.5397, -2.9002, -1.3579, -1.6170, -2.4787],\n",
            "        [-2.1064, -2.6952, -1.9656, -1.9764, -2.2941, -1.7784, -1.7859, -2.3564],\n",
            "        [-1.9549, -2.2472, -2.2262, -2.0612, -2.2173, -1.9033, -1.9582, -2.1338],\n",
            "        [-2.7944, -3.0199, -2.2618, -1.6725, -2.2313, -1.5689, -1.5885, -2.5487],\n",
            "        [-1.7762, -2.3496, -2.0347, -2.2757, -2.3726, -1.9027, -2.0299, -2.0547],\n",
            "        [-1.7560, -2.0417, -1.7235, -2.2964, -2.1362, -2.3210, -2.4128, -2.1843],\n",
            "        [-1.9522, -2.3263, -1.8660, -2.1496, -2.1690, -1.8403, -2.1020, -2.3661]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 6, 6, 5, 5, 4, 6, 7, 4, 7, 7, 0, 3, 4, 7, 3, 7], device='cuda:0')\n",
            "\n",
            "Evaluating...\n",
            "tensor(2.0609, device='cuda:0')\n",
            "tensor(1.8883, device='cuda:0')\n",
            "\n",
            "Training Loss: 2.015\n",
            "Validation Loss: 1.975\n",
            "\n",
            " Epoch 5 / 10\n",
            "tensor([[-1.8724, -2.7061, -1.8045, -2.1131, -2.3253, -2.0769, -1.9673, -2.0317],\n",
            "        [-2.1697, -2.1445, -1.7266, -2.1798, -2.0342, -2.1454, -1.9755, -2.3946],\n",
            "        [-2.0583, -2.6740, -2.0576, -1.9921, -2.1162, -2.0096, -1.6914, -2.2987],\n",
            "        [-2.0260, -1.7715, -1.8691, -2.2958, -2.0755, -2.3414, -2.1809, -2.2211],\n",
            "        [-2.5995, -2.4082, -2.2703, -1.8856, -2.5401, -1.3607, -1.7362, -2.6712],\n",
            "        [-1.7765, -2.8011, -1.9520, -2.1486, -2.2104, -2.0294, -1.9026, -2.1107],\n",
            "        [-2.0981, -2.7190, -1.8348, -2.0406, -2.1981, -1.9604, -1.7644, -2.3160],\n",
            "        [-1.8266, -2.1105, -1.8521, -2.2574, -2.1979, -2.1270, -2.2452, -2.1185],\n",
            "        [-2.9039, -2.5929, -2.5745, -1.7821, -2.6690, -1.2059, -1.6637, -2.6922],\n",
            "        [-1.8354, -2.3164, -1.6291, -2.2978, -2.0737, -2.2769, -2.2356, -2.2074],\n",
            "        [-2.0949, -2.3887, -1.5534, -2.0908, -2.1455, -2.2120, -2.0755, -2.3222],\n",
            "        [-1.9427, -2.0681, -1.7379, -2.3935, -2.2760, -2.3634, -1.8486, -2.2182],\n",
            "        [-1.9091, -2.1357, -1.7217, -2.1292, -2.0018, -2.2305, -2.2353, -2.4487],\n",
            "        [-2.6710, -3.6081, -2.3536, -1.5219, -2.5622, -1.4182, -1.6587, -2.5167],\n",
            "        [-1.9697, -1.8458, -1.7207, -2.2851, -2.0272, -2.4335, -2.3246, -2.2571],\n",
            "        [-1.9719, -1.9435, -1.6112, -2.2834, -2.1197, -2.3579, -2.3487, -2.2459],\n",
            "        [-1.9054, -1.7669, -1.6150, -2.6087, -2.0967, -2.3918, -2.4933, -2.1993],\n",
            "        [-2.6531, -3.3536, -2.3693, -1.4046, -2.5595, -1.5913, -1.6231, -2.5601],\n",
            "        [-2.1280, -1.5603, -1.4936, -2.9280, -2.1482, -2.5422, -2.3902, -2.2464],\n",
            "        [-1.7481, -2.8116, -1.8558, -2.0862, -2.1205, -1.9393, -2.0768, -2.3413],\n",
            "        [-2.0427, -2.3765, -1.7286, -2.2112, -2.1357, -2.1332, -1.8695, -2.3072],\n",
            "        [-2.1336, -1.3995, -1.7807, -2.6794, -2.1437, -2.3509, -2.3201, -2.4419],\n",
            "        [-2.2225, -1.6973, -1.4501, -2.6786, -2.1794, -2.2424, -2.2317, -2.5432],\n",
            "        [-3.0982, -3.5551, -2.6903, -1.5151, -2.7894, -1.3149, -1.4388, -2.6383],\n",
            "        [-1.7822, -2.0734, -1.7511, -2.4395, -2.0832, -2.3138, -2.0758, -2.3402],\n",
            "        [-2.0960, -3.0280, -1.9076, -1.9490, -2.3483, -1.8082, -1.7275, -2.2970],\n",
            "        [-1.8201, -2.0790, -1.7470, -2.5966, -2.0579, -2.2965, -2.1971, -2.0822],\n",
            "        [-2.0479, -1.7242, -1.6793, -2.3207, -1.9731, -2.3708, -2.3519, -2.5213],\n",
            "        [-1.8650, -2.2651, -1.8008, -2.3296, -2.0666, -2.0543, -2.0515, -2.3493],\n",
            "        [-1.7637, -1.9929, -1.9545, -2.3400, -1.9901, -2.3107, -2.0105, -2.4708],\n",
            "        [-1.6814, -2.0979, -1.7806, -2.4245, -2.1384, -2.2204, -2.1573, -2.3852],\n",
            "        [-1.9887, -2.0019, -2.1237, -2.2570, -2.0980, -1.9790, -1.8680, -2.4252]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 5, 7, 7, 7, 6, 5, 6, 5, 7, 5, 0, 5, 7, 3, 6, 7, 3, 7, 6, 6, 4, 7, 3,\n",
            "        0, 7, 7, 3, 3, 6, 6, 6], device='cuda:0')\n",
            "tensor([[-1.7956, -2.0966, -1.8275, -2.2923, -1.9652, -2.3872, -2.1603, -2.2833],\n",
            "        [-2.0199, -2.3440, -1.7061, -2.1480, -1.9873, -2.1761, -1.9288, -2.5609],\n",
            "        [-2.0094, -2.9032, -2.5404, -1.7154, -2.0938, -1.7627, -1.7383, -2.5041],\n",
            "        [-3.2856, -3.2350, -2.9235, -1.4536, -2.6075, -1.7833, -1.1666, -2.4947],\n",
            "        [-2.2268, -1.4439, -2.0281, -2.4042, -1.9675, -2.3770, -1.9961, -2.7229],\n",
            "        [-1.9663, -1.8080, -1.6270, -2.4464, -2.0812, -2.5469, -2.2024, -2.3097],\n",
            "        [-2.0594, -3.2181, -1.8614, -1.8846, -2.2402, -1.8874, -1.8480, -2.2105],\n",
            "        [-1.8726, -2.4091, -1.8873, -2.0593, -1.9596, -2.1929, -2.0784, -2.3053],\n",
            "        [-1.7467, -2.1644, -1.7447, -2.2382, -1.9439, -2.3748, -2.3469, -2.3265],\n",
            "        [-2.2155, -2.8100, -1.9440, -1.8837, -2.1285, -1.8169, -1.8186, -2.3888],\n",
            "        [-2.1805, -2.6432, -1.9165, -1.9470, -1.9858, -1.9889, -1.8237, -2.4022],\n",
            "        [-2.9082, -2.9820, -2.5377, -1.5672, -2.6727, -1.3509, -1.5890, -2.5922],\n",
            "        [-2.7873, -2.0341, -1.8998, -2.1836, -2.1163, -1.8164, -1.7385, -2.4475],\n",
            "        [-4.5446, -2.8347, -3.9844, -1.6810, -3.4851, -1.5945, -0.7894, -3.2684],\n",
            "        [-2.0769, -1.8911, -1.6744, -2.2861, -2.0671, -2.2870, -2.1830, -2.3658],\n",
            "        [-1.7767, -2.4325, -1.8454, -2.0552, -2.0170, -2.2405, -2.0889, -2.3679],\n",
            "        [-1.8667, -2.1782, -1.6108, -2.3076, -2.0594, -2.3439, -2.2879, -2.2262],\n",
            "        [-1.9107, -2.5754, -1.8018, -2.0674, -2.1453, -2.1094, -1.8847, -2.3628],\n",
            "        [-1.8916, -3.0924, -2.0181, -1.8835, -2.2807, -1.9103, -1.8495, -2.1960],\n",
            "        [-2.0930, -2.6345, -1.9111, -1.8803, -1.8830, -2.1727, -1.9061, -2.4102],\n",
            "        [-1.8054, -2.7577, -1.9747, -2.0353, -2.0394, -2.1017, -1.9059, -2.2860],\n",
            "        [-1.6981, -2.3463, -1.7420, -2.2079, -2.1943, -2.3216, -2.0959, -2.2668],\n",
            "        [-2.1968, -2.9396, -1.9229, -1.7120, -2.0702, -1.9537, -1.8976, -2.3923],\n",
            "        [-2.0756, -2.1989, -1.5333, -2.3266, -2.0054, -2.4341, -2.2189, -2.1276],\n",
            "        [-1.8515, -3.0159, -2.0457, -1.7816, -2.2669, -1.7716, -1.9043, -2.6076],\n",
            "        [-2.9535, -2.8070, -2.7026, -1.6891, -2.7175, -1.2229, -1.5251, -2.8522],\n",
            "        [-1.9504, -1.6498, -1.7095, -2.6452, -1.8799, -2.7193, -2.4843, -2.1906],\n",
            "        [-1.9754, -1.5875, -1.8566, -2.4965, -2.2677, -2.2892, -2.0834, -2.4204],\n",
            "        [-1.8420, -2.5466, -1.9639, -1.9616, -1.9431, -2.1059, -2.0048, -2.4947],\n",
            "        [-1.8493, -2.8992, -2.2087, -1.9906, -2.0229, -1.9999, -1.7676, -2.2754],\n",
            "        [-2.1423, -2.8639, -1.7633, -2.0332, -2.0586, -2.0313, -1.7914, -2.3263],\n",
            "        [-1.9923, -2.3314, -1.8779, -2.0646, -1.8358, -2.2616, -1.9687, -2.4843]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 2, 6, 6, 1, 2, 7, 7, 0, 5, 6, 7, 1, 6, 5, 3, 6, 7, 6, 6, 3, 7, 5, 7,\n",
            "        6, 7, 7, 7, 6, 6, 3, 7], device='cuda:0')\n",
            "tensor([[-1.9261, -2.4409, -1.9107, -1.9791, -2.3249, -2.0654, -1.9409, -2.1813],\n",
            "        [-1.9987, -2.5609, -1.8396, -1.9231, -2.0483, -2.0742, -2.0086, -2.3704],\n",
            "        [-2.2471, -2.9284, -2.4699, -1.5489, -2.4006, -1.6204, -1.7260, -2.5607],\n",
            "        [-2.0444, -2.9377, -2.0416, -1.7950, -2.3154, -1.9957, -1.7576, -2.1671],\n",
            "        [-2.0341, -1.6522, -1.4813, -2.3776, -2.1487, -2.7063, -2.5388, -2.3530],\n",
            "        [-2.3341, -2.1733, -2.2564, -1.8734, -2.2507, -1.7597, -1.8595, -2.3248],\n",
            "        [-2.4726, -3.5628, -2.4152, -1.3695, -2.7009, -1.6054, -1.6459, -2.4903],\n",
            "        [-2.0797, -2.6976, -1.9097, -2.0342, -2.0885, -2.2381, -1.7977, -2.0209],\n",
            "        [-2.0788, -1.7172, -1.8179, -2.1814, -1.9144, -2.4783, -2.4441, -2.2828],\n",
            "        [-2.2839, -3.6804, -1.9790, -1.5467, -2.3099, -2.0607, -1.6190, -2.3328],\n",
            "        [-1.6809, -2.7895, -1.9770, -1.8300, -2.1761, -2.2016, -2.0162, -2.3415],\n",
            "        [-3.5269, -3.5196, -3.3387, -1.1220, -2.9225, -1.8201, -1.1934, -2.7986],\n",
            "        [-2.2292, -2.5802, -2.0819, -1.7538, -2.1571, -1.9516, -1.7938, -2.3562],\n",
            "        [-1.8325, -2.9061, -2.0633, -1.7088, -2.0842, -2.2533, -1.9109, -2.3047],\n",
            "        [-2.2176, -3.1331, -1.9809, -1.5708, -2.0706, -2.0549, -1.8595, -2.3885],\n",
            "        [-2.7412, -2.9084, -2.4617, -1.4703, -2.3541, -1.5345, -1.7091, -2.6007],\n",
            "        [-2.7963, -2.7665, -2.7226, -1.5130, -2.6150, -1.4024, -1.6065, -2.6541],\n",
            "        [-2.1909, -3.4196, -2.0540, -1.5881, -2.5067, -1.8165, -1.7870, -2.1953],\n",
            "        [-1.7950, -2.5534, -2.1209, -1.9472, -1.9475, -2.2863, -1.8732, -2.3482],\n",
            "        [-3.9555, -3.0541, -3.5810, -1.5679, -2.9765, -1.5402, -0.9702, -2.9370],\n",
            "        [-4.0286, -2.0195, -3.8804, -1.9480, -3.1648, -1.7443, -0.9161, -2.6710],\n",
            "        [-2.2930, -3.0779, -1.7494, -1.7526, -2.0309, -2.1957, -1.9009, -2.1730],\n",
            "        [-1.8437, -3.0951, -2.1981, -1.6602, -2.1351, -2.0702, -1.9049, -2.2814],\n",
            "        [-2.0163, -1.9888, -1.8587, -2.0632, -1.8665, -2.4641, -2.1015, -2.4645],\n",
            "        [-1.7400, -2.1187, -1.8621, -2.2063, -2.2305, -2.3005, -2.1241, -2.1926],\n",
            "        [-1.9070, -3.0690, -1.9535, -1.8539, -2.1360, -2.2313, -1.6698, -2.3772],\n",
            "        [-2.0680, -2.5339, -1.7762, -1.8853, -2.1316, -2.1075, -1.9592, -2.3861],\n",
            "        [-1.6926, -2.8213, -2.1236, -1.7546, -2.0876, -2.2399, -2.0447, -2.2636],\n",
            "        [-1.9445, -2.5416, -2.0599, -2.0333, -2.0927, -2.0909, -1.8058, -2.2205],\n",
            "        [-1.7738, -2.6824, -1.8184, -1.9298, -2.0115, -2.3298, -2.1298, -2.2585],\n",
            "        [-2.6836, -4.0188, -2.3420, -1.2902, -2.4605, -1.5939, -1.7299, -2.5701],\n",
            "        [-2.7865, -3.0931, -2.4081, -1.4149, -2.5968, -1.4960, -1.6744, -2.6021]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 7, 5, 7, 7, 2, 6, 5, 5, 0, 7, 5, 6, 7, 6, 6, 5, 7, 5, 6, 6, 4, 0, 4,\n",
            "        7, 3, 0, 6, 7, 3, 0, 0], device='cuda:0')\n",
            "tensor([[-1.8366, -2.8723, -1.8448, -1.7215, -1.9901, -2.3659, -2.1916, -2.2545],\n",
            "        [-1.8049, -2.4714, -1.9883, -1.8286, -1.8840, -2.5289, -2.2133, -2.1857],\n",
            "        [-2.3254, -3.1544, -2.1053, -1.6055, -2.3200, -1.7925, -1.7447, -2.3281],\n",
            "        [-2.2758, -3.1917, -2.1694, -1.4839, -2.3876, -1.9599, -1.6203, -2.4695],\n",
            "        [-1.9833, -3.1475, -1.9024, -1.6414, -2.2483, -2.1746, -1.8681, -2.2743],\n",
            "        [-1.9345, -2.8092, -1.8696, -1.8540, -1.9555, -2.3644, -1.9327, -2.2614],\n",
            "        [-2.2468, -3.5433, -2.3773, -1.4738, -2.1108, -1.9404, -1.6534, -2.4382],\n",
            "        [-1.6953, -2.5715, -1.7905, -2.0434, -1.9867, -2.6879, -2.2391, -2.0262],\n",
            "        [-2.1207, -1.8109, -2.0831, -2.3048, -1.7667, -2.5134, -1.9437, -2.3315],\n",
            "        [-2.1677, -3.2231, -2.2077, -1.5094, -2.1493, -1.8840, -1.8886, -2.3550],\n",
            "        [-2.1879, -3.3133, -2.2427, -1.3665, -2.2961, -1.9933, -1.8045, -2.4209],\n",
            "        [-1.9583, -2.3411, -1.6012, -2.0831, -2.0956, -2.4712, -2.1470, -2.1878],\n",
            "        [-2.1715, -2.4301, -2.0935, -1.5693, -2.3466, -1.8846, -2.0249, -2.4425],\n",
            "        [-1.8065, -2.4022, -1.9184, -1.9255, -1.9944, -2.5354, -2.0725, -2.1946],\n",
            "        [-1.8376, -1.8292, -1.8193, -2.2692, -1.9791, -2.7478, -2.3694, -2.1292],\n",
            "        [-2.3604, -3.6333, -2.3975, -1.3024, -2.2190, -1.8741, -1.7749, -2.4694],\n",
            "        [-1.8405, -1.9946, -1.7926, -2.1865, -2.1365, -2.6073, -2.2320, -2.0616],\n",
            "        [-1.8344, -2.2862, -1.7919, -2.0598, -1.9128, -2.5382, -2.1022, -2.3468],\n",
            "        [-2.1153, -2.1336, -1.8266, -1.9471, -1.8074, -2.4689, -2.2429, -2.2785],\n",
            "        [-2.1247, -2.7777, -2.0745, -1.7004, -2.1133, -2.0445, -1.7980, -2.3622],\n",
            "        [-1.6251, -2.5856, -1.8946, -1.8949, -2.1281, -2.4870, -2.1799, -2.1913],\n",
            "        [-1.9627, -2.4210, -1.7783, -1.9199, -1.8634, -2.3997, -2.0928, -2.4544],\n",
            "        [-1.7098, -2.6538, -1.9523, -1.7930, -1.9115, -2.6029, -2.1604, -2.2719],\n",
            "        [-1.7725, -2.6973, -2.0264, -1.7288, -2.1187, -2.2075, -1.9948, -2.4397],\n",
            "        [-1.9225, -2.0018, -1.6353, -2.2443, -2.1580, -2.8880, -2.1809, -2.0130],\n",
            "        [-1.9169, -3.1443, -2.1551, -1.5383, -2.1735, -2.2098, -1.8861, -2.2631],\n",
            "        [-2.4125, -3.7062, -2.3309, -1.3721, -2.4361, -1.8785, -1.6467, -2.2824],\n",
            "        [-2.7368, -2.5629, -2.8971, -1.6780, -2.2736, -1.4570, -1.5639, -2.6449],\n",
            "        [-1.8660, -2.9862, -2.1774, -1.8698, -2.1456, -2.2885, -1.7748, -1.9706],\n",
            "        [-2.0119, -2.4546, -2.0705, -2.0154, -1.6827, -2.4353, -1.9223, -2.2899],\n",
            "        [-2.0395, -2.5361, -1.7119, -1.9551, -2.0129, -2.3396, -1.9549, -2.3320],\n",
            "        [-1.7784, -2.3587, -1.7594, -2.0190, -2.0151, -2.5961, -2.1372, -2.2466]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([0, 3, 5, 3, 7, 6, 6, 7, 1, 6, 7, 7, 5, 5, 7, 5, 7, 4, 1, 0, 3, 4, 7, 5,\n",
            "        5, 6, 5, 5, 7, 6, 6, 6], device='cuda:0')\n",
            "tensor([[-1.7991, -1.8824, -1.9330, -1.9569, -1.7954, -3.0086, -2.5070, -2.3089],\n",
            "        [-1.9669, -3.0335, -2.1835, -1.6316, -1.7957, -2.3598, -2.0064, -2.2185],\n",
            "        [-2.0049, -1.7826, -1.8087, -2.1348, -1.7999, -2.9783, -2.5940, -2.0870],\n",
            "        [-1.9837, -3.3613, -2.4423, -1.4434, -2.3404, -1.9088, -1.7999, -2.3560],\n",
            "        [-1.9447, -2.7527, -2.0748, -1.6484, -2.0205, -2.2304, -2.0367, -2.2563],\n",
            "        [-1.7573, -2.4063, -1.9738, -1.9470, -1.9586, -2.6123, -2.1429, -2.0875],\n",
            "        [-1.8546, -2.5411, -2.1020, -2.0676, -2.1066, -2.1315, -1.9589, -2.0049],\n",
            "        [-2.0079, -2.8679, -1.9349, -1.7733, -1.6625, -2.6141, -2.0223, -2.3082],\n",
            "        [-2.3511, -2.9137, -2.4218, -1.3957, -2.4755, -1.6637, -1.8188, -2.5477],\n",
            "        [-1.9238, -2.6358, -1.7083, -1.8144, -2.0978, -2.5710, -2.2564, -2.0080],\n",
            "        [-2.0156, -3.9804, -2.5331, -1.2876, -2.1737, -2.1758, -1.7069, -2.4764],\n",
            "        [-2.1290, -3.2639, -2.0648, -1.4107, -2.2710, -2.1243, -1.9212, -2.2749],\n",
            "        [-1.5709, -2.5106, -2.1724, -1.8928, -2.0670, -2.3942, -2.3787, -1.9959],\n",
            "        [-1.9833, -2.3642, -1.8647, -1.9298, -1.6587, -2.6414, -2.2424, -2.2986],\n",
            "        [-1.8937, -1.7971, -1.8259, -2.1402, -1.9130, -2.7304, -2.3878, -2.2992],\n",
            "        [-2.0387, -3.0743, -1.9306, -1.6114, -2.2203, -2.2926, -1.9522, -2.0607],\n",
            "        [-2.4320, -3.7774, -2.4075, -1.1694, -2.3953, -1.8824, -1.8036, -2.5185],\n",
            "        [-1.9426, -2.3011, -2.1450, -1.7489, -2.0198, -2.2099, -2.0312, -2.3869],\n",
            "        [-2.2151, -1.4452, -1.7526, -2.3419, -1.8068, -3.1610, -2.7641, -2.1533],\n",
            "        [-1.7802, -2.9791, -2.1621, -1.6507, -1.9728, -2.5009, -1.8603, -2.3344],\n",
            "        [-2.0614, -1.3150, -1.8380, -2.3126, -1.9804, -3.0985, -2.8409, -2.2574],\n",
            "        [-1.7613, -2.7117, -1.9741, -1.7937, -2.1655, -2.6213, -2.1124, -1.9094],\n",
            "        [-1.9131, -2.0658, -1.7474, -2.0608, -1.9335, -2.7403, -2.4142, -2.0759],\n",
            "        [-1.5380, -2.4309, -1.9846, -1.8783, -1.9900, -2.7609, -2.4940, -2.0840],\n",
            "        [-1.9044, -2.7769, -2.1291, -1.7617, -2.1947, -2.1533, -1.8922, -2.1209],\n",
            "        [-2.0798, -2.8249, -2.1088, -1.5889, -2.0774, -2.0800, -1.9043, -2.3961],\n",
            "        [-2.2087, -2.9162, -2.3238, -1.4976, -2.0166, -2.0556, -1.8549, -2.3343],\n",
            "        [-2.3768, -3.3056, -2.4329, -1.2630, -2.1606, -1.8989, -1.8790, -2.4993],\n",
            "        [-2.0310, -2.4609, -1.9548, -1.7600, -1.7274, -2.5605, -2.0833, -2.4050],\n",
            "        [-1.9521, -3.0201, -2.1842, -1.6359, -2.0578, -2.1481, -1.9182, -2.2021],\n",
            "        [-2.2070, -3.0832, -2.3514, -1.4267, -2.4383, -1.8492, -1.7650, -2.3757],\n",
            "        [-1.9441, -2.1498, -1.9181, -2.0133, -2.0137, -2.4785, -2.0089, -2.2213]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 7, 5, 0, 7, 5, 6, 7, 3, 5, 3, 7, 7, 4, 1, 0, 5, 1, 5, 6, 4, 6, 5, 0,\n",
            "        5, 6, 6, 4, 6, 5, 6, 3], device='cuda:0')\n",
            "tensor([[-1.9891, -3.2550, -2.5145, -1.5614, -2.1302, -1.7966, -1.9310, -2.2617],\n",
            "        [-2.0118, -2.7029, -2.4852, -1.8507, -1.5078, -2.4251, -2.1016, -2.0661],\n",
            "        [-1.9841, -2.3938, -2.3608, -1.6740, -1.8022, -2.2220, -2.1653, -2.2896],\n",
            "        [-2.0931, -3.1138, -2.5769, -1.3694, -2.2733, -1.8463, -1.9107, -2.3728],\n",
            "        [-1.6443, -2.4125, -2.1992, -1.8001, -1.8327, -2.7521, -2.4087, -2.0606],\n",
            "        [-1.8160, -2.1355, -2.1534, -1.9569, -1.6396, -2.9628, -2.5224, -1.9970],\n",
            "        [-1.9152, -2.1843, -1.9969, -1.9479, -1.7216, -2.6319, -2.2722, -2.2256],\n",
            "        [-2.0213, -1.2772, -2.2983, -2.2231, -1.7162, -3.1427, -2.8076, -2.3359],\n",
            "        [-1.7028, -3.0404, -2.1372, -1.7227, -2.0109, -2.4770, -2.0427, -2.0723],\n",
            "        [-1.8769, -2.3718, -2.2284, -1.6928, -1.6414, -2.6455, -2.3220, -2.3110],\n",
            "        [-2.0219, -2.1780, -2.0181, -1.9238, -1.5950, -2.6961, -2.5705, -2.0519],\n",
            "        [-1.7499, -2.4936, -2.5225, -1.8205, -1.9417, -2.0928, -2.0798, -2.2106],\n",
            "        [-1.9679, -3.4276, -2.5402, -1.3996, -1.8507, -2.1960, -1.9168, -2.4443],\n",
            "        [-2.1598, -2.7449, -2.3749, -1.4775, -2.3066, -1.8896, -2.0479, -2.1251],\n",
            "        [-1.7715, -2.1012, -2.2554, -1.8935, -1.8753, -2.5981, -2.2464, -2.1307],\n",
            "        [-1.8967, -2.6138, -2.3139, -1.7386, -1.7735, -2.3612, -2.1748, -2.0846],\n",
            "        [-1.6102, -1.9352, -2.2098, -2.1050, -1.6921, -2.6745, -2.6382, -2.3065],\n",
            "        [-2.0702, -2.9859, -2.1082, -1.6610, -1.8214, -2.4165, -1.9049, -2.1887],\n",
            "        [-1.6565, -2.3474, -2.2418, -1.8589, -1.9302, -2.5744, -2.3182, -2.0272],\n",
            "        [-1.8943, -2.0988, -2.2612, -2.0043, -1.4804, -3.0289, -2.4905, -2.0463],\n",
            "        [-1.8606, -2.6806, -2.1562, -1.7852, -1.6974, -2.5956, -2.1664, -2.1201],\n",
            "        [-1.6093, -2.8838, -2.1645, -1.7208, -1.9696, -2.5497, -2.3010, -2.0209],\n",
            "        [-1.9924, -2.9312, -2.2198, -1.5060, -2.0741, -2.2622, -2.0624, -2.0960],\n",
            "        [-1.7450, -2.0866, -2.2770, -1.7814, -1.7052, -2.8106, -2.4921, -2.2480],\n",
            "        [-2.1302, -1.3390, -2.0860, -2.3459, -1.6430, -3.0768, -2.7179, -2.3687],\n",
            "        [-2.6577, -2.7468, -2.6488, -1.5731, -2.3063, -1.5974, -1.6361, -2.3988],\n",
            "        [-2.0076, -2.8786, -2.2926, -1.4129, -1.9913, -2.2845, -1.9371, -2.4940],\n",
            "        [-1.6610, -2.0834, -2.1005, -2.1629, -1.9464, -2.7071, -2.2351, -2.0276],\n",
            "        [-1.7428, -2.1250, -2.1671, -2.0513, -1.6613, -2.7617, -2.2167, -2.2984],\n",
            "        [-1.8177, -2.2797, -2.1533, -1.9054, -1.8804, -2.6223, -2.2264, -1.9853],\n",
            "        [-1.9112, -1.9511, -2.2617, -1.9193, -1.6131, -2.7915, -2.3277, -2.2930],\n",
            "        [-1.7199, -2.0940, -2.1983, -1.9562, -1.9272, -2.6822, -2.3982, -1.9626]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 6, 5, 5, 7, 6, 6, 1, 0, 6, 5, 6, 5, 7, 6, 4, 3, 2, 0, 5, 7, 7, 2, 5,\n",
            "        1, 5, 6, 5, 7, 6, 6, 7], device='cuda:0')\n",
            "tensor([[-1.9284, -1.5160, -2.5743, -2.1658, -1.5005, -3.1090, -2.7159, -2.2043],\n",
            "        [-1.9231, -2.3420, -2.6382, -1.6194, -1.6236, -2.5509, -2.1642, -2.3211],\n",
            "        [-2.2546, -2.7582, -2.4132, -1.5815, -1.4311, -2.7013, -2.2783, -2.0568],\n",
            "        [-1.8727, -2.2460, -2.0967, -2.0037, -1.6195, -2.7364, -2.4400, -2.0189],\n",
            "        [-2.1649, -1.7142, -2.1986, -2.0505, -1.5038, -2.8708, -2.4485, -2.3013],\n",
            "        [-1.7463, -2.6663, -2.3064, -1.6903, -1.7095, -2.7710, -2.5418, -1.8990],\n",
            "        [-1.9330, -2.3416, -2.2054, -1.7062, -1.7495, -2.6044, -2.2392, -2.1804],\n",
            "        [-1.6754, -2.2209, -2.4036, -2.0291, -1.8576, -2.4165, -2.1857, -2.0814],\n",
            "        [-2.0797, -1.6882, -2.2733, -2.2092, -1.5800, -2.7900, -2.3351, -2.1784],\n",
            "        [-2.0744, -2.5615, -2.2552, -1.7417, -1.9289, -2.1227, -1.9910, -2.1583],\n",
            "        [-2.2807, -3.2718, -2.2112, -1.3756, -2.0248, -2.1321, -1.9110, -2.3123],\n",
            "        [-2.3412, -1.5324, -2.2860, -1.9946, -1.4453, -2.8656, -2.8047, -2.3343],\n",
            "        [-2.0827, -1.6176, -2.0453, -2.1233, -1.7455, -3.0719, -2.6222, -2.0061],\n",
            "        [-1.9877, -2.6661, -2.7191, -1.5033, -1.5402, -2.6249, -2.0952, -2.3505],\n",
            "        [-1.9543, -2.0612, -2.3524, -1.7860, -1.6146, -2.8445, -2.3744, -2.1367],\n",
            "        [-2.0294, -1.8827, -2.1828, -2.1777, -1.4292, -3.2128, -2.6044, -1.9901],\n",
            "        [-1.7529, -1.9515, -2.3403, -2.0626, -1.6412, -2.9854, -2.6274, -1.9329],\n",
            "        [-1.9295, -2.4342, -2.3098, -1.6811, -1.7452, -2.5007, -2.2124, -2.1576],\n",
            "        [-2.1821, -1.7005, -2.1747, -2.2642, -1.4257, -2.9864, -2.4442, -2.2122],\n",
            "        [-1.6652, -2.6647, -2.3544, -1.8321, -2.0562, -2.3290, -2.1204, -1.9598],\n",
            "        [-1.7881, -2.0934, -2.2823, -1.9914, -1.5929, -2.8719, -2.4382, -2.0901],\n",
            "        [-2.6836, -2.7304, -2.9605, -1.4739, -2.6644, -1.4726, -1.4953, -2.7724],\n",
            "        [-1.7814, -1.6875, -2.3445, -2.1282, -1.4999, -3.0993, -2.8082, -2.2718],\n",
            "        [-2.0366, -2.9393, -2.3009, -1.5428, -2.0070, -2.1371, -1.9972, -2.1664],\n",
            "        [-1.9948, -2.7413, -2.2706, -1.7223, -1.6782, -2.3208, -1.9518, -2.4010],\n",
            "        [-1.9361, -2.3156, -2.2983, -1.8857, -1.8385, -2.3301, -2.0545, -2.1173],\n",
            "        [-2.0835, -2.6096, -2.3910, -1.6005, -1.4572, -2.4710, -2.2997, -2.3977],\n",
            "        [-1.8776, -1.9425, -2.3168, -1.9311, -1.8925, -2.6514, -2.2311, -2.0292],\n",
            "        [-1.6702, -2.4290, -2.4460, -1.8575, -1.6585, -2.5351, -2.2945, -2.2030],\n",
            "        [-2.1833, -2.9882, -2.6286, -1.4572, -2.3484, -1.8439, -1.8333, -2.1348],\n",
            "        [-1.8751, -2.2125, -2.4304, -1.8043, -1.7264, -2.5747, -2.4374, -1.9439],\n",
            "        [-1.7889, -1.7722, -2.4704, -1.9422, -1.8489, -2.6057, -2.3342, -2.2368]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 6, 7, 7, 2, 7, 6, 5, 5, 6, 5, 6, 2, 0, 7, 2, 7, 3, 6, 0, 7, 6, 7, 3,\n",
            "        6, 5, 5, 6, 5, 3, 7, 7], device='cuda:0')\n",
            "tensor([[-1.6354, -2.3979, -2.4322, -1.7596, -1.8180, -2.4125, -2.3556, -2.2304],\n",
            "        [-1.8534, -1.3852, -2.3554, -2.3250, -1.6382, -3.0453, -2.8111, -2.3194],\n",
            "        [-1.8502, -1.6772, -2.2667, -2.1202, -1.6712, -2.7475, -2.6283, -2.2265],\n",
            "        [-2.0734, -1.8025, -2.4234, -1.8678, -1.5610, -2.7413, -2.5979, -2.1418],\n",
            "        [-1.9576, -1.8314, -2.3182, -1.9753, -1.5668, -2.6627, -2.6866, -2.1639],\n",
            "        [-2.0394, -1.4993, -2.0777, -2.0882, -1.8184, -2.5627, -2.7449, -2.3661],\n",
            "        [-1.9665, -3.3509, -2.6300, -1.4276, -2.2773, -1.7941, -1.8529, -2.4372],\n",
            "        [-1.6998, -1.9610, -2.4390, -1.9421, -1.8179, -2.6069, -2.4415, -2.0976],\n",
            "        [-1.7694, -2.5429, -2.3373, -1.7803, -1.6988, -2.5368, -2.2423, -2.1411],\n",
            "        [-1.9184, -2.1776, -2.3356, -1.7694, -2.0408, -2.1364, -2.1565, -2.2170],\n",
            "        [-1.7089, -2.5743, -2.3873, -1.8527, -1.7571, -2.4003, -2.1244, -2.1957],\n",
            "        [-1.8008, -2.6473, -2.3264, -1.7104, -1.9066, -2.2853, -2.1455, -2.1352],\n",
            "        [-2.3572, -1.0549, -2.4012, -2.3680, -1.6238, -3.2663, -3.0687, -2.3964],\n",
            "        [-2.0207, -2.6332, -2.3287, -1.5829, -2.0115, -2.0134, -2.0408, -2.3481],\n",
            "        [-1.9821, -2.6458, -2.4375, -1.6821, -1.8767, -1.9817, -1.9317, -2.5001],\n",
            "        [-1.7551, -2.6216, -2.5445, -1.7965, -2.0938, -2.1478, -2.0415, -1.9645],\n",
            "        [-1.8959, -1.9557, -2.4151, -2.0099, -1.6869, -2.6081, -2.2788, -2.0890],\n",
            "        [-2.1404, -1.6820, -2.3197, -2.1145, -1.4976, -2.7160, -2.4202, -2.3156],\n",
            "        [-2.3778, -2.5440, -2.4133, -1.5890, -2.0462, -1.8241, -1.8022, -2.5317],\n",
            "        [-1.9377, -1.7576, -2.4631, -2.0602, -1.8261, -2.2877, -2.2342, -2.2899],\n",
            "        [-1.9091, -2.7392, -2.4446, -1.7080, -2.1136, -1.8734, -2.0417, -2.1631],\n",
            "        [-2.1880, -3.0715, -2.4244, -1.4001, -2.0214, -2.1773, -1.8245, -2.3098],\n",
            "        [-1.7382, -1.9907, -2.2224, -2.1095, -1.8695, -2.7669, -2.3621, -1.9197],\n",
            "        [-2.0362, -1.2629, -2.4562, -2.3025, -1.6046, -3.1662, -2.9208, -2.2650],\n",
            "        [-2.0800, -1.3838, -2.3666, -2.4241, -1.6861, -2.7379, -2.7125, -2.0732],\n",
            "        [-2.2345, -2.8767, -2.5729, -1.3730, -1.9723, -1.8718, -1.9269, -2.6825],\n",
            "        [-1.7605, -1.6604, -2.3017, -2.3986, -1.8793, -2.5395, -2.3336, -2.1327],\n",
            "        [-1.9977, -2.2041, -2.4449, -1.8787, -2.0318, -1.9468, -2.0704, -2.1671],\n",
            "        [-2.0343, -1.9160, -2.4431, -1.8342, -1.4636, -2.7932, -2.6544, -2.1854],\n",
            "        [-1.9566, -2.7956, -2.4495, -1.5805, -1.7477, -2.3165, -2.0142, -2.3109],\n",
            "        [-2.1814, -2.6365, -2.3452, -1.3803, -1.8864, -2.3330, -2.0643, -2.3791],\n",
            "        [-1.6994, -2.6838, -2.5039, -1.7641, -1.9397, -2.4268, -2.1458, -1.9191]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([3, 7, 7, 6, 3, 7, 7, 7, 5, 6, 6, 2, 5, 6, 5, 7, 5, 6, 0, 6, 5, 4, 5, 0,\n",
            "        6, 6, 6, 7, 5, 5, 6, 6], device='cuda:0')\n",
            "tensor([[-1.6449, -2.5386, -2.5939, -1.7829, -2.1162, -2.3157, -2.0575, -1.9794],\n",
            "        [-1.9904, -1.8479, -2.4113, -1.9180, -1.8270, -2.2379, -2.3498, -2.2422],\n",
            "        [-1.7352, -2.5667, -2.4067, -1.7677, -1.8243, -2.2390, -2.2167, -2.2151],\n",
            "        [-1.5580, -2.2555, -2.2665, -2.0535, -1.8615, -2.4126, -2.4557, -2.1051],\n",
            "        [-2.1534, -2.3723, -2.4362, -1.8844, -2.2314, -1.6958, -1.8752, -2.2342],\n",
            "        [-1.6200, -2.0229, -2.4585, -2.0557, -1.8809, -2.5261, -2.2489, -2.1343],\n",
            "        [-1.9346, -2.0324, -2.1344, -1.9783, -1.9495, -2.3267, -2.3178, -2.0445],\n",
            "        [-1.6463, -2.1891, -2.3577, -2.1264, -1.8629, -2.3909, -2.1923, -2.0965],\n",
            "        [-1.9583, -2.5660, -2.3188, -1.6661, -2.1298, -2.0168, -2.0922, -2.1257],\n",
            "        [-1.9327, -2.7895, -2.5985, -1.5585, -1.9710, -1.9560, -2.0015, -2.3742],\n",
            "        [-2.1844, -2.3572, -2.2744, -1.7531, -1.7936, -2.4776, -2.1607, -1.8896],\n",
            "        [-1.8369, -3.0004, -2.4634, -1.5822, -1.9205, -2.2830, -2.0295, -2.1173],\n",
            "        [-1.7337, -2.1438, -2.4080, -2.0612, -1.8527, -2.3877, -2.2584, -1.9973],\n",
            "        [-1.7724, -2.0316, -2.1074, -2.0379, -1.8695, -2.4317, -2.4141, -2.1580],\n",
            "        [-2.0804, -2.5383, -2.3673, -1.7525, -1.5159, -2.3860, -2.2000, -2.2383],\n",
            "        [-1.9560, -1.4940, -2.2689, -2.1854, -1.8090, -2.6361, -2.6609, -2.1811],\n",
            "        [-1.8464, -2.6055, -2.3094, -1.6876, -1.8778, -2.3534, -2.1426, -2.1310]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 4, 6, 0, 5, 7, 7, 6, 6, 5, 7, 6, 0, 5, 5, 5, 3], device='cuda:0')\n",
            "\n",
            "Evaluating...\n",
            "tensor(2.0760, device='cuda:0')\n",
            "tensor(1.8786, device='cuda:0')\n",
            "\n",
            "Training Loss: 2.012\n",
            "Validation Loss: 1.977\n",
            "\n",
            " Epoch 6 / 10\n",
            "tensor([[-1.7907, -2.6286, -2.2251, -1.8836, -1.8231, -2.1741, -2.2431, -2.1243],\n",
            "        [-1.9731, -2.6359, -2.5303, -1.6652, -2.2194, -1.6434, -2.0690, -2.3835],\n",
            "        [-1.9986, -1.8611, -2.2021, -2.0986, -1.6957, -2.6849, -2.4927, -1.9562],\n",
            "        [-2.1174, -2.3733, -2.3033, -1.8644, -1.6565, -2.2399, -2.2503, -2.0485],\n",
            "        [-1.8495, -1.9012, -2.3318, -2.2103, -1.8999, -2.2858, -2.3093, -1.9958],\n",
            "        [-2.0110, -2.6526, -2.1073, -1.9254, -1.7200, -2.3167, -2.0206, -2.1364],\n",
            "        [-1.9425, -2.8019, -2.1653, -1.7904, -2.0428, -2.0066, -1.9424, -2.2359],\n",
            "        [-1.8779, -2.0887, -2.0546, -2.2039, -1.7972, -2.5686, -2.4856, -1.8385],\n",
            "        [-1.9451, -1.1193, -2.6719, -2.4456, -2.0888, -2.6910, -2.6323, -2.1969],\n",
            "        [-1.9537, -2.5111, -2.0309, -2.0386, -1.7966, -2.1972, -2.2387, -2.0244],\n",
            "        [-1.9557, -1.7093, -2.3089, -2.2559, -1.7458, -2.5035, -2.7498, -1.8763],\n",
            "        [-1.7214, -2.9507, -2.3450, -1.7998, -1.8111, -2.4062, -2.3538, -1.8385],\n",
            "        [-1.7396, -1.8316, -2.3962, -2.2200, -1.9266, -2.3302, -2.3083, -2.1019],\n",
            "        [-1.9768, -2.4814, -2.1680, -2.1288, -1.9222, -1.9118, -2.0588, -2.0974],\n",
            "        [-1.9138, -2.1837, -2.2215, -1.9118, -1.8475, -2.4349, -2.4691, -1.8727],\n",
            "        [-1.6505, -2.7093, -2.5700, -1.7313, -1.9141, -2.2495, -2.1437, -2.1394],\n",
            "        [-2.2809, -1.4079, -2.0299, -2.2730, -1.6938, -2.8936, -2.8807, -2.0913],\n",
            "        [-1.9624, -2.4813, -2.6631, -1.7491, -2.1931, -1.6503, -2.0183, -2.3461],\n",
            "        [-1.8440, -1.6979, -2.3673, -2.2674, -1.6192, -2.8551, -2.7754, -1.9415],\n",
            "        [-1.8646, -2.1395, -2.5842, -2.1203, -1.5830, -2.4176, -2.1648, -2.0987],\n",
            "        [-1.9333, -2.5037, -2.3859, -1.7707, -1.8164, -2.0082, -2.1551, -2.3169],\n",
            "        [-2.2043, -1.6187, -2.3417, -2.2197, -1.5357, -2.6242, -2.4878, -2.1557],\n",
            "        [-1.9754, -2.0838, -2.1282, -2.1851, -1.7935, -2.1874, -2.1527, -2.2023],\n",
            "        [-1.7316, -2.1567, -2.5671, -1.9555, -1.6853, -2.2345, -2.3836, -2.2597],\n",
            "        [-1.9161, -2.9414, -2.3870, -1.6865, -1.6777, -2.2731, -2.0170, -2.3016],\n",
            "        [-1.7053, -2.1625, -2.3846, -2.0778, -1.8442, -2.3497, -2.2996, -2.0244],\n",
            "        [-1.8526, -2.6370, -2.2257, -1.9091, -1.7380, -2.4060, -2.2015, -1.9754],\n",
            "        [-1.9434, -1.9164, -2.4375, -2.2521, -1.5514, -2.5280, -2.4353, -1.9824],\n",
            "        [-1.6560, -1.7337, -2.4293, -2.3591, -1.8297, -2.5323, -2.4127, -2.1174],\n",
            "        [-1.7592, -2.5845, -2.4533, -1.7193, -1.7431, -2.3239, -2.2123, -2.2551],\n",
            "        [-1.9464, -1.6195, -2.2335, -2.3098, -1.8580, -2.6259, -2.6044, -1.8939],\n",
            "        [-1.8563, -2.5305, -2.5098, -1.7605, -1.8392, -2.2012, -1.9630, -2.2942]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([2, 5, 7, 7, 5, 6, 6, 7, 1, 6, 2, 7, 5, 6, 7, 5, 7, 5, 7, 6, 5, 5, 6, 4,\n",
            "        5, 0, 6, 7, 6, 6, 7, 6], device='cuda:0')\n",
            "tensor([[-2.1950, -1.4313, -2.1800, -2.4937, -1.7432, -2.6166, -2.8304, -1.9174],\n",
            "        [-1.9006, -2.6674, -2.2666, -2.0840, -1.8181, -2.0559, -2.1361, -1.9340],\n",
            "        [-2.0509, -1.9037, -2.1139, -2.1485, -1.8207, -2.2196, -2.4624, -2.0467],\n",
            "        [-1.9174, -3.4217, -2.6239, -1.8562, -1.9457, -1.8554, -1.7642, -2.1123],\n",
            "        [-2.0650, -3.6430, -2.4498, -1.4486, -2.0936, -1.7057, -2.0588, -2.3717],\n",
            "        [-1.6591, -2.7527, -2.2058, -1.9775, -1.9967, -2.1067, -2.3110, -1.9605],\n",
            "        [-1.8468, -2.2241, -2.2481, -2.0730, -1.8900, -2.1942, -2.2368, -2.0145],\n",
            "        [-1.7352, -3.1475, -2.4665, -1.8250, -2.0269, -1.9154, -1.9812, -2.1401],\n",
            "        [-1.7532, -2.0926, -2.3109, -2.0435, -1.9375, -2.3523, -2.4306, -1.9141],\n",
            "        [-1.9967, -3.0253, -2.4825, -1.7186, -1.8810, -1.8526, -1.9284, -2.3210],\n",
            "        [-2.1080, -2.1869, -2.0942, -2.0431, -1.7441, -2.4267, -2.6013, -1.7364],\n",
            "        [-2.2036, -1.7157, -2.0760, -2.2522, -1.6415, -2.3564, -2.6211, -2.1371],\n",
            "        [-2.0204, -2.3818, -2.2064, -1.9742, -1.7251, -2.3803, -2.2062, -1.9293],\n",
            "        [-2.1106, -2.4800, -2.1558, -1.8872, -1.7159, -2.2033, -2.1030, -2.1589],\n",
            "        [-1.9631, -3.1583, -2.3457, -1.7260, -1.8468, -2.1614, -1.9926, -2.0095],\n",
            "        [-2.1783, -1.6398, -2.1509, -2.2921, -1.8475, -2.4110, -2.3992, -1.9865],\n",
            "        [-1.7612, -2.5145, -2.5986, -1.9907, -1.8127, -2.0231, -1.9914, -2.2601],\n",
            "        [-2.0533, -2.8024, -2.5886, -1.8172, -2.1756, -1.5906, -1.7979, -2.4030],\n",
            "        [-1.8893, -1.6960, -2.3000, -2.5539, -1.9388, -2.1218, -2.2308, -2.1522],\n",
            "        [-1.6802, -2.6006, -2.1743, -2.0392, -2.1956, -2.0337, -2.0965, -2.0358],\n",
            "        [-1.9499, -1.6153, -2.2713, -2.2377, -1.8765, -2.5087, -2.6194, -1.9545],\n",
            "        [-1.7698, -2.1284, -2.3214, -2.1831, -1.7888, -2.3862, -2.2365, -2.0114],\n",
            "        [-1.9332, -2.6096, -2.0873, -2.0435, -1.7177, -2.2492, -2.1708, -2.0473],\n",
            "        [-2.3278, -1.1267, -2.3116, -2.6487, -1.8521, -2.5598, -2.8557, -2.1472],\n",
            "        [-2.2190, -1.6591, -2.2355, -2.2104, -1.8157, -2.3972, -2.5576, -1.8761],\n",
            "        [-1.7496, -2.8914, -2.3371, -1.8567, -1.9706, -2.0391, -2.0171, -2.1602],\n",
            "        [-1.9247, -2.1980, -2.1641, -2.1214, -1.7650, -2.2327, -2.3650, -1.9954],\n",
            "        [-2.6439, -2.5156, -2.2136, -1.6830, -1.6300, -2.1690, -2.1501, -2.0690],\n",
            "        [-2.0669, -2.0915, -2.4355, -1.9872, -1.5317, -2.2838, -2.2939, -2.2410],\n",
            "        [-2.2950, -1.7973, -2.2937, -2.2130, -1.6128, -2.2863, -2.2221, -2.1725],\n",
            "        [-1.6510, -2.6341, -2.3849, -1.8984, -2.0299, -2.1843, -2.1546, -2.0055],\n",
            "        [-2.0241, -3.9828, -2.5993, -1.3931, -2.4144, -1.6949, -1.8747, -2.3009]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([3, 5, 3, 7, 5, 5, 7, 7, 0, 6, 7, 7, 4, 6, 7, 6, 6, 5, 6, 7, 5, 5, 5, 5,\n",
            "        5, 6, 5, 5, 6, 6, 4, 5], device='cuda:0')\n",
            "tensor([[-2.3344, -2.7220, -2.0142, -2.0196, -1.8674, -1.9416, -2.1944, -1.8213],\n",
            "        [-1.6324, -2.9775, -2.4317, -2.0141, -1.8370, -2.0085, -2.1841, -2.0698],\n",
            "        [-3.5916, -3.7430, -3.8396, -1.7576, -2.8300, -1.7485, -0.7356, -3.1571],\n",
            "        [-2.1991, -2.4013, -1.9868, -2.2520, -1.9202, -2.1252, -2.1517, -1.7492],\n",
            "        [-1.9142, -2.7977, -2.1651, -2.0900, -1.9202, -2.0462, -2.1512, -1.8262],\n",
            "        [-1.9826, -2.2600, -1.8508, -2.2774, -1.8701, -2.2037, -2.4993, -1.8863],\n",
            "        [-2.3610, -1.5621, -2.0630, -2.6104, -1.8029, -2.3455, -2.6220, -1.8192],\n",
            "        [-2.2175, -2.7115, -2.0464, -2.0920, -1.7230, -1.9837, -2.2415, -1.8993],\n",
            "        [-2.0112, -3.0533, -2.1655, -1.8892, -1.8494, -1.9924, -2.1025, -1.9861],\n",
            "        [-1.9332, -2.1882, -2.0595, -2.3103, -2.0218, -2.1508, -2.3833, -1.7407],\n",
            "        [-1.8987, -3.2206, -2.3122, -1.8894, -1.7673, -2.0612, -1.9774, -2.0908],\n",
            "        [-2.1656, -2.3699, -2.2011, -1.9572, -1.8917, -1.9829, -2.2596, -1.9172],\n",
            "        [-1.8693, -3.0088, -2.2637, -2.1489, -1.9131, -1.8260, -1.8827, -2.1631],\n",
            "        [-2.0095, -2.0452, -2.2234, -2.2990, -1.6616, -2.1700, -2.3612, -2.0428],\n",
            "        [-2.3349, -1.4755, -2.2452, -2.6419, -1.9264, -2.4089, -2.4625, -1.7340],\n",
            "        [-1.9071, -3.2010, -2.1947, -2.0552, -1.9096, -1.9276, -1.9972, -1.9523],\n",
            "        [-2.1507, -3.0360, -2.2080, -1.8594, -1.8481, -1.8038, -1.9239, -2.2863],\n",
            "        [-2.1535, -2.1781, -1.9236, -2.2685, -1.9295, -2.0984, -2.2307, -1.9256],\n",
            "        [-2.1820, -2.4202, -2.6506, -2.0305, -2.2427, -1.4255, -1.8039, -2.4630],\n",
            "        [-2.0178, -2.6897, -2.1458, -2.0130, -1.9859, -1.9269, -2.3287, -1.7819],\n",
            "        [-1.9423, -2.4845, -2.0359, -2.3619, -2.0742, -2.0592, -2.0533, -1.7901],\n",
            "        [-1.8876, -3.4188, -2.1416, -1.8941, -1.9806, -1.9469, -1.9160, -2.1203],\n",
            "        [-1.8953, -2.5345, -2.3557, -2.0880, -1.9744, -2.0232, -2.1658, -1.7962],\n",
            "        [-2.4178, -1.6199, -2.1196, -2.4484, -1.7351, -2.2373, -2.5605, -1.9238],\n",
            "        [-1.7980, -2.4610, -2.5117, -2.0819, -2.0145, -1.7582, -2.0569, -2.2109],\n",
            "        [-1.7611, -2.6600, -2.4668, -2.2634, -2.0172, -1.6472, -2.0054, -2.2152],\n",
            "        [-2.0354, -2.6020, -2.1946, -2.0342, -1.8969, -1.9842, -2.0916, -1.9516],\n",
            "        [-1.8565, -3.3585, -2.2847, -1.9298, -1.8973, -1.9623, -1.9513, -2.0448],\n",
            "        [-2.6996, -1.2842, -1.9595, -2.7442, -1.8825, -2.4492, -2.9725, -1.8269],\n",
            "        [-2.1280, -3.0726, -2.3091, -1.7764, -1.9932, -1.7081, -1.8710, -2.3583],\n",
            "        [-2.1017, -2.8364, -2.3475, -1.8350, -1.7647, -2.1302, -2.0689, -1.9138],\n",
            "        [-1.9734, -3.3065, -2.5164, -1.7409, -2.0840, -1.6373, -1.8752, -2.3435]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 3, 6, 7, 0, 7, 7, 7, 6, 6, 7, 6, 6, 6, 7, 5, 3, 2, 6, 0, 5, 7, 3, 6,\n",
            "        7, 5, 6, 7, 5, 4, 6, 3], device='cuda:0')\n",
            "tensor([[-1.9507, -3.8183, -2.7248, -1.7788, -2.2462, -1.4957, -1.6782, -2.4668],\n",
            "        [-2.5255, -2.7382, -1.7505, -2.1382, -1.9289, -1.9994, -2.5525, -1.5841],\n",
            "        [-2.0363, -2.8335, -2.1343, -2.0634, -2.0623, -1.9714, -2.2248, -1.6564],\n",
            "        [-1.9832, -2.9700, -2.1093, -2.2097, -1.9743, -1.7994, -2.1424, -1.8426],\n",
            "        [-2.1906, -2.7880, -2.3474, -2.1011, -1.7607, -1.7885, -2.0589, -1.9523],\n",
            "        [-2.4050, -2.5667, -2.8012, -2.0388, -2.1776, -1.2470, -1.7769, -2.6287],\n",
            "        [-1.8576, -2.5873, -2.2604, -2.1202, -2.0118, -1.6555, -2.0645, -2.3774],\n",
            "        [-1.9246, -3.4802, -2.3748, -1.9164, -2.1008, -1.7767, -1.8079, -2.0593],\n",
            "        [-2.1536, -3.5922, -2.3920, -1.7621, -2.0652, -1.5508, -1.8325, -2.3604],\n",
            "        [-2.2159, -1.8570, -2.3020, -2.5311, -1.8650, -1.9269, -2.2070, -1.9334],\n",
            "        [-1.9534, -2.3298, -2.3938, -2.3012, -1.9564, -1.9102, -2.0676, -1.8737],\n",
            "        [-2.5521, -1.5540, -2.1959, -2.5876, -1.8559, -2.0266, -2.2851, -2.0072],\n",
            "        [-2.5519, -1.8774, -1.8394, -2.4447, -1.8890, -2.1975, -2.5021, -1.7192],\n",
            "        [-2.1920, -3.1013, -2.2357, -2.0807, -2.1013, -1.7976, -1.9563, -1.7027],\n",
            "        [-4.7364, -3.3508, -5.0002, -2.6583, -3.8501, -2.5782, -0.2742, -3.8181],\n",
            "        [-2.2971, -3.8768, -2.2246, -1.8141, -1.9923, -1.6382, -1.8437, -2.1311],\n",
            "        [-2.4515, -1.8420, -1.9728, -2.4562, -2.0499, -1.9931, -2.4528, -1.7180],\n",
            "        [-2.0260, -2.3766, -2.1341, -2.4014, -1.9547, -1.7534, -2.1890, -1.9697],\n",
            "        [-2.0056, -2.8294, -2.0940, -2.1031, -1.9674, -1.9631, -2.1817, -1.7838],\n",
            "        [-1.8904, -2.6064, -2.1655, -2.4484, -2.0546, -1.7014, -2.1425, -1.9233],\n",
            "        [-2.0250, -2.2133, -1.9995, -2.2949, -2.1284, -1.9995, -2.3088, -1.7798],\n",
            "        [-2.1714, -3.0415, -2.1483, -2.0995, -2.0275, -1.8140, -2.0847, -1.7148],\n",
            "        [-1.9608, -2.6440, -2.1846, -2.1025, -2.1516, -1.6439, -2.0962, -2.1115],\n",
            "        [-1.9981, -3.0920, -2.1539, -2.3518, -1.9653, -1.8474, -2.0726, -1.6921],\n",
            "        [-2.2784, -2.5614, -1.9938, -2.0990, -1.8983, -1.8758, -2.2275, -1.8921],\n",
            "        [-1.9849, -3.0408, -2.0567, -2.0359, -2.0281, -1.9445, -2.1044, -1.8338],\n",
            "        [-2.1351, -3.1884, -2.0457, -1.9190, -1.8799, -1.9436, -1.9056, -2.1206],\n",
            "        [-2.0717, -3.5510, -2.5030, -1.7695, -2.2381, -1.4050, -1.9106, -2.3746],\n",
            "        [-2.2113, -2.8936, -1.9631, -2.0986, -1.9679, -1.8002, -2.1909, -1.8632],\n",
            "        [-2.1134, -2.9421, -2.2679, -1.9051, -1.7447, -2.0015, -2.0697, -1.9804],\n",
            "        [-1.9269, -3.3046, -2.2255, -2.1214, -1.8695, -1.8856, -1.8706, -2.0415],\n",
            "        [-2.2765, -2.3243, -2.1114, -2.3514, -2.1027, -2.1603, -2.4003, -1.3661]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 7, 6, 5, 7, 5, 0, 3, 6, 6, 6, 6, 2, 3, 5, 5, 6, 1, 3, 7, 0, 5, 0, 5,\n",
            "        7, 7, 6, 7, 7, 0, 6, 7], device='cuda:0')\n",
            "tensor([[-2.3261, -1.9910, -2.0044, -2.3169, -2.0314, -2.0181, -2.4082, -1.7237],\n",
            "        [-2.1437, -3.7215, -2.1155, -2.0014, -2.0081, -1.9017, -1.8592, -1.8109],\n",
            "        [-2.2726, -3.7204, -2.4156, -1.7211, -2.0424, -1.5251, -1.8657, -2.2784],\n",
            "        [-2.1083, -3.5219, -2.6422, -1.6654, -2.2132, -1.4514, -1.8156, -2.4967],\n",
            "        [-2.0987, -2.7057, -1.8528, -2.3589, -2.2788, -1.9110, -2.2706, -1.5816],\n",
            "        [-2.5825, -3.1547, -1.9420, -2.1850, -1.9507, -1.7798, -1.9595, -1.7482],\n",
            "        [-1.9517, -2.8973, -2.2933, -2.4397, -2.1129, -1.6962, -1.9691, -1.7671],\n",
            "        [-2.0141, -3.2468, -2.0742, -2.2463, -2.0641, -1.8095, -1.9430, -1.8185],\n",
            "        [-2.0141, -2.8939, -2.0060, -2.2987, -2.1410, -1.9067, -2.0377, -1.7156],\n",
            "        [-2.2845, -2.5283, -1.9633, -2.1812, -1.9207, -1.8581, -2.2387, -1.8578],\n",
            "        [-2.1309, -2.9583, -2.0423, -2.1825, -2.1403, -1.9429, -2.1251, -1.5772],\n",
            "        [-2.0902, -2.7457, -2.1249, -2.4173, -2.1621, -1.8267, -2.0824, -1.5951],\n",
            "        [-1.9928, -3.0421, -2.0959, -2.0835, -2.1919, -1.6880, -2.0649, -1.9304],\n",
            "        [-2.2851, -2.9286, -2.2016, -2.1603, -2.1646, -1.6963, -1.9826, -1.6984],\n",
            "        [-1.9083, -3.1814, -2.2341, -2.0661, -2.1167, -1.4809, -2.0432, -2.3136],\n",
            "        [-2.0418, -3.0162, -2.1203, -2.1742, -1.9705, -1.7552, -2.1360, -1.8505],\n",
            "        [-1.8514, -2.8891, -2.3876, -2.0707, -1.9862, -1.6593, -1.9209, -2.3491],\n",
            "        [-3.1931, -2.3159, -3.8419, -2.4611, -2.7163, -1.5706, -0.8165, -3.2840],\n",
            "        [-2.0684, -3.7973, -2.1082, -2.0250, -2.0740, -1.9023, -1.7762, -1.8738],\n",
            "        [-2.1824, -2.7343, -2.1663, -2.1183, -2.0904, -1.5273, -2.1722, -2.0192],\n",
            "        [-2.0572, -3.2827, -2.2140, -2.0377, -2.2410, -1.9332, -1.9617, -1.5925],\n",
            "        [-2.1669, -3.5222, -2.2901, -1.9773, -1.9716, -1.6056, -1.8164, -2.1749],\n",
            "        [-2.3550, -2.5389, -1.9296, -2.3589, -2.2066, -1.8374, -2.1276, -1.6195],\n",
            "        [-1.9756, -3.4760, -2.2403, -2.1764, -2.1254, -1.7315, -1.8688, -1.8337],\n",
            "        [-2.3371, -3.1556, -2.8630, -1.8861, -2.0419, -1.2103, -1.8065, -2.8151],\n",
            "        [-1.8953, -3.6185, -2.3698, -1.9212, -2.1541, -1.6813, -1.8741, -2.0608],\n",
            "        [-2.2914, -2.5587, -1.9873, -2.4402, -2.0976, -2.0545, -2.3236, -1.3926],\n",
            "        [-2.0883, -3.2026, -2.1877, -1.9768, -2.0354, -1.7820, -1.7886, -2.1317],\n",
            "        [-2.1379, -3.5377, -1.9218, -2.1995, -2.1291, -1.8634, -1.9184, -1.7436],\n",
            "        [-2.5824, -2.6203, -1.8310, -2.2159, -2.0891, -1.9583, -2.3856, -1.4899],\n",
            "        [-2.0746, -3.3668, -2.3410, -1.7940, -2.1978, -1.8898, -2.0237, -1.6980],\n",
            "        [-2.3988, -3.3861, -2.1570, -2.0424, -1.8045, -1.8917, -1.8879, -1.8129]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 3, 5, 0, 7, 5, 6, 7, 0, 4, 3, 7, 7, 5, 5, 7, 3, 6, 3, 5, 6, 6, 6, 0,\n",
            "        6, 3, 2, 4, 6, 6, 5, 5], device='cuda:0')\n",
            "tensor([[-1.8231, -3.3127, -2.4121, -2.0458, -2.0709, -1.6781, -1.8856, -2.1317],\n",
            "        [-2.4181, -2.5833, -1.8260, -2.0548, -2.2134, -1.9543, -2.1451, -1.7250],\n",
            "        [-1.8669, -3.5284, -2.2149, -2.0452, -2.4840, -1.5767, -1.9560, -1.9239],\n",
            "        [-2.3028, -2.8166, -1.8887, -2.4204, -2.1332, -1.7453, -1.9781, -1.7798],\n",
            "        [-2.0465, -3.4954, -1.9298, -2.2154, -2.2838, -1.7808, -1.9446, -1.7559],\n",
            "        [-2.1469, -3.2645, -2.1437, -2.0175, -2.1938, -1.5898, -2.0153, -1.9241],\n",
            "        [-2.4139, -2.9164, -1.8017, -2.2459, -2.3397, -1.7563, -2.3426, -1.5121],\n",
            "        [-2.3985, -3.8563, -1.7335, -2.0894, -2.4471, -1.7401, -2.0138, -1.6501],\n",
            "        [-1.8736, -3.1943, -2.3406, -2.0423, -2.0701, -1.5864, -1.8849, -2.3355],\n",
            "        [-2.1478, -4.2287, -2.6217, -1.6096, -2.2073, -1.4974, -1.6691, -2.6048],\n",
            "        [-1.9646, -3.0960, -2.3059, -2.1136, -2.0526, -1.6845, -1.7519, -2.2375],\n",
            "        [-2.1610, -3.6289, -2.1306, -1.9406, -2.1708, -1.7626, -1.9246, -1.8063],\n",
            "        [-1.9667, -3.8539, -2.7880, -1.8044, -2.4034, -1.2911, -1.8084, -2.4832],\n",
            "        [-2.0020, -3.5776, -2.3109, -2.0039, -2.0648, -1.7805, -1.8235, -1.9232],\n",
            "        [-2.2724, -1.8670, -1.9474, -2.4912, -2.3163, -1.8918, -2.2887, -1.7954],\n",
            "        [-2.1301, -3.6155, -2.0981, -1.9399, -2.1732, -1.6722, -1.8848, -2.0072],\n",
            "        [-2.2114, -3.3675, -2.0770, -1.9950, -2.2909, -1.6591, -2.0104, -1.7764],\n",
            "        [-2.1249, -3.8351, -2.0354, -2.0487, -2.2648, -1.7717, -1.7336, -1.9046],\n",
            "        [-2.0469, -3.3597, -2.1441, -2.0071, -2.2204, -1.5287, -2.0578, -2.0291],\n",
            "        [-2.8271, -2.0362, -1.5905, -2.5203, -2.4010, -1.8633, -2.3753, -1.6753],\n",
            "        [-2.1476, -2.3010, -1.8437, -2.2041, -2.1542, -1.8735, -2.2470, -1.9717],\n",
            "        [-2.4762, -3.2577, -3.4747, -1.7949, -2.4051, -1.2348, -1.4053, -2.9205],\n",
            "        [-1.9560, -3.0099, -2.2632, -2.2259, -2.1391, -1.5059, -1.8753, -2.2595],\n",
            "        [-2.3744, -3.1247, -1.8136, -2.1450, -2.2376, -1.8283, -2.0799, -1.6581],\n",
            "        [-1.9373, -2.9062, -2.0418, -2.3891, -2.2311, -1.8184, -1.9410, -1.7930],\n",
            "        [-2.1744, -3.3002, -1.8528, -2.0677, -2.1331, -1.8860, -2.1782, -1.6994],\n",
            "        [-2.5108, -2.3296, -1.7405, -2.4619, -2.3881, -1.8771, -2.6910, -1.3938],\n",
            "        [-2.2426, -3.8205, -2.0645, -2.0081, -2.2254, -1.7288, -1.6017, -2.0900],\n",
            "        [-2.6943, -1.4144, -1.9690, -2.5214, -2.1480, -1.8793, -2.7383, -2.0001],\n",
            "        [-1.7456, -3.3395, -2.2503, -2.1021, -2.2737, -1.7265, -1.9905, -1.9313],\n",
            "        [-1.9621, -3.8902, -2.4437, -1.9276, -2.1924, -1.6095, -1.7433, -2.1196],\n",
            "        [-2.1451, -3.4838, -1.9368, -2.0212, -2.4454, -1.7844, -2.0129, -1.6745]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([0, 3, 7, 6, 7, 5, 7, 4, 0, 3, 6, 3, 7, 7, 4, 5, 5, 0, 5, 1, 4, 5, 5, 7,\n",
            "        7, 2, 7, 5, 1, 7, 7, 6], device='cuda:0')\n",
            "tensor([[-1.8993, -3.5912, -2.6366, -2.1062, -2.0219, -1.3720, -1.8284, -2.4914],\n",
            "        [-2.4780, -3.2413, -1.8142, -2.0307, -2.1217, -1.6827, -1.9768, -1.9765],\n",
            "        [-2.4581, -3.5444, -1.5773, -2.1055, -2.2869, -1.8014, -2.1462, -1.7508],\n",
            "        [-2.5565, -3.4310, -2.0077, -2.1473, -1.7947, -1.7708, -1.7162, -2.0969],\n",
            "        [-2.2008, -3.3684, -2.4290, -1.8713, -2.2044, -1.4956, -1.8133, -2.1607],\n",
            "        [-2.3809, -3.4600, -1.9554, -2.1028, -2.2494, -1.6903, -1.7817, -1.8694],\n",
            "        [-2.4947, -2.5638, -1.7868, -2.1686, -1.9735, -1.7127, -2.2336, -2.0238],\n",
            "        [-2.0291, -3.2553, -2.1858, -1.8198, -2.0017, -1.6072, -2.0033, -2.4642],\n",
            "        [-2.0731, -3.6133, -2.1254, -1.8828, -2.3682, -1.7215, -1.9571, -1.8203],\n",
            "        [-1.9283, -3.0153, -2.2789, -2.1942, -2.1651, -1.5953, -1.8211, -2.1868],\n",
            "        [-2.6374, -3.3226, -1.7632, -2.0578, -2.2449, -1.7195, -1.9954, -1.7596],\n",
            "        [-2.1428, -3.1399, -2.0556, -2.0468, -2.4000, -1.6957, -2.0208, -1.7403],\n",
            "        [-2.2589, -4.2269, -2.3987, -2.0731, -2.0838, -1.3909, -1.7065, -2.2118],\n",
            "        [-2.1234, -3.5338, -2.2081, -2.0183, -2.0550, -1.7312, -1.8201, -1.9574],\n",
            "        [-2.1690, -2.7343, -1.8286, -2.3582, -2.1567, -1.7969, -2.1952, -1.7563],\n",
            "        [-2.4100, -3.4525, -1.6990, -1.9765, -2.2313, -1.8653, -2.0953, -1.7612],\n",
            "        [-2.6457, -2.5480, -1.6738, -1.9984, -2.4832, -1.8886, -2.4941, -1.5588],\n",
            "        [-2.2532, -3.8509, -1.8995, -1.9272, -2.4131, -1.7626, -1.9931, -1.7088],\n",
            "        [-2.7138, -2.2167, -1.8530, -2.1150, -2.1752, -1.8201, -2.2071, -1.8218],\n",
            "        [-2.1588, -2.8633, -2.9635, -2.0357, -2.2426, -1.2057, -1.7053, -2.8498],\n",
            "        [-1.9552, -3.4958, -2.1731, -2.0999, -2.2634, -1.5731, -1.9718, -1.9573],\n",
            "        [-2.4017, -3.0336, -1.7887, -1.9810, -2.4384, -1.8644, -2.0435, -1.6911],\n",
            "        [-2.0449, -3.6166, -2.1597, -1.9426, -2.1710, -1.7896, -1.8777, -1.8904],\n",
            "        [-2.3164, -2.9463, -2.2089, -2.2379, -1.9317, -1.5171, -1.9557, -2.0666],\n",
            "        [-2.0777, -3.4739, -2.1451, -1.9352, -2.0380, -1.8496, -1.8319, -2.0052],\n",
            "        [-2.1410, -3.3324, -2.0952, -2.0083, -2.1223, -1.9404, -1.7885, -1.8396],\n",
            "        [-2.1388, -4.0040, -2.1591, -1.6726, -2.2027, -1.7041, -1.8305, -2.2258],\n",
            "        [-1.8259, -3.5188, -2.2298, -2.0630, -2.1655, -1.5302, -1.9898, -2.2373],\n",
            "        [-1.8902, -2.8310, -2.0557, -2.2652, -2.2121, -1.7157, -2.0459, -1.9688],\n",
            "        [-2.6354, -3.0881, -1.6203, -2.1078, -2.2540, -1.8304, -2.3119, -1.6146],\n",
            "        [-1.9914, -2.6596, -1.9904, -2.3260, -2.1582, -1.7058, -1.9959, -2.0703],\n",
            "        [-2.1078, -3.7167, -2.2976, -1.9931, -2.0094, -1.6878, -1.7254, -2.1176]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 3, 7, 4, 5, 5, 1, 0, 7, 7, 6, 5, 5, 5, 6, 7, 5, 7, 7, 5, 6, 0, 7, 5,\n",
            "        0, 0, 5, 6, 7, 7, 6, 3], device='cuda:0')\n",
            "tensor([[-2.3210, -3.1271, -1.8284, -2.0861, -2.3062, -1.9221, -2.0056, -1.6471],\n",
            "        [-2.1632, -3.7404, -2.3790, -1.6760, -2.0487, -1.6128, -1.9206, -2.2370],\n",
            "        [-2.2960, -2.9469, -1.7549, -2.2063, -2.4732, -1.7933, -2.2766, -1.5585],\n",
            "        [-1.7922, -3.9005, -2.4884, -1.7741, -2.2280, -1.6350, -1.7417, -2.4938],\n",
            "        [-1.9232, -3.5529, -2.3448, -1.9964, -2.2838, -1.5645, -1.8945, -2.0246],\n",
            "        [-1.9941, -3.4552, -2.6008, -1.9921, -2.1457, -1.2470, -1.9765, -2.5414],\n",
            "        [-1.9691, -4.1031, -2.1626, -1.8713, -2.1972, -1.8464, -1.7984, -1.9629],\n",
            "        [-2.1876, -4.4950, -2.5462, -1.8273, -2.1439, -1.4115, -1.6498, -2.4727],\n",
            "        [-1.8352, -3.7027, -2.3233, -1.9499, -2.2828, -1.5305, -1.8754, -2.2653],\n",
            "        [-1.8971, -3.6755, -2.1891, -1.9536, -2.3359, -1.6402, -2.0215, -1.9121],\n",
            "        [-3.6451, -3.4979, -4.1977, -2.1806, -3.2360, -1.5308, -0.6349, -3.5078],\n",
            "        [-1.9499, -2.8071, -2.1924, -2.2315, -2.1219, -1.6534, -1.9515, -2.0789],\n",
            "        [-2.1257, -3.1434, -2.2456, -1.9593, -1.9937, -1.5750, -1.9104, -2.3080],\n",
            "        [-1.9920, -2.6423, -2.0465, -2.1906, -2.2662, -1.6844, -2.0936, -1.9743],\n",
            "        [-2.2028, -3.3765, -1.8720, -2.0653, -2.3286, -1.7024, -2.1583, -1.7174],\n",
            "        [-2.0491, -3.6973, -2.6621, -1.9028, -2.2665, -1.2930, -1.7591, -2.5629],\n",
            "        [-2.1255, -3.4298, -2.4177, -1.9294, -2.1088, -1.7021, -1.6972, -2.0636],\n",
            "        [-1.8715, -4.0256, -2.3022, -1.7226, -2.3298, -1.6880, -1.9242, -2.1085],\n",
            "        [-2.0217, -3.7495, -2.5811, -1.8317, -2.2599, -1.3701, -1.8988, -2.3024],\n",
            "        [-2.1007, -3.7154, -2.5398, -1.7867, -1.9304, -1.5379, -1.8069, -2.4913],\n",
            "        [-1.9839, -3.6513, -2.5027, -1.8711, -1.8268, -1.6081, -1.8325, -2.5322],\n",
            "        [-2.1848, -1.9794, -2.0574, -2.4266, -2.0760, -1.8429, -2.0857, -2.0777],\n",
            "        [-2.7313, -2.7578, -1.6263, -2.0921, -2.1327, -1.7644, -2.1572, -1.9248],\n",
            "        [-2.2600, -3.4256, -1.9604, -1.9165, -2.2321, -1.6796, -2.1379, -1.8107],\n",
            "        [-1.9791, -2.7136, -1.9840, -2.1096, -1.9770, -1.8322, -2.1732, -2.0847],\n",
            "        [-2.1301, -3.5806, -3.0490, -1.8493, -2.0823, -1.2245, -1.6982, -3.0577],\n",
            "        [-2.0925, -3.8776, -2.8263, -1.7864, -1.8874, -1.4957, -1.7399, -2.5508],\n",
            "        [-2.0748, -3.5874, -2.2238, -1.8125, -2.4704, -1.7803, -2.0158, -1.6663],\n",
            "        [-2.3232, -2.4205, -1.9551, -2.4484, -2.1110, -1.7702, -1.9494, -1.8879],\n",
            "        [-1.8690, -3.8768, -2.3897, -1.8851, -2.2009, -1.4345, -1.9377, -2.4242],\n",
            "        [-2.0604, -2.2958, -2.5052, -2.2212, -1.7648, -1.7011, -1.9428, -2.4678],\n",
            "        [-2.3922, -2.3006, -1.8156, -2.5287, -2.0859, -1.8818, -2.1737, -1.7394]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 6, 7, 6, 5, 5, 3, 6, 2, 6, 6, 6, 4, 5, 6, 6, 6, 0, 6, 6, 3, 1, 5, 6,\n",
            "        6, 6, 5, 6, 2, 7, 1, 7], device='cuda:0')\n",
            "tensor([[-1.7793, -3.9680, -2.5197, -1.6889, -2.0553, -1.7579, -1.8422, -2.4282],\n",
            "        [-2.0882, -3.6409, -2.3109, -1.7883, -1.7830, -1.7529, -1.8176, -2.5303],\n",
            "        [-2.1025, -3.5322, -2.0482, -1.8503, -2.3017, -1.8709, -1.9598, -1.7868],\n",
            "        [-2.4330, -2.5908, -1.8093, -1.9820, -2.2272, -2.0461, -2.2593, -1.6388],\n",
            "        [-2.3310, -4.0235, -2.4358, -1.7829, -2.0373, -1.4941, -1.7100, -2.3694],\n",
            "        [-1.8937, -3.3075, -2.0510, -1.9518, -2.1934, -1.8087, -2.2482, -1.8248],\n",
            "        [-2.0517, -3.8277, -2.0597, -1.8889, -2.0224, -1.8960, -1.7940, -2.1023],\n",
            "        [-2.0645, -3.4282, -1.8370, -2.0036, -2.4708, -1.7556, -2.1747, -1.7398],\n",
            "        [-2.2294, -2.7898, -1.8889, -2.2522, -2.0830, -1.8478, -2.0638, -1.7991],\n",
            "        [-2.3502, -1.7310, -2.3160, -2.2419, -1.9181, -2.0442, -1.8571, -2.4066],\n",
            "        [-2.5533, -2.4143, -1.6319, -2.2933, -2.3615, -1.9016, -2.2214, -1.6919],\n",
            "        [-2.4453, -2.5799, -1.7821, -2.1976, -2.0179, -1.8255, -2.2386, -1.8484],\n",
            "        [-2.0650, -3.1979, -2.1182, -1.9905, -2.0662, -1.8479, -1.9293, -1.9243],\n",
            "        [-2.0157, -3.7595, -2.3303, -1.6853, -2.1939, -1.6968, -1.9841, -2.0514],\n",
            "        [-1.6821, -3.7208, -2.4178, -1.9746, -2.3782, -1.7840, -1.7819, -2.0184],\n",
            "        [-1.9370, -2.8827, -2.1607, -2.1804, -2.0768, -1.5985, -2.0573, -2.1516],\n",
            "        [-5.4242, -3.9615, -5.9631, -3.2619, -4.7046, -2.1967, -0.2192, -4.4006]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 2, 3, 6, 6, 0, 7, 7, 5, 1, 7, 7, 0, 3, 7, 7, 7], device='cuda:0')\n",
            "\n",
            "Evaluating...\n",
            "tensor(1.9740, device='cuda:0')\n",
            "tensor(1.8613, device='cuda:0')\n",
            "\n",
            "Training Loss: 1.975\n",
            "Validation Loss: 1.918\n",
            "\n",
            " Epoch 7 / 10\n",
            "tensor([[-2.0700, -2.9953, -2.2146, -2.0129, -1.9652, -1.6853, -1.8653, -2.2963],\n",
            "        [-2.0810, -3.0129, -1.9831, -1.7541, -2.5286, -1.9985, -2.2819, -1.6199],\n",
            "        [-2.1031, -4.3793, -2.9618, -1.4978, -2.3035, -1.3186, -1.7087, -3.1819],\n",
            "        [-1.8995, -3.5977, -2.9712, -1.5499, -2.2655, -1.3950, -1.8109, -3.1159],\n",
            "        [-1.8983, -2.9235, -2.2297, -1.9425, -2.2733, -1.7770, -1.8725, -2.1230],\n",
            "        [-1.6350, -3.1073, -2.5860, -2.0160, -2.0092, -1.8036, -1.8830, -2.2939],\n",
            "        [-1.8834, -3.3331, -2.7186, -1.8967, -2.1426, -1.4072, -1.7865, -2.7110],\n",
            "        [-2.0893, -3.3936, -2.1814, -1.7701, -2.1261, -1.9044, -1.9056, -1.9485],\n",
            "        [-1.8622, -4.1291, -2.5632, -1.7202, -2.0092, -1.7989, -1.7579, -2.2977],\n",
            "        [-1.9460, -2.9319, -2.1512, -1.8694, -2.2701, -1.9428, -1.9089, -1.9772],\n",
            "        [-1.9762, -3.6037, -2.2221, -1.7946, -2.1438, -1.7294, -1.8286, -2.2597],\n",
            "        [-2.0086, -3.1904, -2.3637, -1.7343, -2.1735, -1.7288, -1.9182, -2.1547],\n",
            "        [-1.8734, -3.5298, -2.0166, -2.1488, -2.0143, -2.0499, -1.7893, -1.9797],\n",
            "        [-1.9410, -3.5355, -2.3710, -1.6810, -2.0971, -1.7807, -1.9141, -2.2173],\n",
            "        [-1.8683, -3.6053, -2.3754, -1.6725, -2.2751, -1.7341, -1.9209, -2.1904],\n",
            "        [-1.9585, -3.3278, -2.0546, -1.8423, -2.4458, -2.0218, -1.9941, -1.7079],\n",
            "        [-1.8001, -3.5060, -2.2933, -1.9095, -2.1051, -1.7460, -1.8472, -2.2865],\n",
            "        [-1.8602, -2.7650, -2.0376, -2.0957, -2.3133, -1.9126, -2.1402, -1.8092],\n",
            "        [-1.6275, -3.0177, -2.6448, -2.0216, -2.1832, -1.5088, -1.9477, -2.5937],\n",
            "        [-2.2470, -2.2531, -1.7871, -2.2314, -2.1458, -2.0770, -2.1007, -1.8988],\n",
            "        [-2.0001, -4.3409, -2.9213, -1.4671, -2.3430, -1.3673, -1.8306, -2.8817],\n",
            "        [-2.2564, -2.0942, -1.6799, -2.3793, -2.1697, -2.1685, -2.5310, -1.6876],\n",
            "        [-1.9242, -2.9359, -2.4894, -2.1194, -2.0062, -1.5495, -1.7983, -2.4601],\n",
            "        [-2.0426, -3.4793, -2.0956, -1.6900, -2.2856, -1.8534, -1.8850, -2.1061],\n",
            "        [-1.7468, -3.9955, -2.2510, -1.7105, -2.3180, -1.8369, -1.9120, -2.1572],\n",
            "        [-1.8787, -3.3662, -1.9496, -1.9697, -2.0750, -1.9526, -2.0234, -2.0311],\n",
            "        [-1.5826, -3.5364, -2.4572, -1.9516, -2.2624, -1.8600, -1.7982, -2.1862],\n",
            "        [-2.0247, -3.0509, -1.9816, -1.9161, -2.2945, -1.9604, -1.9471, -1.8882],\n",
            "        [-2.4351, -1.3034, -2.0074, -2.7645, -2.0951, -2.2632, -2.4302, -2.0528],\n",
            "        [-2.3043, -3.1437, -2.1462, -1.7025, -2.0164, -1.8563, -2.0097, -2.0062],\n",
            "        [-2.1146, -2.9423, -2.1210, -2.1102, -2.0132, -1.7668, -1.9395, -1.9862],\n",
            "        [-1.9064, -2.5354, -2.1061, -2.3849, -2.1336, -1.7988, -2.0858, -1.8957]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 7, 3, 3, 6, 0, 5, 7, 5, 3, 6, 6, 7, 6, 5, 6, 5, 7, 7, 6, 5, 7, 5, 6,\n",
            "        7, 6, 7, 6, 1, 3, 7, 7], device='cuda:0')\n",
            "tensor([[-1.9935, -3.0912, -2.2279, -1.9374, -2.2127, -1.8324, -1.8340, -1.9857],\n",
            "        [-2.5750, -2.2435, -1.8222, -1.9929, -2.3636, -1.9193, -2.2951, -1.7245],\n",
            "        [-2.0092, -1.7741, -2.0874, -2.4284, -2.2054, -2.1893, -2.1390, -1.9372],\n",
            "        [-3.5179, -0.9990, -1.5518, -2.7048, -2.6392, -2.6992, -2.7852, -2.0962],\n",
            "        [-2.0305, -3.0677, -2.2537, -1.6165, -2.3170, -1.9494, -2.0119, -1.9384],\n",
            "        [-1.8918, -2.5971, -2.6634, -2.0573, -2.2234, -1.3831, -1.9232, -2.6308],\n",
            "        [-2.2270, -2.4468, -1.7973, -2.1130, -2.3758, -2.0738, -2.0833, -1.7385],\n",
            "        [-1.9220, -2.8806, -2.0227, -1.9367, -2.4797, -2.0937, -1.8992, -1.8053],\n",
            "        [-1.8290, -3.7328, -2.2187, -1.8256, -2.3659, -1.7455, -1.8065, -2.1807],\n",
            "        [-2.0614, -3.3567, -3.1479, -1.8201, -2.3987, -1.2250, -1.6185, -2.9929],\n",
            "        [-1.6898, -2.9841, -2.3591, -2.1296, -2.1948, -1.6116, -2.0456, -2.1963],\n",
            "        [-1.8880, -2.5957, -2.6300, -2.1656, -1.9590, -1.7129, -1.7238, -2.4358],\n",
            "        [-2.1517, -1.9130, -1.9599, -2.4749, -2.3255, -2.1978, -1.9459, -1.8364],\n",
            "        [-2.4484, -2.2625, -1.8700, -2.0224, -2.1557, -1.9048, -2.1848, -1.9252],\n",
            "        [-2.1622, -2.8810, -2.0781, -1.8454, -2.1377, -2.0314, -2.1407, -1.7200],\n",
            "        [-1.8979, -2.8026, -2.0484, -2.0380, -2.1155, -1.9418, -2.0479, -1.9864],\n",
            "        [-2.0258, -1.9574, -2.1412, -2.2527, -2.0984, -2.0255, -1.9364, -2.2493],\n",
            "        [-1.9797, -3.8478, -2.0572, -1.6805, -2.2126, -1.8525, -1.8985, -2.2035],\n",
            "        [-1.9680, -3.0564, -2.2221, -1.7875, -2.4493, -1.8365, -1.9375, -1.9128],\n",
            "        [-1.9504, -3.5904, -2.5261, -1.6569, -2.2634, -1.6742, -1.8226, -2.2403],\n",
            "        [-1.7113, -3.0362, -2.5361, -1.9097, -2.1397, -1.5842, -1.9685, -2.5062],\n",
            "        [-2.1223, -2.7172, -2.0698, -2.0657, -2.3257, -2.0563, -1.9081, -1.6755],\n",
            "        [-1.8586, -2.6958, -2.6569, -2.0929, -2.3527, -1.2343, -2.0571, -2.6716],\n",
            "        [-2.0121, -2.6490, -2.1434, -2.0221, -2.0691, -2.0090, -2.0034, -1.8929],\n",
            "        [-1.7597, -4.1402, -2.4642, -1.6432, -2.2993, -1.7748, -1.8876, -2.1869],\n",
            "        [-2.7860, -3.9979, -3.4231, -1.7436, -2.3942, -1.2662, -1.2091, -3.1975],\n",
            "        [-2.4420, -2.0431, -1.5831, -2.2314, -2.3827, -2.2979, -2.4051, -1.6732],\n",
            "        [-1.8957, -4.0186, -2.4997, -1.6376, -2.2215, -1.7331, -1.6997, -2.4382],\n",
            "        [-2.3647, -2.4132, -2.1637, -2.0271, -2.1181, -2.0105, -1.8169, -1.8763],\n",
            "        [-1.9631, -2.8361, -2.2044, -1.8671, -2.1343, -2.0339, -1.8657, -2.0240],\n",
            "        [-2.0680, -2.9924, -2.0647, -1.8339, -2.2476, -1.8639, -1.8919, -2.0776],\n",
            "        [-1.7235, -3.4443, -2.2821, -1.8015, -2.3473, -2.0059, -1.9037, -1.9425]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 5, 4, 1, 7, 5, 4, 7, 7, 5, 7, 6, 6, 5, 0, 6, 2, 2, 5, 5, 5, 7, 5, 7,\n",
            "        0, 6, 7, 6, 3, 6, 7, 3], device='cuda:0')\n",
            "tensor([[-1.7145, -2.3771, -2.3690, -2.2549, -2.1572, -1.7183, -1.9754, -2.3545],\n",
            "        [-2.2252, -1.7797, -1.9708, -2.1366, -2.1938, -2.3633, -2.1067, -1.9761],\n",
            "        [-2.4755, -1.8673, -1.7209, -2.3481, -2.3441, -2.2238, -2.3003, -1.7008],\n",
            "        [-1.8716, -2.2949, -1.9801, -2.2748, -2.4463, -2.2305, -2.0163, -1.7303],\n",
            "        [-1.8756, -2.6619, -2.2500, -1.8554, -2.2753, -2.1115, -1.9306, -1.9225],\n",
            "        [-1.9584, -2.6227, -2.0674, -1.9837, -2.0972, -1.9537, -1.9342, -2.1791],\n",
            "        [-1.9290, -2.2525, -1.9813, -2.1909, -2.3871, -2.2211, -2.2672, -1.6303],\n",
            "        [-1.9495, -2.4564, -2.1197, -1.9077, -2.2135, -2.0995, -2.2086, -1.8219],\n",
            "        [-2.0428, -3.7521, -2.4843, -1.5600, -2.2028, -1.6502, -1.8474, -2.3729],\n",
            "        [-2.3758, -1.6221, -1.8196, -2.4788, -2.4228, -2.4808, -2.3552, -1.6276],\n",
            "        [-2.1645, -1.8206, -2.1301, -2.2564, -2.1825, -2.1940, -1.9237, -2.0447],\n",
            "        [-2.0844, -2.9394, -2.3279, -2.0292, -2.1705, -1.7363, -1.7029, -2.1092],\n",
            "        [-2.1227, -2.9587, -2.6821, -1.9600, -2.1546, -1.2559, -1.8619, -2.7653],\n",
            "        [-1.9754, -3.1083, -2.6068, -1.5665, -2.1482, -1.5878, -1.8959, -2.7678],\n",
            "        [-1.6759, -2.8748, -2.2014, -2.1413, -2.1421, -1.8503, -1.9387, -2.2090],\n",
            "        [-2.3366, -2.1651, -1.8214, -2.2039, -2.2949, -2.0663, -2.1847, -1.7344],\n",
            "        [-1.8838, -2.6345, -2.1718, -1.9517, -2.2985, -1.9565, -1.9961, -1.9477],\n",
            "        [-2.1473, -2.6489, -2.2859, -1.8577, -2.0388, -1.9790, -1.8840, -2.0071],\n",
            "        [-1.8257, -2.4949, -2.7119, -2.2282, -2.1504, -1.3925, -1.9366, -2.6151],\n",
            "        [-1.9063, -2.4572, -2.2753, -1.9540, -2.0138, -2.0758, -2.0377, -2.0252],\n",
            "        [-2.1143, -1.5096, -1.9966, -2.3413, -2.3915, -2.2962, -2.5237, -1.8708],\n",
            "        [-1.7994, -2.7390, -2.5282, -2.1244, -2.1173, -1.6698, -1.8106, -2.3180],\n",
            "        [-1.9882, -1.8396, -2.0007, -2.4426, -2.4386, -2.0724, -2.0109, -2.0028],\n",
            "        [-1.8960, -3.4472, -2.8757, -1.5562, -2.1799, -1.4423, -1.9752, -2.7728],\n",
            "        [-1.6534, -2.4634, -2.3683, -2.1109, -2.1902, -1.9806, -2.0157, -2.0748],\n",
            "        [-1.7903, -3.0919, -2.3475, -1.7767, -2.2380, -2.1018, -1.9393, -1.8961],\n",
            "        [-2.3504, -1.7701, -1.9078, -2.3021, -2.4312, -2.4021, -2.4818, -1.4969],\n",
            "        [-1.8725, -3.2700, -2.5305, -1.6073, -2.0787, -1.6425, -2.0049, -2.5909],\n",
            "        [-1.8716, -2.9685, -1.9638, -1.8383, -2.2204, -2.3118, -1.9872, -1.8931],\n",
            "        [-1.8513, -2.6426, -2.2311, -1.8953, -2.4038, -2.1537, -2.0774, -1.7014],\n",
            "        [-1.9214, -3.4584, -2.6704, -1.9403, -1.9092, -1.6132, -1.7523, -2.4258],\n",
            "        [-2.5095, -1.6193, -1.7323, -2.4734, -2.2789, -2.5862, -2.4836, -1.6178]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 6, 5, 0, 7, 6, 7, 7, 5, 5, 4, 6, 0, 6, 2, 5, 3, 6, 5, 6, 6, 5, 7, 3,\n",
            "        5, 0, 0, 6, 2, 6, 5, 7], device='cuda:0')\n",
            "tensor([[-1.7852, -2.4212, -2.2219, -1.9172, -2.4119, -2.0325, -2.0297, -1.9953],\n",
            "        [-2.0533, -1.6128, -1.9670, -2.5277, -2.4141, -2.3069, -2.2129, -1.8692],\n",
            "        [-1.8155, -2.7188, -1.9368, -1.9603, -2.1573, -2.2927, -2.1520, -1.8745],\n",
            "        [-2.6160, -1.7002, -1.9687, -2.1871, -2.0973, -2.3543, -1.9149, -2.0613],\n",
            "        [-1.7935, -3.1662, -2.2619, -1.8225, -2.1061, -1.9676, -1.8148, -2.2895],\n",
            "        [-1.8640, -2.7042, -2.3921, -2.0078, -2.1105, -1.5119, -1.9564, -2.6697],\n",
            "        [-2.1390, -1.8081, -1.8929, -2.1168, -2.2414, -2.3780, -2.2678, -1.9336],\n",
            "        [-1.7088, -3.3744, -2.4071, -1.8303, -2.2245, -1.8772, -1.8581, -2.1445],\n",
            "        [-1.7686, -3.2174, -2.1442, -1.8805, -2.5541, -2.0657, -1.8604, -1.8350],\n",
            "        [-2.0475, -2.8878, -2.2724, -1.6923, -2.3965, -2.1997, -1.7936, -1.8335],\n",
            "        [-1.9627, -2.3811, -1.9733, -1.8665, -2.2807, -2.1047, -2.2309, -1.9528],\n",
            "        [-1.7589, -2.5109, -2.0222, -2.0956, -2.1244, -2.0057, -2.0828, -2.1842],\n",
            "        [-2.2612, -1.8550, -2.1360, -1.9303, -2.5289, -2.3491, -2.0819, -1.7362],\n",
            "        [-2.3977, -2.0176, -1.7624, -2.1015, -2.1913, -2.4821, -2.3677, -1.6443],\n",
            "        [-2.3785, -1.2903, -2.1229, -2.7433, -2.1134, -2.5046, -2.0166, -2.1853],\n",
            "        [-2.3840, -1.7462, -1.8348, -2.0646, -2.3722, -2.4097, -2.2075, -1.8723],\n",
            "        [-1.7578, -2.4043, -2.2241, -1.7268, -2.3217, -2.2719, -2.0494, -2.1103],\n",
            "        [-1.9772, -2.5010, -2.6744, -1.9848, -2.0712, -1.3715, -1.9174, -3.0697],\n",
            "        [-1.7898, -3.6157, -2.3946, -1.5228, -2.3600, -1.7513, -1.9134, -2.5102],\n",
            "        [-1.9279, -2.6110, -2.0650, -1.8346, -2.2837, -2.2686, -2.0175, -1.8564],\n",
            "        [-1.6463, -2.7032, -2.4791, -2.1251, -2.2804, -1.4998, -1.9865, -2.5984],\n",
            "        [-1.9981, -3.1310, -2.3390, -1.7072, -2.1662, -1.9810, -1.7880, -2.0948],\n",
            "        [-2.0777, -2.5655, -2.1070, -1.8541, -2.0265, -2.1305, -1.8350, -2.2116],\n",
            "        [-3.0797, -0.9981, -1.5238, -2.9349, -2.5495, -3.1900, -2.9081, -1.9620],\n",
            "        [-1.6956, -2.3538, -2.1095, -2.2219, -2.2196, -2.1975, -2.0895, -1.9085],\n",
            "        [-2.1785, -3.3497, -2.6860, -1.5463, -2.1668, -1.4080, -1.8623, -2.8824],\n",
            "        [-1.6281, -3.4684, -2.4231, -1.9211, -2.3630, -1.6725, -1.8403, -2.3355],\n",
            "        [-2.0971, -2.5339, -1.7180, -2.0235, -2.4385, -2.3210, -2.2394, -1.6387],\n",
            "        [-2.1026, -2.6214, -2.1268, -1.8315, -2.1208, -2.1619, -1.8520, -2.0113],\n",
            "        [-2.0444, -2.1353, -2.1983, -2.0774, -2.2035, -2.0069, -1.9859, -2.0098],\n",
            "        [-2.0572, -2.6105, -1.9693, -1.9112, -2.0419, -2.1685, -2.0178, -2.0088],\n",
            "        [-1.8985, -2.5990, -2.0226, -1.9734, -2.4226, -2.1009, -2.0359, -1.8142]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 5, 0, 6, 6, 5, 7, 3, 0, 6, 7, 7, 6, 6, 1, 6, 0, 6, 6, 3, 6, 5, 5, 2,\n",
            "        7, 5, 0, 3, 6, 6, 5, 6], device='cuda:0')\n",
            "tensor([[-1.5807, -3.4311, -2.5428, -1.7225, -2.2243, -1.8457, -1.8174, -2.5764],\n",
            "        [-2.3819, -0.7093, -2.3199, -3.1704, -2.5407, -2.9261, -2.6365, -2.6404],\n",
            "        [-1.7209, -2.3365, -1.8616, -2.3950, -2.2955, -2.2508, -1.9745, -2.0176],\n",
            "        [-1.9556, -1.4682, -2.1152, -2.6277, -2.3036, -2.2905, -2.1396, -2.1498],\n",
            "        [-2.1211, -2.6399, -1.6835, -1.8108, -2.3722, -2.2175, -2.1927, -1.9261],\n",
            "        [-2.0324, -1.7063, -1.7286, -2.2601, -2.4754, -2.5941, -2.3517, -1.8871],\n",
            "        [-2.1275, -2.0013, -1.8979, -2.0121, -2.2099, -2.4210, -1.9535, -2.1053],\n",
            "        [-2.5147, -1.0716, -1.8883, -2.7717, -2.6402, -2.4724, -2.7735, -1.9338],\n",
            "        [-2.0578, -2.0880, -2.0877, -2.0589, -2.0534, -2.1555, -1.8673, -2.3221],\n",
            "        [-1.9329, -1.5374, -2.3222, -2.3041, -2.3768, -2.4062, -2.0963, -1.9914],\n",
            "        [-1.8467, -2.7842, -2.3207, -1.8550, -2.0564, -2.2950, -1.5916, -2.3695],\n",
            "        [-1.6017, -2.7921, -2.0083, -2.0225, -2.4341, -2.1173, -1.9055, -2.1731],\n",
            "        [-1.9933, -1.9632, -2.0059, -2.0635, -2.2071, -2.5579, -1.9901, -1.9833],\n",
            "        [-1.9723, -2.9014, -1.8891, -1.7930, -2.2843, -2.4449, -1.9001, -1.8964],\n",
            "        [-1.6152, -2.4752, -2.0098, -2.0425, -2.1880, -2.1709, -2.1431, -2.2094],\n",
            "        [-2.2595, -2.7753, -3.3372, -2.1975, -2.5374, -1.0750, -1.5507, -2.9152],\n",
            "        [-1.7634, -3.7420, -2.7418, -1.5187, -2.1563, -1.5684, -1.8698, -3.1441],\n",
            "        [-2.3232, -1.3779, -1.8832, -2.3959, -2.5677, -2.8872, -2.3096, -1.7430],\n",
            "        [-2.1118, -2.0474, -1.8239, -2.1094, -2.1956, -2.5094, -1.9514, -2.0209],\n",
            "        [-2.0342, -3.4108, -2.1313, -1.6119, -2.3052, -1.6939, -1.9096, -2.4495],\n",
            "        [-2.3693, -1.2488, -2.0606, -2.0201, -2.4917, -2.8234, -2.5047, -1.9972],\n",
            "        [-1.9134, -2.0925, -2.1057, -1.9496, -2.2206, -2.3319, -1.9105, -2.1955],\n",
            "        [-2.0186, -2.2939, -1.7886, -2.1494, -2.4438, -2.4383, -2.1389, -1.6574],\n",
            "        [-1.9459, -2.4127, -2.6118, -2.0984, -2.2937, -1.3062, -1.9381, -2.8857],\n",
            "        [-2.7658, -0.8620, -1.9667, -2.9655, -2.4200, -2.8326, -2.4977, -2.3727],\n",
            "        [-2.2038, -4.1769, -2.6405, -1.3686, -2.2183, -1.6782, -1.5930, -3.0025],\n",
            "        [-1.8668, -3.5761, -2.3622, -1.5667, -2.3107, -1.9211, -1.7026, -2.4464],\n",
            "        [-1.7480, -3.1807, -2.6695, -1.6517, -2.4838, -1.3987, -2.0464, -2.7528],\n",
            "        [-1.8005, -1.5775, -2.0452, -2.5307, -2.3164, -2.3772, -2.0590, -2.2995],\n",
            "        [-1.8513, -2.8085, -2.2083, -2.1324, -2.3291, -1.5972, -1.8804, -2.2841],\n",
            "        [-1.9105, -2.3874, -1.9268, -1.9287, -2.2685, -2.6344, -1.9229, -1.9121],\n",
            "        [-1.7313, -2.7303, -2.4089, -1.9496, -2.1015, -1.6123, -1.9838, -2.7144]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([3, 1, 2, 7, 7, 7, 6, 5, 6, 4, 6, 7, 0, 3, 7, 6, 3, 2, 4, 5, 3, 6, 6, 6,\n",
            "        5, 4, 0, 5, 6, 5, 7, 0], device='cuda:0')\n",
            "tensor([[-2.1251, -1.8348, -1.6972, -2.3846, -2.2776, -2.4926, -2.0002, -2.0787],\n",
            "        [-1.9317, -1.7061, -1.9015, -2.3678, -2.1450, -2.5306, -2.1315, -2.1614],\n",
            "        [-2.3055, -1.5837, -1.7754, -2.2336, -2.2067, -2.7806, -2.0628, -2.1256],\n",
            "        [-1.4854, -2.5705, -2.1557, -2.0296, -2.2160, -2.0457, -2.0106, -2.5558],\n",
            "        [-1.8379, -1.9265, -1.9829, -2.2866, -2.0889, -2.6385, -1.7541, -2.4354],\n",
            "        [-2.9961, -0.3843, -2.7210, -3.4757, -2.8570, -3.4853, -3.0695, -3.2750],\n",
            "        [-1.6978, -2.3219, -2.1505, -2.1393, -2.2362, -1.7086, -2.0743, -2.6445],\n",
            "        [-1.7381, -3.1314, -1.9314, -1.8975, -2.1735, -2.1364, -1.7961, -2.4328],\n",
            "        [-2.3423, -1.2657, -1.6846, -2.3716, -2.7115, -2.7834, -2.3547, -2.1218],\n",
            "        [-1.6347, -3.1298, -2.1477, -1.8534, -2.2145, -2.3637, -1.6686, -2.3432],\n",
            "        [-2.5117, -1.1978, -1.8593, -2.4676, -2.2063, -2.8567, -2.4117, -2.1270],\n",
            "        [-1.7925, -2.1547, -1.8635, -2.1186, -2.3049, -2.5282, -1.9436, -2.1250],\n",
            "        [-1.8103, -2.2411, -1.8099, -2.1831, -2.2331, -2.3578, -2.0087, -2.1395],\n",
            "        [-1.7839, -2.2445, -1.9942, -1.9366, -2.0896, -2.4334, -1.9656, -2.3628],\n",
            "        [-1.6939, -2.2603, -2.6085, -2.1396, -2.1845, -1.6027, -1.8945, -2.8776],\n",
            "        [-2.4595, -1.6313, -1.6358, -2.1579, -2.1857, -2.8925, -2.1067, -2.1286],\n",
            "        [-1.8059, -3.6766, -2.4658, -1.3797, -2.3431, -1.7218, -1.9477, -2.8755],\n",
            "        [-1.9332, -3.9660, -2.8143, -1.4203, -2.3456, -1.4028, -1.8466, -3.3437],\n",
            "        [-1.8435, -3.0799, -2.2438, -1.7613, -2.2394, -2.1789, -1.5926, -2.3560],\n",
            "        [-1.7634, -2.7900, -2.9374, -2.0061, -2.2647, -1.2892, -1.8727, -3.0676],\n",
            "        [-2.6816, -0.7484, -2.1573, -2.8584, -2.3994, -3.1506, -2.7424, -2.4370],\n",
            "        [-2.5419, -0.8778, -1.6953, -3.2115, -2.4148, -3.1881, -2.6315, -2.5363],\n",
            "        [-1.8101, -2.2367, -1.9198, -2.1127, -2.1061, -2.3303, -1.8319, -2.4898],\n",
            "        [-2.0300, -2.1197, -1.6845, -1.9470, -2.3853, -2.6497, -2.0964, -2.0045],\n",
            "        [-2.0469, -1.4869, -1.8170, -2.3285, -2.5240, -2.7087, -2.1570, -2.1003],\n",
            "        [-1.9499, -2.2380, -1.5525, -2.1656, -2.4051, -2.5759, -2.1343, -1.9663],\n",
            "        [-2.3239, -1.1550, -1.8511, -2.7149, -2.4981, -2.8494, -2.4252, -2.0011],\n",
            "        [-2.2262, -1.7875, -1.6711, -2.1764, -2.1477, -2.7400, -2.0863, -2.1394],\n",
            "        [-2.0276, -2.0176, -1.6363, -2.1733, -2.3394, -2.6587, -2.0958, -1.9842],\n",
            "        [-2.6557, -1.2118, -1.5934, -2.6427, -2.5664, -2.8816, -2.6703, -1.8604],\n",
            "        [-1.9216, -2.1280, -2.0578, -2.0862, -1.9324, -2.4970, -1.8652, -2.2959],\n",
            "        [-2.2601, -1.8411, -1.9776, -1.8652, -2.2469, -2.2861, -2.0865, -2.1869]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 7, 7, 7, 6, 1, 5, 6, 7, 5, 4, 3, 7, 2, 5, 5, 5, 6, 5, 5, 1, 7, 6, 7,\n",
            "        6, 5, 5, 5, 7, 5, 6, 5], device='cuda:0')\n",
            "tensor([[-1.8753, -2.0576, -1.9725, -2.3682, -2.2539, -2.1276, -1.8993, -2.1858],\n",
            "        [-1.8935, -1.9404, -1.8679, -2.3200, -2.2356, -2.0940, -1.8645, -2.6883],\n",
            "        [-1.9464, -2.0712, -1.6614, -1.8888, -2.3215, -2.5752, -2.2403, -2.2133],\n",
            "        [-1.9745, -2.0165, -1.9121, -1.9048, -2.3099, -2.6181, -1.9697, -2.1226],\n",
            "        [-1.9919, -1.2112, -1.9717, -2.6520, -2.4105, -2.7599, -2.2649, -2.3118],\n",
            "        [-2.3252, -3.4315, -3.2418, -2.0826, -2.6948, -1.2594, -1.2309, -2.7676],\n",
            "        [-4.8891, -4.3775, -6.0580, -2.8931, -4.9290, -1.3317, -0.5000, -3.1156],\n",
            "        [-3.0838, -0.6931, -1.8196, -3.1762, -2.9206, -3.1319, -2.6757, -2.4774],\n",
            "        [-1.8680, -1.9195, -1.9036, -2.3811, -2.1875, -1.8514, -2.1505, -2.6344],\n",
            "        [-1.8529, -1.5876, -1.7622, -2.5012, -2.4885, -2.6778, -2.1444, -2.1519],\n",
            "        [-2.1184, -1.7370, -1.7780, -2.2277, -2.4288, -2.3376, -1.9556, -2.2946],\n",
            "        [-2.2491, -2.0436, -1.7998, -1.8762, -2.2539, -2.9195, -2.1449, -1.7696],\n",
            "        [-1.6263, -2.2693, -1.8193, -2.3203, -2.5446, -2.3149, -1.9889, -2.0759],\n",
            "        [-1.6516, -3.1327, -2.2164, -1.7903, -2.1024, -2.1322, -1.8282, -2.4385],\n",
            "        [-1.7200, -1.9075, -1.9438, -2.4383, -2.3741, -2.1209, -2.1189, -2.2180],\n",
            "        [-2.6176, -0.9219, -1.5547, -2.9433, -2.6665, -3.2791, -2.8915, -2.2762],\n",
            "        [-1.5013, -2.0879, -2.2058, -2.4073, -2.3629, -1.8853, -2.0674, -2.5189],\n",
            "        [-1.5246, -2.5793, -2.7077, -1.8236, -2.1532, -2.0746, -1.7185, -2.8598],\n",
            "        [-1.9423, -2.5121, -1.9685, -1.9862, -2.1326, -2.2971, -1.6859, -2.3612],\n",
            "        [-2.3981, -0.8719, -1.9643, -2.8045, -2.7946, -3.0847, -2.4174, -2.3629],\n",
            "        [-2.0797, -3.1160, -1.7174, -1.6795, -2.5049, -2.2466, -1.8388, -2.1349],\n",
            "        [-1.9127, -1.6468, -1.9111, -2.3146, -2.4202, -2.6168, -1.9806, -2.1801],\n",
            "        [-2.0310, -1.9633, -1.5763, -2.3334, -2.1791, -2.6435, -1.9890, -2.2671],\n",
            "        [-1.9515, -1.4119, -1.8475, -2.3446, -2.4816, -2.8292, -2.2495, -2.1840],\n",
            "        [-1.9951, -4.0296, -2.4105, -1.3297, -2.3894, -1.7842, -1.8656, -2.5579],\n",
            "        [-2.0152, -2.0515, -1.7184, -2.0328, -2.2345, -2.2339, -1.9609, -2.6177],\n",
            "        [-2.0096, -1.7620, -1.6639, -2.2667, -2.4784, -2.7355, -2.1761, -1.9735],\n",
            "        [-1.8448, -2.5468, -1.7830, -1.8963, -2.2671, -2.3531, -1.9051, -2.3241],\n",
            "        [-1.5245, -3.0858, -2.0585, -1.8275, -2.2429, -2.2748, -1.8940, -2.4226],\n",
            "        [-1.7864, -3.2518, -1.8299, -1.8741, -2.4398, -1.9380, -1.7951, -2.4946],\n",
            "        [-2.4533, -1.5543, -1.5430, -2.3243, -2.1652, -2.8776, -2.1547, -2.2622],\n",
            "        [-2.6900, -0.7865, -2.1195, -2.9272, -2.5107, -3.0840, -2.3813, -2.4814]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 6, 3, 5, 7, 7, 7, 7, 5, 7, 5, 7, 7, 4, 6, 6, 6, 6, 6, 6, 7, 7, 3, 5,\n",
            "        6, 6, 7, 3, 4, 6, 6, 5], device='cuda:0')\n",
            "tensor([[-1.7958, -2.7499, -2.0692, -1.8509, -1.9416, -2.1509, -1.8436, -2.6795],\n",
            "        [-3.2222, -0.6284, -1.8781, -2.9664, -2.5960, -3.3505, -3.0621, -2.7199],\n",
            "        [-2.3291, -1.2297, -1.9399, -2.2793, -2.0035, -2.9504, -2.3645, -2.4892],\n",
            "        [-2.7986, -0.9078, -1.6359, -3.1345, -2.7213, -3.2721, -2.7512, -2.0414],\n",
            "        [-2.2416, -1.4431, -1.7741, -2.3258, -2.1308, -2.9499, -2.2117, -2.2112],\n",
            "        [-2.6038, -1.0747, -1.8732, -2.5961, -2.3771, -2.7211, -2.2508, -2.3808],\n",
            "        [-1.7355, -3.2930, -1.9467, -1.8236, -2.4933, -2.0469, -1.8298, -2.2059],\n",
            "        [-1.7783, -2.5208, -1.7838, -2.0617, -2.1391, -2.4517, -1.8240, -2.4063],\n",
            "        [-2.8009, -1.3709, -1.5928, -2.2955, -2.3648, -2.7030, -2.0959, -2.3293],\n",
            "        [-2.2430, -3.9727, -3.0945, -1.7020, -2.3633, -1.0942, -1.6748, -3.4681],\n",
            "        [-1.7019, -2.4481, -1.9650, -2.1090, -2.1560, -2.0906, -1.8968, -2.5229],\n",
            "        [-1.8661, -2.3696, -1.9451, -2.0056, -2.1769, -1.8133, -2.0459, -2.6820],\n",
            "        [-3.0737, -0.6663, -1.8985, -3.0324, -2.6429, -3.4210, -2.7031, -2.6403],\n",
            "        [-2.3088, -1.2820, -1.7362, -2.6154, -2.0999, -2.9147, -2.1550, -2.5106],\n",
            "        [-1.8295, -2.7010, -2.0695, -1.8396, -2.1629, -1.8144, -1.8975, -2.8241],\n",
            "        [-1.9851, -2.4954, -1.6381, -1.8893, -2.1163, -2.4985, -1.8944, -2.5065],\n",
            "        [-2.1851, -1.5025, -1.5101, -2.4863, -2.4683, -2.8014, -2.3557, -2.1155],\n",
            "        [-2.5618, -1.3188, -1.5881, -2.5190, -2.3013, -2.8541, -2.4269, -2.0836],\n",
            "        [-2.3145, -1.3804, -1.7173, -2.4150, -2.3744, -2.8278, -2.4630, -1.9423],\n",
            "        [-2.3916, -1.5780, -1.4428, -2.3080, -2.1628, -2.9428, -2.3569, -2.2637],\n",
            "        [-2.1530, -1.4323, -1.7517, -2.3560, -2.5814, -2.6969, -2.2041, -2.0924],\n",
            "        [-2.2219, -4.1456, -3.1824, -1.6546, -2.5993, -1.2343, -1.4736, -3.0234],\n",
            "        [-2.9312, -0.8837, -1.6572, -2.9434, -2.4221, -3.4658, -2.8104, -2.2084],\n",
            "        [-3.0160, -0.9009, -1.6503, -2.6270, -2.5177, -3.4158, -2.7892, -2.2486],\n",
            "        [-2.0051, -2.3055, -1.6302, -1.8790, -2.1227, -2.6980, -2.0763, -2.2580],\n",
            "        [-1.8583, -2.4386, -1.7860, -2.0686, -2.2604, -2.2616, -1.8825, -2.2819],\n",
            "        [-2.1029, -2.3809, -1.8122, -1.8471, -1.9955, -2.5764, -1.7903, -2.4585],\n",
            "        [-2.8717, -0.7911, -1.8596, -2.8579, -2.4563, -3.3253, -2.5119, -2.6026],\n",
            "        [-3.5129, -0.3475, -2.3300, -4.0800, -3.0799, -4.1377, -3.3449, -2.9500],\n",
            "        [-3.8116, -4.2784, -4.3030, -2.0175, -3.4107, -1.4562, -0.7098, -2.8195],\n",
            "        [-2.1072, -1.6982, -1.9070, -2.2284, -2.3376, -2.4848, -1.9657, -2.1267],\n",
            "        [-1.7491, -2.6449, -1.9216, -1.8518, -2.3642, -2.4999, -1.9795, -1.9843]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 6, 4, 0, 0, 5, 7, 3, 5, 6, 6, 6, 4, 2, 5, 7, 0, 3, 7, 7, 7, 3, 7, 3,\n",
            "        0, 6, 5, 7, 1, 6, 5, 6], device='cuda:0')\n",
            "tensor([[-2.1705, -1.7563, -1.7318, -1.9414, -2.3060, -2.6708, -2.2767, -2.1099],\n",
            "        [-1.9182, -2.7006, -1.7054, -2.0537, -2.1281, -2.3038, -1.8000, -2.3886],\n",
            "        [-2.2653, -1.7360, -1.6906, -2.1539, -2.1606, -2.5375, -2.1532, -2.2156],\n",
            "        [-2.0371, -1.5961, -1.8786, -2.3662, -1.8721, -2.7890, -2.1486, -2.4265],\n",
            "        [-1.6417, -3.6233, -2.3907, -1.8024, -2.3562, -1.5702, -1.8631, -2.7302],\n",
            "        [-1.9846, -2.6686, -1.8932, -1.9445, -2.1971, -2.3429, -1.8080, -2.0525],\n",
            "        [-1.9186, -1.6971, -1.8389, -2.0930, -2.2459, -2.6719, -2.2914, -2.1929],\n",
            "        [-2.4998, -1.3784, -1.6892, -2.3070, -2.2910, -2.8384, -2.2133, -2.1833],\n",
            "        [-1.8174, -1.9694, -1.7802, -2.0834, -2.2165, -2.6611, -2.1316, -2.2312],\n",
            "        [-2.0031, -4.4225, -2.5115, -1.4361, -2.4109, -1.6360, -1.6313, -2.9203],\n",
            "        [-2.0130, -2.1076, -1.7680, -2.0488, -2.2885, -2.5336, -2.1944, -1.8766],\n",
            "        [-1.8607, -2.7026, -1.6340, -1.9290, -2.1942, -2.4095, -2.0056, -2.2918],\n",
            "        [-1.7419, -2.4280, -1.7267, -1.9601, -2.1670, -2.5770, -2.1664, -2.1825],\n",
            "        [-1.9200, -1.9846, -1.7677, -2.1414, -2.1256, -2.4237, -2.0576, -2.3858],\n",
            "        [-2.2148, -1.6025, -1.7917, -2.3510, -1.9319, -2.4969, -2.0463, -2.6443],\n",
            "        [-2.2580, -2.1391, -1.3945, -2.1448, -2.0545, -2.6768, -2.1203, -2.3466],\n",
            "        [-2.0989, -2.6837, -2.0043, -1.7500, -2.0401, -1.9291, -1.8144, -2.7750]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 6, 6, 7, 7, 7, 0, 5, 0, 5, 7, 7, 0, 7, 1, 7, 6], device='cuda:0')\n",
            "\n",
            "Evaluating...\n",
            "tensor(2.0925, device='cuda:0')\n",
            "tensor(1.7946, device='cuda:0')\n",
            "\n",
            "Training Loss: 1.885\n",
            "Validation Loss: 1.944\n",
            "\n",
            " Epoch 8 / 10\n",
            "tensor([[-1.8382, -4.6638, -2.9716, -1.4475, -2.6116, -1.3922, -1.7499, -3.0089],\n",
            "        [-1.6977, -2.7125, -1.9267, -1.8352, -2.1743, -2.4192, -1.9591, -2.2862],\n",
            "        [-1.9010, -2.3151, -1.8601, -2.0569, -2.0229, -2.5264, -1.9418, -2.1834],\n",
            "        [-1.7437, -2.4613, -1.8038, -1.9888, -2.2289, -2.7231, -2.1382, -1.9167],\n",
            "        [-2.3818, -1.7357, -1.6208, -2.3671, -2.1597, -2.7142, -2.0087, -2.0869],\n",
            "        [-2.0158, -2.1274, -1.6938, -2.0912, -2.1521, -2.6845, -2.2065, -1.9261],\n",
            "        [-1.9962, -3.1020, -1.7236, -1.8559, -2.0025, -2.5970, -1.7494, -2.2919],\n",
            "        [-2.0322, -1.2322, -2.0569, -2.7290, -2.0517, -2.3862, -2.2745, -2.7998],\n",
            "        [-1.9949, -2.5632, -2.1360, -1.7818, -2.2116, -2.1552, -1.7226, -2.3386],\n",
            "        [-1.5697, -3.1745, -2.8231, -1.8957, -2.4251, -1.4586, -1.8175, -2.8651],\n",
            "        [-1.8471, -2.3345, -1.8369, -1.9761, -2.1278, -2.5106, -2.0083, -2.1803],\n",
            "        [-2.5142, -1.2491, -1.8997, -2.2641, -2.0441, -2.9435, -2.3581, -2.2827],\n",
            "        [-1.9609, -2.6679, -2.2784, -1.9377, -2.1559, -1.4929, -1.9963, -2.7026],\n",
            "        [-2.2442, -2.1338, -1.8157, -1.9075, -2.0471, -2.7294, -1.8159, -2.2315],\n",
            "        [-2.2958, -1.3911, -1.9201, -2.1131, -2.0050, -3.0220, -2.3017, -2.3065],\n",
            "        [-3.2700, -0.8704, -1.6515, -2.8294, -2.3142, -3.2901, -2.9221, -2.2780],\n",
            "        [-2.1259, -2.0205, -1.7330, -2.0801, -2.1086, -2.8159, -2.0172, -2.0240],\n",
            "        [-1.6113, -4.1020, -2.2838, -1.6960, -2.3623, -1.9593, -1.8419, -2.2553],\n",
            "        [-1.8249, -3.3114, -1.9566, -1.7734, -2.0600, -2.2327, -1.7360, -2.5222],\n",
            "        [-1.7659, -3.5640, -2.3272, -1.8716, -2.1254, -1.6647, -1.6922, -2.8746],\n",
            "        [-1.8744, -2.2901, -1.9669, -2.2317, -2.1086, -1.9192, -1.9485, -2.4368],\n",
            "        [-1.8246, -2.6345, -1.8020, -2.0539, -1.9281, -2.4631, -1.9217, -2.3352],\n",
            "        [-2.2546, -1.6760, -1.8345, -2.0312, -2.0565, -2.6455, -2.0065, -2.4797],\n",
            "        [-1.9084, -2.5989, -1.6002, -1.9791, -2.2816, -2.7241, -2.0889, -1.9260],\n",
            "        [-1.8919, -2.8100, -2.0046, -1.9231, -2.1347, -2.2625, -1.7471, -2.1939],\n",
            "        [-2.3169, -1.3094, -1.8521, -2.3983, -2.0294, -3.0613, -2.2492, -2.3031],\n",
            "        [-1.9904, -2.5116, -1.8048, -1.9361, -1.9252, -2.4111, -1.8954, -2.4347],\n",
            "        [-1.7234, -2.7289, -1.8820, -1.9122, -2.1162, -2.2763, -1.8995, -2.4839],\n",
            "        [-2.3354, -1.4866, -1.6653, -2.3812, -1.9670, -2.8017, -2.2619, -2.3994],\n",
            "        [-1.8357, -2.9952, -1.8392, -1.5824, -2.2390, -2.5385, -1.9000, -2.3975],\n",
            "        [-1.8675, -3.1288, -2.0267, -1.7563, -2.1063, -2.4100, -1.7059, -2.2619],\n",
            "        [-3.1868, -2.5469, -3.8027, -2.8664, -3.1813, -1.2217, -0.9262, -2.6757]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 3, 7, 0, 5, 7, 7, 6, 5, 6, 5, 4, 5, 5, 0, 7, 7, 7, 7, 0, 7, 6, 6, 7,\n",
            "        7, 6, 6, 3, 6, 7, 6, 5], device='cuda:0')\n",
            "tensor([[-1.5424, -3.5134, -2.2432, -1.8196, -2.3274, -1.9384, -1.9417, -2.2714],\n",
            "        [-2.2523, -2.2788, -1.7808, -1.7152, -2.0305, -2.7650, -2.2273, -1.9523],\n",
            "        [-1.4401, -2.7369, -2.0564, -2.1431, -2.1334, -2.5115, -2.0469, -2.0842],\n",
            "        [-1.8772, -2.2962, -2.0848, -1.9627, -1.9825, -2.6085, -2.0464, -1.9592],\n",
            "        [-1.7548, -2.8399, -1.9355, -1.7743, -2.1423, -2.5564, -1.9099, -2.1928],\n",
            "        [-2.0624, -2.0426, -1.9488, -2.0428, -1.8357, -2.6222, -2.2136, -2.0433],\n",
            "        [-1.8082, -2.7780, -1.7486, -1.8842, -2.2402, -2.5727, -1.9961, -2.0457],\n",
            "        [-2.3566, -2.2667, -2.0638, -1.6378, -1.9454, -2.3626, -1.9938, -2.2353],\n",
            "        [-2.5996, -1.3986, -1.5299, -2.3952, -2.2614, -3.1150, -2.4795, -1.9756],\n",
            "        [-1.9871, -2.0738, -1.9715, -2.2218, -1.9350, -2.3807, -2.0298, -2.1099],\n",
            "        [-1.7013, -2.5921, -2.1424, -1.9569, -2.2775, -2.3363, -1.9188, -1.9804],\n",
            "        [-1.6793, -2.5829, -1.7985, -2.0607, -2.1800, -2.7345, -2.1056, -1.9291],\n",
            "        [-1.6680, -3.7540, -1.9989, -1.7533, -2.4031, -2.1620, -1.9325, -2.0484],\n",
            "        [-1.9068, -2.3183, -1.8018, -1.7674, -2.1240, -2.8173, -2.3830, -1.9267],\n",
            "        [-1.6928, -3.3769, -2.1575, -1.6895, -2.1367, -2.2326, -1.7884, -2.4181],\n",
            "        [-2.0116, -2.4452, -1.8105, -1.8291, -1.7958, -2.6796, -2.1892, -2.2183],\n",
            "        [-1.8559, -2.6549, -1.9506, -2.0501, -2.0033, -1.8920, -2.0155, -2.4821],\n",
            "        [-1.6386, -3.4285, -2.2596, -1.9165, -2.1280, -2.0295, -1.6587, -2.5141],\n",
            "        [-1.6788, -2.3639, -2.3363, -2.1979, -1.9536, -2.1444, -1.8456, -2.3559],\n",
            "        [-2.0146, -3.4697, -2.0409, -1.8344, -1.9869, -2.2005, -1.5927, -2.3575],\n",
            "        [-2.7053, -1.0007, -1.8731, -2.7253, -2.1444, -3.0347, -2.5633, -2.2624],\n",
            "        [-1.8009, -2.9243, -2.8257, -1.9955, -2.2245, -1.3901, -1.7972, -2.7646],\n",
            "        [-2.0187, -2.6117, -2.0278, -2.0502, -1.8106, -2.4007, -1.8272, -2.1341],\n",
            "        [-2.2491, -2.0043, -1.9231, -2.3708, -1.4528, -2.8653, -1.8953, -2.5376],\n",
            "        [-2.1453, -3.1764, -2.1952, -1.6457, -1.8991, -2.3565, -1.6868, -2.2307],\n",
            "        [-2.1646, -1.3637, -1.6707, -2.6551, -2.3523, -2.9373, -2.4469, -1.9923],\n",
            "        [-1.8312, -1.4158, -2.1211, -2.5843, -2.1804, -2.4650, -2.2651, -2.3037],\n",
            "        [-1.9167, -2.9332, -1.8929, -1.7991, -2.1740, -2.4362, -1.8419, -2.0885],\n",
            "        [-1.8454, -2.8839, -1.9322, -1.8381, -2.0398, -2.5160, -1.8035, -2.2384],\n",
            "        [-1.9753, -2.2334, -1.8242, -2.1578, -2.0129, -2.7606, -2.1173, -1.8327],\n",
            "        [-1.6810, -3.0728, -2.0324, -1.9100, -1.9882, -2.3401, -1.8733, -2.2871],\n",
            "        [-1.9600, -3.8136, -2.3404, -1.5641, -1.9821, -2.0056, -1.6536, -2.6914]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 3, 7, 5, 7, 5, 2, 5, 7, 5, 7, 7, 6, 7, 6, 6, 3, 0, 6, 6, 6, 5, 6, 4,\n",
            "        5, 2, 6, 6, 0, 5, 3, 6], device='cuda:0')\n",
            "tensor([[-1.8435, -3.2962, -2.9068, -1.9378, -2.5321, -1.2124, -1.8656, -2.6001],\n",
            "        [-2.0047, -3.6040, -3.2094, -1.6009, -2.3289, -1.2237, -1.8074, -3.2098],\n",
            "        [-2.5158, -0.7863, -2.1754, -3.1575, -2.2237, -3.2575, -2.6239, -2.4262],\n",
            "        [-1.8576, -3.1487, -1.9373, -1.8402, -2.0763, -2.4285, -2.0043, -1.8981],\n",
            "        [-1.8037, -3.5249, -2.4716, -1.5415, -2.0986, -2.1879, -1.8801, -2.1202],\n",
            "        [-1.8532, -3.0705, -2.6092, -2.0730, -2.3260, -1.2714, -1.9498, -2.5634],\n",
            "        [-2.0581, -3.5737, -2.8686, -1.9389, -2.6203, -1.1273, -1.7719, -2.5651],\n",
            "        [-1.5328, -2.4419, -2.0227, -2.4270, -2.1635, -2.1867, -2.0170, -2.1523],\n",
            "        [-2.0529, -3.1551, -2.1743, -1.5559, -2.1336, -2.0711, -1.9684, -2.1188],\n",
            "        [-1.6322, -3.3578, -2.1231, -1.9578, -2.0504, -2.3393, -1.8393, -2.0806],\n",
            "        [-1.5054, -2.8467, -2.1113, -2.0012, -2.1165, -2.4339, -1.9910, -2.1279],\n",
            "        [-2.1437, -3.0511, -2.0608, -1.9731, -1.8842, -2.7244, -2.0204, -1.5188],\n",
            "        [-1.8346, -2.2462, -1.9455, -2.0859, -1.9402, -2.8849, -2.3823, -1.7399],\n",
            "        [-2.0789, -3.6301, -2.3987, -1.4193, -1.8263, -2.0796, -1.9013, -2.5218],\n",
            "        [-2.1318, -3.8530, -3.4296, -1.7754, -2.5655, -1.0236, -1.7200, -3.1448],\n",
            "        [-1.8071, -4.4070, -2.1796, -1.6288, -2.1859, -1.9269, -1.8172, -2.3647],\n",
            "        [-1.9898, -1.9570, -2.1716, -2.1113, -1.7553, -2.6496, -2.1116, -2.1009],\n",
            "        [-2.2866, -2.2003, -1.7067, -1.9571, -1.9329, -2.8363, -2.4729, -1.7306],\n",
            "        [-2.6542, -1.5076, -1.6676, -2.4583, -2.1068, -3.1454, -2.6318, -1.6230],\n",
            "        [-1.6126, -2.8557, -2.1503, -1.9861, -1.9751, -2.4088, -1.9742, -2.1045],\n",
            "        [-1.7889, -2.5840, -1.9869, -2.1903, -1.9808, -2.1621, -1.9340, -2.2003],\n",
            "        [-1.8767, -2.8092, -2.1841, -2.0249, -1.8896, -2.3152, -1.7813, -2.0892],\n",
            "        [-1.9152, -2.2808, -1.6301, -2.3472, -2.2212, -2.9203, -2.3389, -1.6089],\n",
            "        [-1.5794, -4.0595, -2.4845, -1.7041, -2.3591, -1.7629, -1.8315, -2.4637],\n",
            "        [-2.7621, -1.1444, -1.8938, -2.4270, -2.0274, -2.8011, -2.3896, -2.3483],\n",
            "        [-2.0254, -2.7663, -1.9422, -1.8683, -1.8487, -2.7524, -2.0134, -1.8796],\n",
            "        [-1.6110, -3.2156, -2.1714, -2.0241, -1.9406, -2.0762, -1.9886, -2.2245],\n",
            "        [-2.1448, -2.3150, -1.8002, -2.0675, -2.1223, -2.7043, -2.2411, -1.6126],\n",
            "        [-1.6164, -3.3580, -2.5127, -1.9177, -2.4125, -1.5269, -1.9680, -2.3855],\n",
            "        [-1.7581, -3.3335, -2.1994, -1.9412, -2.0317, -2.2021, -1.9109, -1.9111],\n",
            "        [-1.9814, -2.4397, -1.9544, -1.9413, -2.0525, -2.8664, -2.2409, -1.6190],\n",
            "        [-1.6657, -3.5736, -1.9879, -2.0092, -2.1252, -2.1759, -1.7328, -2.2817]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 5, 1, 5, 6, 5, 5, 5, 6, 6, 6, 3, 6, 5, 6, 5, 6, 7, 5, 5, 1, 5, 7, 3,\n",
            "        5, 5, 7, 7, 6, 7, 0, 6], device='cuda:0')\n",
            "tensor([[-1.8634, -2.3729, -2.0979, -2.4485, -2.0060, -2.3171, -1.8551, -1.8774],\n",
            "        [-1.8822, -4.2365, -2.6083, -1.5672, -2.5668, -1.5468, -1.8608, -2.2468],\n",
            "        [-1.8528, -3.1567, -2.3933, -1.6715, -2.2176, -2.2881, -1.7053, -2.0456],\n",
            "        [-1.4443, -2.9618, -2.3993, -2.2411, -2.3250, -2.0691, -1.8734, -1.9837],\n",
            "        [-1.5009, -4.0289, -2.2902, -1.6987, -2.3404, -2.1586, -1.9945, -2.0616],\n",
            "        [-1.7668, -3.2438, -1.9837, -1.9320, -1.9378, -2.3786, -1.9324, -2.0700],\n",
            "        [-4.1550, -4.0265, -5.2341, -2.7263, -3.9369, -1.0405, -0.9952, -1.8758],\n",
            "        [-2.0757, -3.2608, -1.9745, -1.5749, -1.9760, -2.5839, -2.2718, -1.7539],\n",
            "        [-1.7890, -2.6184, -1.9314, -2.2902, -2.1537, -2.3490, -2.1087, -1.7102],\n",
            "        [-1.8416, -1.9739, -2.1126, -2.1229, -2.0983, -2.5978, -2.3204, -1.7923],\n",
            "        [-1.8188, -3.4990, -1.9171, -1.7354, -1.7406, -2.5620, -2.0680, -2.2520],\n",
            "        [-1.9249, -1.9833, -2.0281, -2.3547, -1.7544, -2.4622, -2.1371, -2.1737],\n",
            "        [-2.1430, -2.3060, -1.7942, -2.1446, -1.8721, -2.5517, -2.1947, -1.8546],\n",
            "        [-1.5005, -4.2299, -2.1204, -1.8350, -2.4318, -2.4872, -1.9944, -1.7389],\n",
            "        [-1.6508, -3.1201, -2.1979, -2.1981, -2.0996, -2.0166, -1.9061, -1.9831],\n",
            "        [-2.0375, -3.0625, -1.9975, -1.8224, -1.8754, -2.6542, -1.8780, -1.9038],\n",
            "        [-1.8721, -2.4474, -2.0581, -2.2218, -2.0168, -2.1042, -2.1183, -1.9084],\n",
            "        [-1.7847, -2.1579, -1.8732, -2.4184, -2.0780, -2.0299, -2.1401, -2.3054],\n",
            "        [-1.8037, -3.3270, -2.0739, -1.7697, -1.9291, -2.5012, -2.0918, -1.8799],\n",
            "        [-1.5105, -3.6149, -2.3279, -2.1376, -2.5299, -1.7548, -1.9656, -1.9367],\n",
            "        [-1.5906, -3.1067, -1.9833, -2.0102, -2.0739, -2.6438, -2.1395, -1.7995],\n",
            "        [-1.9560, -3.5895, -1.9441, -1.7840, -2.2640, -2.5034, -1.8663, -1.7178],\n",
            "        [-1.6643, -2.9356, -2.3448, -2.0690, -1.9369, -2.1666, -1.7613, -2.2552],\n",
            "        [-1.7289, -3.4635, -2.4122, -1.8720, -2.2279, -1.6593, -1.8026, -2.4665],\n",
            "        [-1.6962, -2.9022, -2.0806, -1.7542, -2.2154, -2.6430, -2.1887, -1.7632],\n",
            "        [-1.6557, -3.7563, -2.4265, -1.6655, -2.1139, -1.9405, -1.7750, -2.5991],\n",
            "        [-1.8049, -4.1998, -2.2382, -1.7135, -2.2291, -1.8397, -1.7812, -2.3157],\n",
            "        [-1.4134, -2.7640, -2.1572, -2.3091, -2.0195, -2.4697, -2.0911, -1.9821],\n",
            "        [-1.6140, -3.6229, -2.8573, -1.7208, -2.1340, -1.9179, -1.7505, -2.3137],\n",
            "        [-1.9167, -2.7648, -2.0579, -1.8284, -2.0259, -2.5905, -2.0527, -1.7940],\n",
            "        [-1.8671, -1.9441, -1.9899, -2.3346, -2.2576, -2.5533, -2.2248, -1.7246],\n",
            "        [-1.6943, -2.0180, -2.3975, -2.2431, -1.9917, -2.2772, -2.1557, -2.0293]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 7, 6, 5, 3, 6, 6, 7, 5, 4, 5, 1, 2, 7, 7, 6, 5, 7, 6, 7, 7, 6, 7, 6,\n",
            "        0, 2, 2, 0, 6, 7, 7, 6], device='cuda:0')\n",
            "tensor([[-1.5079, -3.6333, -2.2172, -1.9426, -2.4274, -2.1301, -1.9405, -1.9023],\n",
            "        [-1.6974, -3.7328, -2.2145, -1.6387, -2.4159, -2.0554, -1.8680, -2.1395],\n",
            "        [-1.8561, -3.2550, -2.1279, -2.0490, -2.1862, -1.8505, -1.9216, -1.9568],\n",
            "        [-2.3370, -3.4435, -2.3151, -1.6372, -1.8752, -2.0129, -1.7839, -2.0935],\n",
            "        [-1.6638, -4.0697, -2.1944, -1.6924, -2.3892, -1.9511, -1.8976, -2.1695],\n",
            "        [-1.5991, -3.9710, -2.5534, -1.8281, -2.2475, -1.9279, -1.8640, -2.0071],\n",
            "        [-1.8010, -3.5665, -2.1069, -1.7829, -2.2181, -2.2266, -2.0255, -1.7827],\n",
            "        [-1.6310, -3.7898, -2.4503, -1.9139, -2.1896, -1.7131, -1.8707, -2.2865],\n",
            "        [-1.8270, -1.7629, -2.0667, -2.3936, -1.9242, -2.5642, -2.1656, -2.1894],\n",
            "        [-1.8804, -3.0741, -1.9037, -1.8698, -2.1678, -2.3810, -2.2261, -1.6970],\n",
            "        [-1.5006, -3.6530, -2.3394, -2.0183, -2.2152, -2.2016, -1.9013, -1.8794],\n",
            "        [-1.8845, -4.4328, -2.2769, -1.3865, -2.2935, -2.2520, -1.9900, -1.9598],\n",
            "        [-2.1609, -2.0692, -1.8576, -2.3265, -1.9244, -2.7355, -1.9834, -1.8554],\n",
            "        [-1.7598, -2.6672, -2.0551, -1.9792, -1.8790, -2.7076, -2.2208, -1.8064],\n",
            "        [-1.8041, -3.1008, -2.2306, -1.8611, -2.2617, -2.3373, -2.2837, -1.4929],\n",
            "        [-1.8885, -4.4046, -2.3607, -1.4651, -2.4745, -1.8002, -1.7088, -2.5191],\n",
            "        [-1.9913, -2.2269, -1.9877, -2.3572, -1.8174, -2.3962, -2.0913, -1.9180],\n",
            "        [-2.1847, -1.3148, -2.2028, -2.7400, -1.9872, -2.5506, -2.2162, -2.1222],\n",
            "        [-2.0566, -4.4132, -2.6214, -1.4723, -2.6023, -1.4452, -1.7841, -2.5240],\n",
            "        [-1.6646, -4.0433, -2.5408, -1.7473, -2.4067, -1.6991, -1.8322, -2.2337],\n",
            "        [-1.7418, -3.1782, -1.9321, -2.1307, -2.1452, -2.1485, -1.9587, -1.9325],\n",
            "        [-1.7125, -2.7268, -2.1307, -2.1399, -2.2014, -1.7814, -2.0514, -2.2061],\n",
            "        [-1.7877, -3.7093, -2.1827, -1.7253, -2.2264, -1.9458, -1.9123, -2.1306],\n",
            "        [-1.9355, -2.7109, -1.9842, -2.0927, -1.9394, -2.0523, -2.1667, -1.9551],\n",
            "        [-1.6253, -3.0802, -1.9943, -2.2170, -2.4152, -2.0733, -2.0777, -1.7613],\n",
            "        [-1.8283, -2.4778, -2.0497, -2.0834, -2.2047, -2.5368, -2.2281, -1.5850],\n",
            "        [-1.5507, -3.0076, -2.1906, -1.8712, -2.0380, -2.4979, -2.4237, -1.7628],\n",
            "        [-2.1490, -2.3005, -1.7961, -2.1940, -2.2616, -2.5611, -2.2595, -1.5143],\n",
            "        [-2.2347, -2.2598, -1.6904, -2.2636, -2.0179, -2.8088, -2.5578, -1.4719],\n",
            "        [-1.9061, -3.3437, -2.5221, -1.7145, -2.1061, -1.7076, -1.7762, -2.4840],\n",
            "        [-1.8610, -3.4375, -2.0151, -2.0811, -1.9674, -2.5656, -1.9996, -1.5987],\n",
            "        [-2.0221, -4.2213, -2.3918, -1.5207, -2.1278, -1.9470, -1.7464, -2.2375]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 6, 5, 3, 4, 5, 5, 6, 4, 6, 0, 7, 0, 7, 6, 3, 4, 1, 5, 6, 6, 0, 3, 7,\n",
            "        7, 5, 6, 7, 7, 3, 6, 6], device='cuda:0')\n",
            "tensor([[-2.0884, -2.3305, -1.9500, -2.0537, -2.1631, -2.5282, -2.5705, -1.4394],\n",
            "        [-1.5945, -3.4318, -2.2036, -2.0966, -2.3636, -2.2704, -2.0433, -1.5875],\n",
            "        [-2.0192, -3.4830, -2.5080, -1.6453, -2.1569, -1.5921, -1.8251, -2.5040],\n",
            "        [-2.5153, -0.9463, -2.5971, -2.9821, -1.9302, -2.6449, -2.3728, -2.3387],\n",
            "        [-1.7272, -3.1538, -2.2056, -1.8999, -2.2449, -2.4095, -1.9823, -1.6809],\n",
            "        [-1.6772, -2.3151, -2.2190, -2.5539, -2.1450, -2.2443, -2.0578, -1.7314],\n",
            "        [-1.8913, -2.9882, -2.3514, -2.2291, -2.2050, -1.6498, -1.7633, -2.1032],\n",
            "        [-1.5267, -2.7844, -2.3322, -2.2367, -2.2700, -2.0719, -1.8986, -1.9801],\n",
            "        [-1.6100, -2.7962, -2.2934, -2.0421, -2.1669, -2.4250, -1.9681, -1.7977],\n",
            "        [-1.5276, -4.1610, -2.5391, -1.5891, -2.4227, -1.9447, -1.9044, -2.2662],\n",
            "        [-1.9962, -2.5405, -2.5567, -2.3275, -2.4534, -1.2706, -1.8278, -2.4915],\n",
            "        [-2.2808, -4.3712, -2.6528, -1.3712, -2.4077, -1.5912, -1.7210, -2.4268],\n",
            "        [-1.6047, -3.4386, -2.2401, -1.8729, -2.2675, -2.1324, -2.3242, -1.6775],\n",
            "        [-1.7622, -2.5336, -2.0046, -2.4495, -1.8399, -2.3400, -2.0894, -1.9038],\n",
            "        [-2.1038, -2.9558, -1.7808, -1.9953, -1.9805, -2.7293, -2.2422, -1.5512],\n",
            "        [-2.2219, -2.6553, -2.1510, -2.3125, -1.8529, -1.8736, -1.8171, -2.0167],\n",
            "        [-1.7478, -4.3315, -2.4035, -1.8243, -2.0660, -2.0918, -1.7830, -1.9472],\n",
            "        [-1.7220, -3.5029, -2.4039, -1.8940, -2.4247, -1.5575, -1.8272, -2.4044],\n",
            "        [-1.9837, -2.8478, -1.8955, -2.1276, -2.0807, -2.5120, -2.5491, -1.3823],\n",
            "        [-1.8208, -3.9058, -2.2331, -1.8244, -2.2395, -2.2939, -1.8745, -1.6678],\n",
            "        [-1.7146, -3.7531, -2.2460, -1.8715, -2.1556, -2.1572, -2.0285, -1.7498],\n",
            "        [-1.7646, -2.8398, -2.1971, -2.0094, -2.2046, -2.2919, -2.1830, -1.6042],\n",
            "        [-1.9892, -4.2922, -2.4138, -1.4553, -2.3036, -1.9287, -1.9210, -2.0022],\n",
            "        [-1.5703, -3.1330, -2.4723, -1.9325, -2.2791, -1.9589, -2.0727, -1.8971],\n",
            "        [-1.8878, -3.4482, -1.9438, -2.0129, -2.1236, -2.3602, -2.2159, -1.5279],\n",
            "        [-1.8015, -3.3899, -2.1563, -1.7785, -2.4602, -2.3686, -1.9027, -1.6692],\n",
            "        [-1.7256, -3.3827, -2.2211, -2.0928, -2.0651, -2.4780, -2.1579, -1.4703],\n",
            "        [-1.8471, -3.7421, -2.3304, -1.8628, -2.0735, -2.2826, -2.0542, -1.5600],\n",
            "        [-1.7100, -2.7629, -2.0472, -2.4577, -2.0408, -2.1832, -2.1109, -1.7284],\n",
            "        [-2.3096, -1.0690, -2.4410, -2.7022, -2.0322, -2.5672, -2.6015, -2.1097],\n",
            "        [-2.1982, -2.0266, -1.8778, -2.3611, -2.0531, -2.3814, -2.5948, -1.5391],\n",
            "        [-1.9178, -4.0870, -2.5204, -1.4979, -2.1051, -2.2016, -1.8348, -1.9651]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([3, 7, 6, 1, 6, 7, 7, 7, 0, 3, 5, 6, 0, 6, 7, 5, 6, 5, 6, 6, 7, 5, 6, 6,\n",
            "        4, 3, 7, 5, 5, 1, 5, 5], device='cuda:0')\n",
            "tensor([[-1.8657, -2.1900, -1.9913, -2.3603, -2.2681, -2.4339, -2.4046, -1.5101],\n",
            "        [-2.1477, -3.0544, -2.7924, -2.1199, -2.7346, -1.1028, -1.7368, -2.5030],\n",
            "        [-2.0397, -1.8569, -2.1369, -2.4002, -1.9504, -2.5773, -2.5226, -1.5769],\n",
            "        [-1.8984, -4.1269, -2.3852, -1.4137, -2.3280, -2.0689, -2.0156, -1.9540],\n",
            "        [-2.2303, -3.7372, -1.9826, -1.8265, -2.2542, -1.8460, -1.9184, -1.8305],\n",
            "        [-1.7492, -2.4738, -2.1767, -2.2198, -2.2295, -2.0798, -2.4453, -1.6067],\n",
            "        [-2.3272, -2.1157, -1.9654, -2.3192, -1.9580, -2.2599, -2.4206, -1.5651],\n",
            "        [-1.7427, -3.8595, -1.9448, -2.0227, -2.2399, -2.1682, -2.0029, -1.7558],\n",
            "        [-1.7732, -3.4948, -2.1480, -1.9766, -2.2265, -1.9845, -1.8505, -1.9513],\n",
            "        [-1.6740, -2.8118, -2.2710, -2.2868, -2.0984, -2.2852, -2.2765, -1.5116],\n",
            "        [-5.8845, -3.8785, -6.7002, -4.2202, -5.8645, -1.6030, -0.9139, -1.0342],\n",
            "        [-2.0764, -3.4698, -2.3899, -1.8995, -2.1802, -1.4093, -1.8738, -2.3933],\n",
            "        [-1.9235, -3.2192, -2.2334, -2.1512, -1.9477, -2.2270, -1.8572, -1.6937],\n",
            "        [-2.1599, -1.3256, -2.0813, -2.7808, -2.1271, -2.3667, -2.4780, -1.9998],\n",
            "        [-2.0458, -2.7096, -2.0579, -2.1248, -1.8724, -2.2567, -2.0007, -1.8123],\n",
            "        [-2.1433, -2.0989, -2.0779, -2.2320, -2.1395, -2.2599, -2.4795, -1.5061],\n",
            "        [-1.8160, -2.6246, -2.2658, -2.4606, -1.9509, -1.9879, -1.9780, -1.8436],\n",
            "        [-1.9440, -1.7379, -2.1665, -2.8346, -2.2647, -2.3308, -2.1574, -1.6558],\n",
            "        [-2.1906, -2.1684, -2.0171, -2.1804, -2.0336, -2.4449, -2.5149, -1.4728],\n",
            "        [-1.9230, -2.9453, -2.3504, -2.2722, -2.0118, -2.3068, -1.9979, -1.4530],\n",
            "        [-1.7210, -3.4941, -2.0765, -1.9875, -2.1123, -1.9693, -1.9306, -2.0977],\n",
            "        [-1.8031, -2.7453, -2.3913, -2.1805, -2.2132, -1.7314, -1.9976, -1.9349],\n",
            "        [-1.8575, -2.4465, -2.1335, -2.5269, -2.2512, -1.9451, -1.8690, -1.8547],\n",
            "        [-1.7955, -2.5585, -2.2246, -2.0720, -2.0696, -2.1969, -2.1060, -1.8118],\n",
            "        [-1.7043, -4.1994, -2.4642, -1.6553, -2.3348, -2.1504, -2.0186, -1.7100],\n",
            "        [-2.2412, -1.7785, -2.0069, -2.4716, -2.1452, -2.4837, -2.6529, -1.4482],\n",
            "        [-1.8538, -2.2670, -2.3013, -2.2383, -1.9101, -2.2355, -2.1918, -1.7942],\n",
            "        [-2.2168, -4.5040, -3.0443, -1.6788, -2.7956, -1.1762, -1.5807, -2.6535],\n",
            "        [-1.5465, -2.8989, -2.6245, -2.2631, -2.0766, -1.9844, -1.8928, -1.9521],\n",
            "        [-2.9498, -5.1746, -4.2076, -1.5814, -2.9018, -0.9619, -1.4048, -3.2462],\n",
            "        [-1.7955, -3.1509, -2.2398, -1.9646, -1.8683, -2.2171, -1.8981, -2.0304],\n",
            "        [-1.6814, -2.8258, -2.3250, -2.0801, -2.0517, -2.2590, -2.2827, -1.6250]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 7, 7, 5, 7, 7, 2, 0, 6, 7, 6, 6, 5, 1, 7, 0, 5, 6, 3, 7, 7, 6, 7, 5,\n",
            "        7, 5, 4, 4, 0, 6, 4, 7], device='cuda:0')\n",
            "tensor([[-2.1851, -4.1782, -2.3311, -1.9700, -2.5730, -1.2951, -1.6856, -2.3023],\n",
            "        [-2.0955, -4.2807, -2.9082, -1.7044, -2.4955, -1.4108, -1.5483, -2.4339],\n",
            "        [-2.0382, -2.7953, -2.0553, -2.0530, -1.8873, -2.2412, -2.2726, -1.6535],\n",
            "        [-2.2278, -1.3200, -2.4016, -2.6976, -1.9046, -2.3431, -2.4420, -2.0006],\n",
            "        [-1.8051, -2.8661, -2.3150, -2.2400, -2.2617, -1.7428, -2.0786, -1.7773],\n",
            "        [-1.6803, -2.1340, -2.6866, -2.5577, -2.0665, -1.8647, -2.0267, -1.9921],\n",
            "        [-1.9722, -3.4806, -2.7998, -2.1490, -2.2863, -1.2796, -1.8211, -2.1982],\n",
            "        [-2.3534, -4.3624, -3.1690, -1.6840, -2.7307, -1.0777, -1.6520, -2.6983],\n",
            "        [-2.1369, -4.6037, -2.4404, -1.5661, -2.2083, -1.5636, -1.7897, -2.4112],\n",
            "        [-1.9674, -2.3175, -2.2660, -2.2393, -1.9977, -2.1983, -2.2461, -1.6147],\n",
            "        [-1.8781, -2.3439, -2.2020, -2.3587, -1.9112, -2.2967, -2.5208, -1.5271],\n",
            "        [-2.0695, -3.5056, -2.4799, -2.1058, -2.0931, -1.7159, -1.6442, -1.9523],\n",
            "        [-1.9305, -2.9545, -2.0740, -2.1448, -2.0498, -2.1301, -2.3853, -1.5124],\n",
            "        [-2.2406, -2.3347, -2.5628, -2.2673, -1.9421, -1.7662, -1.8790, -1.9042],\n",
            "        [-2.8282, -0.9008, -2.2079, -3.1296, -2.0171, -2.9577, -3.0898, -1.8938],\n",
            "        [-1.6797, -3.5879, -2.4169, -1.9804, -2.1001, -1.9236, -1.9964, -1.8687],\n",
            "        [-1.8761, -2.7866, -2.3010, -2.3214, -1.8968, -2.1406, -2.0685, -1.6457],\n",
            "        [-1.9539, -2.7075, -2.3982, -1.9902, -1.8706, -2.1089, -1.9742, -1.8988],\n",
            "        [-2.2255, -3.1746, -2.0109, -2.2076, -1.6021, -2.1706, -2.2366, -1.6932],\n",
            "        [-1.9899, -2.2815, -2.2001, -2.3387, -1.7962, -2.0271, -2.2379, -1.8999],\n",
            "        [-1.6929, -3.5562, -2.6358, -1.8322, -2.1257, -1.7585, -2.0005, -2.0493],\n",
            "        [-1.8860, -3.6065, -2.3931, -1.8397, -2.0416, -2.0977, -1.8008, -1.8758],\n",
            "        [-2.6201, -1.2755, -2.2964, -3.0972, -1.7341, -2.2269, -2.4487, -2.0303],\n",
            "        [-1.9767, -2.3543, -2.4607, -2.3313, -1.8184, -2.0502, -2.1312, -1.7471],\n",
            "        [-1.6288, -3.5011, -2.6586, -1.8941, -2.0970, -1.9433, -2.0292, -1.8599],\n",
            "        [-1.9026, -3.4459, -2.2987, -1.9705, -2.0307, -1.9302, -1.9182, -1.8584],\n",
            "        [-2.1757, -3.4001, -3.1199, -1.9831, -2.4734, -1.0948, -1.8158, -2.4113],\n",
            "        [-1.8348, -4.0768, -2.7187, -1.8173, -2.3597, -1.8737, -1.6162, -1.9083],\n",
            "        [-2.0689, -1.8924, -1.9631, -2.8801, -1.9043, -2.4742, -2.5266, -1.5449],\n",
            "        [-1.7632, -2.1859, -2.3345, -2.4906, -1.8743, -2.2902, -2.2313, -1.7470],\n",
            "        [-2.0110, -2.1226, -2.3702, -2.2787, -1.6624, -2.6136, -2.3539, -1.6472],\n",
            "        [-2.7438, -1.5034, -2.0501, -2.3942, -1.6229, -2.2890, -2.9435, -1.9523]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 3, 6, 1, 5, 6, 7, 5, 7, 6, 6, 5, 0, 5, 4, 0, 0, 3, 2, 5, 7, 3, 5, 5,\n",
            "        3, 5, 5, 6, 7, 6, 0, 3], device='cuda:0')\n",
            "tensor([[-2.3905, -4.1794, -2.6228, -1.4965, -2.2116, -1.5280, -1.5893, -2.7174],\n",
            "        [-2.2300, -1.5041, -2.3124, -2.6954, -1.8583, -2.4236, -2.3368, -1.8168],\n",
            "        [-2.2861, -4.2891, -2.8698, -1.4619, -2.3584, -1.4332, -1.5839, -2.8502],\n",
            "        [-1.9263, -2.9573, -2.8959, -2.3844, -2.0371, -1.4031, -1.7771, -2.2111],\n",
            "        [-1.8760, -3.5676, -2.3811, -1.8231, -2.0104, -2.0270, -2.3359, -1.5985],\n",
            "        [-1.8102, -2.1770, -2.3700, -2.3577, -1.7299, -2.4075, -2.4944, -1.6873],\n",
            "        [-2.0771, -1.8176, -2.3344, -2.7230, -1.9274, -2.0448, -2.0862, -1.8927],\n",
            "        [-1.7803, -2.8836, -2.4393, -2.0670, -2.2245, -1.8762, -2.2535, -1.6328],\n",
            "        [-2.3936, -0.8821, -2.6769, -3.1792, -1.9468, -2.7943, -2.7798, -2.1332],\n",
            "        [-2.1872, -2.2573, -2.2990, -2.4209, -1.4793, -1.9124, -2.1442, -2.2901],\n",
            "        [-1.7041, -3.1153, -2.6980, -1.9936, -1.8787, -1.7832, -1.9624, -2.2188],\n",
            "        [-1.7820, -3.8734, -2.4402, -1.6666, -2.1250, -1.9440, -2.0130, -1.9753],\n",
            "        [-2.4606, -1.1367, -2.3995, -2.8254, -1.7586, -2.5047, -2.7888, -2.0542],\n",
            "        [-2.0669, -2.8273, -3.0074, -2.2638, -2.2349, -1.2028, -1.7370, -2.5579],\n",
            "        [-1.8497, -2.6654, -2.3355, -2.2027, -1.9079, -1.9053, -2.0819, -1.9379],\n",
            "        [-2.4995, -1.3087, -2.3161, -2.5158, -1.6916, -2.5584, -2.8173, -1.9185],\n",
            "        [-2.7719, -1.2773, -2.2128, -3.2085, -1.5962, -2.2950, -2.4735, -2.1108]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([3, 2, 5, 5, 7, 7, 6, 6, 2, 6, 6, 0, 7, 5, 7, 3, 7], device='cuda:0')\n",
            "\n",
            "Evaluating...\n",
            "tensor(1.9755, device='cuda:0')\n",
            "tensor(1.8032, device='cuda:0')\n",
            "\n",
            "Training Loss: 1.905\n",
            "Validation Loss: 1.889\n",
            "\n",
            " Epoch 9 / 10\n",
            "tensor([[-1.8654, -2.4079, -2.4686, -2.1789, -1.7505, -1.9400, -2.2039, -2.0439],\n",
            "        [-2.0241, -2.1201, -2.2862, -2.1370, -1.6072, -2.3576, -2.7273, -1.7854],\n",
            "        [-2.1243, -2.6903, -2.5380, -2.1082, -1.6207, -1.6814, -1.9256, -2.4953],\n",
            "        [-1.8106, -2.5135, -2.3719, -2.2555, -1.8225, -1.9117, -2.1091, -2.0672],\n",
            "        [-2.2274, -1.5812, -2.2849, -2.5402, -1.5721, -2.3423, -2.4994, -2.1204],\n",
            "        [-1.8349, -2.5301, -2.3441, -2.3445, -1.9031, -2.0747, -2.0201, -1.8229],\n",
            "        [-2.5821, -4.3105, -2.6656, -1.6421, -2.3388, -1.2402, -1.7261, -2.4758],\n",
            "        [-2.0511, -2.1882, -2.3428, -2.3330, -1.8056, -1.8235, -2.1662, -2.0734],\n",
            "        [-1.8825, -3.1282, -2.4955, -2.0435, -1.9161, -1.9242, -1.8644, -1.9393],\n",
            "        [-2.1163, -1.7031, -2.3602, -2.4226, -1.8642, -2.1466, -2.3631, -1.9087],\n",
            "        [-5.8016, -3.7853, -5.9187, -4.4239, -5.4584, -1.9925, -1.1694, -0.6764],\n",
            "        [-1.7070, -2.0711, -2.6840, -2.3950, -1.8086, -1.9477, -2.2705, -2.0928],\n",
            "        [-1.8905, -2.1465, -2.7778, -2.1059, -1.5485, -1.9508, -2.2409, -2.4406],\n",
            "        [-2.3697, -1.3013, -1.9885, -2.6788, -1.8871, -2.1883, -2.8820, -2.2154],\n",
            "        [-1.9979, -3.4864, -2.5436, -2.1990, -2.2113, -1.4264, -1.6400, -2.2969],\n",
            "        [-2.0252, -2.7892, -2.4279, -1.8065, -1.9195, -2.0480, -2.2454, -1.7571],\n",
            "        [-2.1570, -3.4432, -2.6571, -1.7853, -1.8163, -1.6947, -1.7109, -2.4363],\n",
            "        [-2.0955, -2.8049, -2.3959, -2.2223, -2.0299, -1.5297, -2.0191, -1.9930],\n",
            "        [-2.1491, -1.3282, -2.5644, -2.8660, -1.6246, -2.4149, -2.7271, -2.0191],\n",
            "        [-1.9391, -2.5066, -2.3002, -1.9185, -1.6232, -2.2378, -2.5472, -1.9290],\n",
            "        [-2.5429, -3.1023, -3.2411, -2.0964, -2.7044, -0.9660, -1.6399, -2.6189],\n",
            "        [-1.6480, -2.7948, -2.2354, -2.1428, -1.8182, -2.0058, -2.4057, -2.0017],\n",
            "        [-1.9910, -3.2703, -2.4184, -1.6469, -1.7473, -1.8652, -2.2316, -2.2323],\n",
            "        [-1.7384, -2.5670, -2.4302, -1.9974, -1.8449, -2.0801, -2.3134, -1.9530],\n",
            "        [-2.5614, -1.9361, -2.5225, -2.2439, -1.4114, -1.8630, -2.3940, -2.2831],\n",
            "        [-1.8194, -2.4998, -2.3369, -2.3243, -1.8989, -1.9951, -2.1496, -1.8386],\n",
            "        [-2.3536, -2.9139, -2.9904, -2.2735, -2.3709, -1.0360, -1.7570, -2.5682],\n",
            "        [-2.8322, -0.8649, -2.5470, -3.3218, -1.8665, -2.2539, -2.4276, -2.8518],\n",
            "        [-1.9528, -1.7277, -2.7757, -2.3546, -1.4616, -2.3940, -2.6906, -2.0233],\n",
            "        [-1.7435, -3.5141, -2.5415, -1.7614, -2.0589, -1.8527, -2.0868, -1.9932],\n",
            "        [-1.7451, -3.4803, -2.4099, -2.0011, -2.1733, -1.6943, -2.0293, -1.9617],\n",
            "        [-2.1807, -3.2925, -2.3762, -1.9311, -1.6527, -1.6989, -2.0417, -2.2278]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([4, 3, 4, 6, 5, 7, 2, 7, 6, 7, 6, 7, 6, 5, 5, 7, 3, 5, 5, 3, 5, 6, 3, 0,\n",
            "        5, 5, 6, 6, 4, 0, 6, 7], device='cuda:0')\n",
            "tensor([[-2.1634, -3.8379, -2.6904, -1.8959, -2.5812, -1.2450, -1.8373, -2.0987],\n",
            "        [-2.1994, -2.4302, -2.9199, -2.5223, -2.0606, -1.2447, -1.7879, -2.4749],\n",
            "        [-1.8191, -2.9313, -2.8329, -2.0511, -1.9219, -1.6320, -1.9341, -2.2015],\n",
            "        [-1.6951, -4.3453, -2.5464, -1.8289, -2.0084, -1.7358, -2.0559, -2.0711],\n",
            "        [-1.7972, -2.4560, -2.4566, -2.0051, -1.6294, -2.1772, -2.3204, -2.1166],\n",
            "        [-2.3991, -2.6770, -2.2324, -1.7817, -1.5599, -1.9991, -2.1765, -2.2467],\n",
            "        [-1.5198, -3.2898, -2.4334, -2.0466, -2.1387, -1.9523, -2.4798, -1.6951],\n",
            "        [-2.7470, -0.8436, -2.3742, -3.0450, -1.6899, -2.5887, -3.3323, -2.6640],\n",
            "        [-2.0287, -1.5967, -2.2169, -2.6739, -1.9752, -1.9826, -2.6782, -1.9459],\n",
            "        [-1.8064, -2.3983, -2.3406, -2.7600, -2.0589, -1.7375, -1.8994, -2.0242],\n",
            "        [-2.3116, -1.1927, -2.2139, -2.6718, -1.8048, -2.5547, -2.9340, -2.0900],\n",
            "        [-1.8814, -3.4616, -2.7623, -1.7716, -2.0003, -1.6123, -1.8653, -2.3702],\n",
            "        [-2.2850, -1.8829, -1.9023, -2.3176, -1.4513, -2.4181, -2.7361, -2.2059],\n",
            "        [-2.3255, -1.2626, -2.2067, -2.6496, -1.8263, -2.2121, -2.6714, -2.3130],\n",
            "        [-5.3427, -4.6455, -6.0254, -3.8341, -5.0328, -1.5858, -0.6366, -1.5088],\n",
            "        [-1.9501, -2.2357, -2.3919, -2.0689, -1.6610, -2.1822, -2.5042, -1.9068],\n",
            "        [-2.1231, -3.9662, -2.2340, -1.7872, -1.9486, -1.7575, -1.7667, -2.2925],\n",
            "        [-2.1974, -1.2242, -2.4057, -2.9990, -2.0022, -2.0714, -2.5670, -2.1449],\n",
            "        [-1.7877, -2.4874, -2.2091, -2.1355, -1.6943, -2.2009, -2.6050, -1.8759],\n",
            "        [-3.1252, -2.9257, -3.5223, -2.7362, -2.8519, -0.7808, -1.4948, -2.6876],\n",
            "        [-2.1928, -2.0872, -1.8604, -2.5482, -1.6166, -2.1436, -2.3919, -2.0934],\n",
            "        [-1.8506, -2.5218, -2.1222, -2.0509, -1.8507, -2.0974, -2.2203, -2.0740],\n",
            "        [-2.8091, -4.3732, -3.3881, -1.6079, -2.3361, -1.1146, -1.4961, -3.1170],\n",
            "        [-2.6184, -1.4583, -2.1093, -2.3960, -1.5172, -2.3948, -2.7868, -2.2080],\n",
            "        [-1.9846, -3.0560, -2.6855, -2.0601, -2.3097, -1.2627, -1.9528, -2.3456],\n",
            "        [-2.5599, -4.6996, -2.6754, -1.2449, -2.1503, -1.8529, -1.6318, -2.4312],\n",
            "        [-2.1237, -1.4916, -2.5587, -2.7202, -1.5591, -2.1214, -2.4207, -2.3741],\n",
            "        [-1.9152, -1.4525, -2.4489, -2.6977, -1.6992, -2.2980, -2.6209, -2.2171],\n",
            "        [-1.8681, -2.6758, -2.4768, -1.9045, -1.5949, -2.1428, -2.3677, -2.0412],\n",
            "        [-2.3457, -3.0865, -2.8990, -2.2875, -2.5678, -0.9764, -1.7729, -2.5417],\n",
            "        [-1.7189, -2.8558, -2.7769, -2.0302, -1.9393, -1.7964, -1.9755, -2.1095],\n",
            "        [-2.0044, -4.0817, -2.7229, -1.3731, -2.1565, -1.8328, -1.8008, -2.4246]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 5, 5, 7, 7, 7, 7, 4, 7, 6, 7, 6, 7, 6, 6, 5, 2, 7, 7, 6, 6, 6, 5, 2,\n",
            "        5, 6, 7, 5, 3, 5, 6, 5], device='cuda:0')\n",
            "tensor([[-1.8826, -2.3643, -2.3559, -2.0478, -1.5732, -2.0930, -2.4295, -2.1966],\n",
            "        [-2.0356, -4.2313, -2.8614, -1.6575, -1.9191, -1.5911, -1.7782, -2.4342],\n",
            "        [-3.0496, -0.7278, -2.3666, -2.9641, -1.7762, -2.7206, -3.4873, -2.8378],\n",
            "        [-2.0790, -2.5787, -2.4903, -1.6068, -1.4035, -2.3626, -2.6159, -2.2762],\n",
            "        [-2.0577, -3.1286, -2.4597, -2.1213, -2.2688, -1.4288, -1.8857, -2.0527],\n",
            "        [-2.3435, -2.6644, -2.4743, -2.2521, -1.9986, -1.3542, -1.8707, -2.3303],\n",
            "        [-2.4610, -4.5297, -2.4432, -1.3959, -2.2354, -1.5693, -1.7611, -2.4964],\n",
            "        [-2.0778, -2.9208, -2.0098, -1.9818, -1.6054, -2.3660, -2.3397, -1.8449],\n",
            "        [-1.9906, -2.4008, -2.1359, -2.3585, -1.8363, -1.8573, -2.3018, -1.9347],\n",
            "        [-2.1455, -3.5710, -2.2530, -1.9469, -1.5343, -2.1132, -1.8989, -2.1130],\n",
            "        [-2.1114, -3.7086, -2.5029, -1.9255, -2.1561, -1.4943, -1.8791, -2.0109],\n",
            "        [-2.2118, -3.3644, -2.9070, -2.0733, -2.0356, -1.3586, -1.6106, -2.4292],\n",
            "        [-2.4456, -2.7449, -2.0291, -1.7490, -1.3778, -2.1618, -2.8406, -2.1369],\n",
            "        [-2.7265, -1.1938, -2.5765, -2.7171, -1.6037, -2.1430, -2.2837, -2.6736],\n",
            "        [-2.1583, -3.4784, -2.3110, -1.6836, -1.4744, -2.0343, -2.1705, -2.3544],\n",
            "        [-1.8215, -3.4717, -2.6408, -1.8212, -2.1067, -1.6756, -1.8856, -2.1765],\n",
            "        [-2.1514, -3.2416, -2.3466, -2.2424, -2.2448, -1.2841, -1.9667, -2.1211],\n",
            "        [-1.6104, -2.8227, -2.5767, -1.6655, -2.0061, -1.9256, -2.6758, -2.0678],\n",
            "        [-2.1812, -3.3875, -2.1485, -1.9703, -1.8270, -1.8650, -1.8605, -2.0728],\n",
            "        [-1.7549, -3.3972, -2.1248, -1.8458, -1.8267, -2.1779, -2.1526, -2.0725],\n",
            "        [-1.7614, -3.3245, -2.0654, -1.6896, -1.9343, -2.2155, -2.5801, -1.8876],\n",
            "        [-2.1669, -1.9940, -2.1473, -2.5619, -1.8464, -1.7096, -2.2765, -2.1716],\n",
            "        [-2.3931, -2.3827, -2.2523, -2.0462, -1.2555, -2.1379, -2.4278, -2.3981],\n",
            "        [-1.8633, -3.4831, -2.2508, -1.8924, -2.1414, -1.7848, -1.9298, -2.0588],\n",
            "        [-2.7181, -3.8706, -2.9103, -1.8196, -2.3284, -1.0759, -1.6795, -2.6355],\n",
            "        [-2.2855, -3.1970, -2.0946, -1.9852, -1.5251, -1.9498, -2.0386, -2.2366],\n",
            "        [-2.5731, -1.2532, -2.1632, -2.3134, -1.6246, -2.4938, -3.1776, -2.2732],\n",
            "        [-1.7403, -3.4143, -2.0739, -1.7038, -2.1582, -2.2162, -2.4186, -1.7699],\n",
            "        [-2.3024, -4.9242, -2.7289, -1.4097, -2.2973, -1.5755, -1.7963, -2.2087],\n",
            "        [-1.8363, -3.2849, -2.4092, -1.7161, -1.9341, -1.8149, -2.1729, -2.1871],\n",
            "        [-1.8783, -3.0684, -2.2672, -1.7027, -1.6007, -2.2955, -2.4846, -2.0476],\n",
            "        [-1.6578, -3.3184, -2.4118, -1.8036, -2.1971, -1.8857, -2.0223, -2.0902]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 6, 1, 5, 7, 5, 7, 7, 6, 5, 7, 5, 7, 1, 4, 3, 7, 6, 6, 6, 6, 5, 4, 2,\n",
            "        5, 3, 7, 3, 7, 5, 7, 6], device='cuda:0')\n",
            "tensor([[-2.4563, -4.3593, -2.3267, -1.4668, -1.6576, -1.9092, -1.8498, -2.5622],\n",
            "        [-2.2167, -4.1505, -2.3360, -1.4245, -1.8014, -2.0293, -2.1966, -2.0383],\n",
            "        [-2.2205, -2.4809, -2.0706, -1.7437, -1.5885, -2.1382, -2.7306, -2.1243],\n",
            "        [-2.3293, -2.6913, -1.8688, -1.9475, -1.5346, -2.1134, -2.7019, -2.0064],\n",
            "        [-2.1512, -4.0253, -2.2998, -1.5633, -1.6241, -2.0205, -2.2013, -2.1564],\n",
            "        [-2.5728, -2.5884, -1.7182, -1.8298, -1.4960, -2.4216, -2.6916, -2.0549],\n",
            "        [-2.2166, -4.0510, -2.2569, -1.5514, -1.7262, -2.0193, -2.1045, -2.0845],\n",
            "        [-2.2259, -2.9292, -2.3548, -1.8151, -1.2924, -2.1782, -2.5315, -2.1763],\n",
            "        [-2.0810, -3.4719, -2.0368, -1.6327, -1.8598, -2.1000, -2.2894, -1.9747],\n",
            "        [-2.7773, -1.4917, -1.7150, -2.3199, -1.7093, -2.2723, -3.1708, -2.2207],\n",
            "        [-1.8637, -3.2637, -2.0452, -2.1744, -1.7412, -1.9499, -2.1205, -2.0711],\n",
            "        [-1.8972, -3.1136, -2.0907, -1.8648, -1.7730, -2.1907, -2.5074, -1.8086],\n",
            "        [-2.7956, -4.6886, -2.8920, -1.3989, -2.3507, -1.2881, -1.6276, -2.8153],\n",
            "        [-1.8898, -3.0823, -2.4493, -2.0219, -1.7696, -1.8614, -2.0245, -2.0686],\n",
            "        [-2.4724, -1.9384, -1.9241, -2.3473, -1.3486, -2.2150, -2.6031, -2.4391],\n",
            "        [-2.5205, -2.2312, -2.2036, -2.6140, -2.0407, -1.4718, -1.8218, -2.2317],\n",
            "        [-3.4049, -0.5952, -2.9350, -3.5953, -1.6279, -2.8977, -3.2930, -3.0762],\n",
            "        [-2.2352, -3.5615, -2.0574, -1.6241, -1.5787, -2.0899, -2.2189, -2.2918],\n",
            "        [-2.2409, -3.0715, -1.9460, -2.2377, -1.7064, -1.7586, -2.0375, -2.1753],\n",
            "        [-2.0878, -3.4375, -2.2479, -1.9783, -2.1271, -1.5057, -1.9626, -2.1335],\n",
            "        [-2.2796, -2.0693, -2.3217, -2.3534, -1.4059, -2.0318, -2.4041, -2.1923],\n",
            "        [-2.2000, -4.4237, -1.9694, -1.6003, -2.2363, -1.7994, -2.0027, -2.0510],\n",
            "        [-1.9153, -3.2326, -1.9854, -1.9309, -1.8343, -2.0558, -2.3288, -1.9258],\n",
            "        [-2.1481, -3.1435, -2.3225, -1.9630, -1.9981, -1.4980, -2.0080, -2.2230],\n",
            "        [-2.3537, -4.0299, -2.2626, -1.5560, -1.5059, -2.2457, -2.3160, -1.9255],\n",
            "        [-2.0933, -3.8026, -2.4839, -1.3471, -1.9606, -1.8712, -2.0110, -2.4958],\n",
            "        [-2.0021, -3.2033, -2.3652, -1.8467, -1.9928, -1.8097, -1.9180, -2.0737],\n",
            "        [-2.1408, -3.6249, -2.7370, -1.3781, -1.7371, -1.9667, -1.8672, -2.6813],\n",
            "        [-3.3794, -4.7928, -3.5029, -1.9573, -2.7775, -1.1358, -1.1329, -2.5154],\n",
            "        [-1.8940, -3.0649, -2.2532, -1.6446, -1.8496, -2.0599, -2.6572, -1.8983],\n",
            "        [-2.0737, -3.4637, -2.3833, -1.5895, -1.8253, -2.0135, -2.1499, -1.9988],\n",
            "        [-2.6078, -1.9797, -1.9455, -1.9818, -1.2762, -2.4495, -3.0102, -2.3781]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([3, 6, 5, 7, 6, 5, 5, 7, 6, 7, 7, 7, 3, 5, 7, 5, 1, 6, 6, 3, 1, 7, 7, 7,\n",
            "        7, 5, 0, 6, 6, 7, 6, 3], device='cuda:0')\n",
            "tensor([[-2.4409, -2.9246, -1.8323, -2.1570, -1.8098, -1.8712, -2.0601, -1.9774],\n",
            "        [-2.5838, -1.2330, -2.1491, -2.6974, -1.6915, -2.4044, -2.8854, -2.1308],\n",
            "        [-2.5301, -2.4770, -1.9857, -1.7997, -1.5445, -2.2305, -2.4794, -2.0476],\n",
            "        [-3.5311, -4.0161, -3.4697, -1.9115, -2.7926, -1.1772, -1.2069, -2.2519],\n",
            "        [-2.3720, -2.0267, -2.4273, -2.4895, -1.7061, -1.7617, -2.1069, -2.0496],\n",
            "        [-2.7704, -2.9859, -2.0944, -1.6358, -1.6978, -1.9302, -2.1976, -2.0428],\n",
            "        [-1.8125, -3.3337, -2.1961, -1.9572, -1.9373, -2.0498, -2.3098, -1.7346],\n",
            "        [-2.8773, -1.6821, -2.2692, -2.4350, -1.1512, -2.4276, -2.9552, -2.2058],\n",
            "        [-2.6347, -3.4864, -2.4001, -1.8144, -1.8205, -1.5440, -1.8146, -2.2475],\n",
            "        [-3.2213, -1.4727, -2.2241, -1.9930, -1.3294, -2.1572, -3.2012, -2.7279],\n",
            "        [-2.4215, -3.3644, -2.4728, -1.6030, -1.7863, -1.5803, -2.0597, -2.4078],\n",
            "        [-2.6056, -3.4324, -2.5639, -2.2859, -2.4627, -1.1153, -1.6410, -2.2225],\n",
            "        [-2.1754, -2.7976, -2.1050, -1.7408, -1.6524, -2.2063, -2.4427, -1.9686],\n",
            "        [-2.7418, -1.8605, -2.0415, -2.3602, -1.3952, -2.1391, -2.4502, -2.2645],\n",
            "        [-3.5363, -0.6861, -2.3296, -2.9322, -1.7837, -2.8942, -3.5799, -2.7258],\n",
            "        [-2.3570, -2.9838, -2.1418, -1.8407, -1.6327, -2.1453, -2.1073, -1.9341],\n",
            "        [-2.7524, -2.1853, -1.6517, -2.1160, -1.6761, -2.3700, -2.5151, -1.8965],\n",
            "        [-2.5339, -4.1005, -2.1551, -1.4096, -1.8996, -1.9056, -1.7981, -2.5258],\n",
            "        [-2.2985, -2.7796, -2.2013, -2.1223, -1.6064, -2.0185, -2.2495, -1.7827],\n",
            "        [-2.4158, -3.7805, -2.9489, -1.5026, -1.7939, -1.8104, -1.5751, -2.5762],\n",
            "        [-2.8232, -2.6500, -1.7665, -1.9496, -1.2806, -2.3711, -3.0598, -1.9768],\n",
            "        [-1.9711, -2.6196, -2.3780, -2.0011, -1.6044, -1.9973, -2.1711, -2.2147],\n",
            "        [-2.3961, -2.5951, -2.4133, -1.8382, -1.4632, -2.1358, -2.5394, -1.8508],\n",
            "        [-2.5049, -2.4756, -2.4064, -2.4952, -2.1320, -1.3700, -1.7980, -2.0937],\n",
            "        [-4.1196, -4.5728, -3.9734, -2.0772, -3.3455, -1.5873, -0.7117, -2.3149],\n",
            "        [-2.1993, -2.3762, -2.0151, -1.7200, -1.5549, -2.2910, -2.9852, -2.1125],\n",
            "        [-2.5513, -1.8847, -2.0075, -2.0414, -1.4777, -2.4452, -2.6780, -2.1003],\n",
            "        [-2.6048, -1.9527, -2.0203, -2.2191, -1.3570, -2.2513, -2.5446, -2.2861],\n",
            "        [-2.2447, -3.0668, -2.1239, -2.0176, -1.8942, -1.6935, -1.9356, -2.1517],\n",
            "        [-2.5474, -4.3450, -2.2199, -1.2585, -2.0326, -2.1455, -2.1069, -1.9212],\n",
            "        [-2.2229, -3.6830, -2.2933, -1.3166, -1.8109, -2.0355, -2.4236, -2.1642],\n",
            "        [-2.1980, -2.8091, -2.2047, -2.0183, -1.5871, -1.9612, -2.1127, -2.1251]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 6, 2, 5, 6, 6, 7, 0, 6, 5, 6, 6, 3, 1, 1, 6, 2, 6, 5, 6, 6, 6, 6, 7,\n",
            "        6, 0, 6, 0, 0, 7, 3, 6], device='cuda:0')\n",
            "tensor([[-2.3247, -2.4604, -2.0238, -1.9908, -1.6853, -2.1743, -2.5817, -1.7526],\n",
            "        [-2.3245, -3.5126, -2.1806, -1.5748, -1.9852, -1.9533, -1.8857, -2.1082],\n",
            "        [-2.6382, -2.3762, -1.9693, -1.7924, -1.3581, -2.6847, -3.0689, -1.8476],\n",
            "        [-2.4008, -2.4014, -2.0179, -1.9029, -1.7921, -2.0167, -2.6723, -1.7845],\n",
            "        [-2.8484, -2.4487, -1.7937, -1.6859, -1.6430, -2.1303, -2.6795, -2.0938],\n",
            "        [-2.5089, -3.1736, -1.9686, -1.9351, -1.7487, -1.8804, -1.9470, -2.0916],\n",
            "        [-2.0219, -3.8543, -2.2024, -1.5006, -2.1295, -2.1790, -2.1477, -1.8074],\n",
            "        [-2.7018, -2.8252, -2.1871, -2.0952, -1.6119, -2.0191, -1.7250, -2.0567],\n",
            "        [-2.0932, -3.2064, -2.5360, -1.5584, -2.0329, -1.7894, -1.9886, -2.1923],\n",
            "        [-2.3170, -3.3367, -1.9084, -1.7492, -1.9030, -2.0631, -2.1345, -1.9027],\n",
            "        [-2.6744, -2.0826, -1.7640, -2.2405, -1.6291, -2.0950, -2.6700, -1.9642],\n",
            "        [-2.6826, -2.6324, -1.6874, -1.8478, -1.6775, -2.3012, -2.9958, -1.7139],\n",
            "        [-2.9260, -2.8623, -2.4275, -2.3953, -2.4187, -1.1557, -1.6837, -2.1179],\n",
            "        [-2.0247, -3.8420, -2.1056, -1.5417, -1.9737, -2.1554, -2.3419, -1.8339],\n",
            "        [-2.4836, -2.8621, -2.0932, -1.7405, -1.7330, -2.2422, -2.2303, -1.7707],\n",
            "        [-2.2021, -1.7895, -2.0446, -2.3527, -1.7255, -2.3854, -2.5027, -1.9252],\n",
            "        [-3.0457, -2.2630, -1.6474, -2.0652, -1.3814, -2.4088, -2.7067, -2.1107],\n",
            "        [-2.2213, -2.5903, -1.7542, -1.8298, -1.7588, -2.5171, -2.6264, -1.8467],\n",
            "        [-2.3880, -3.3310, -2.5088, -1.4410, -1.9564, -1.6978, -1.9337, -2.4614],\n",
            "        [-2.8177, -2.4777, -1.9345, -1.8619, -1.6411, -2.0904, -2.0697, -2.1819],\n",
            "        [-2.2233, -2.3113, -1.9353, -2.1316, -1.7505, -2.2407, -2.3537, -1.8676],\n",
            "        [-2.3660, -2.8173, -2.2454, -1.9079, -1.4056, -2.1322, -2.4312, -1.9635],\n",
            "        [-3.0547, -5.2349, -2.9110, -1.2267, -2.7129, -1.2995, -1.6878, -2.5777],\n",
            "        [-2.5666, -1.5858, -2.2593, -2.5894, -1.9072, -1.6735, -2.2867, -2.2901],\n",
            "        [-2.3690, -1.8177, -2.0242, -2.4799, -1.7402, -2.0564, -2.5442, -1.9225],\n",
            "        [-2.2280, -2.0443, -1.9508, -2.0063, -2.0828, -2.1119, -2.4178, -1.8876],\n",
            "        [-3.2794, -1.2605, -1.8138, -2.7222, -1.5996, -2.4395, -3.0155, -2.1903],\n",
            "        [-2.4131, -3.0358, -2.0162, -1.6966, -1.5512, -2.2851, -2.2956, -2.0288],\n",
            "        [-2.4142, -2.4990, -2.0171, -1.7375, -1.6499, -2.2394, -2.4466, -2.0083],\n",
            "        [-2.5325, -3.9460, -2.3346, -1.6198, -2.2929, -1.4067, -1.8468, -2.2753],\n",
            "        [-2.4771, -2.6959, -1.9117, -1.7202, -1.7720, -2.3081, -2.2549, -1.9149],\n",
            "        [-2.3486, -3.0494, -2.0590, -1.5226, -1.9458, -2.0622, -2.2337, -2.0084]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 6, 7, 5, 6, 0, 0, 6, 5, 3, 5, 7, 2, 0, 7, 6, 7, 0, 5, 5, 6, 7, 5, 7,\n",
            "        0, 0, 5, 7, 7, 5, 6, 5], device='cuda:0')\n",
            "tensor([[-2.1698, -3.1226, -2.0490, -1.9225, -1.9352, -1.9640, -2.0532, -1.8732],\n",
            "        [-1.9398, -2.7866, -2.2644, -1.8123, -2.0229, -2.1074, -2.3171, -1.7424],\n",
            "        [-2.2475, -3.7459, -2.3529, -1.5401, -2.2689, -1.7999, -1.8716, -1.9758],\n",
            "        [-2.4770, -2.2928, -1.9993, -2.0797, -1.9409, -2.0695, -2.1411, -1.7881],\n",
            "        [-2.5533, -3.6156, -2.0568, -1.4158, -1.7577, -2.2700, -2.1174, -2.0512],\n",
            "        [-2.3607, -3.1483, -2.1475, -1.8723, -1.9946, -1.6957, -1.8563, -2.1508],\n",
            "        [-2.4417, -3.5477, -1.9698, -1.6583, -1.7871, -2.0962, -2.0414, -2.0098],\n",
            "        [-2.2502, -2.8436, -1.9870, -1.9387, -2.0629, -2.0128, -2.1891, -1.6999],\n",
            "        [-2.8911, -1.7705, -1.8375, -2.0969, -1.7680, -2.2432, -2.9914, -1.8008],\n",
            "        [-1.9451, -2.9051, -1.9807, -1.7243, -1.9847, -2.2071, -2.2640, -2.0052],\n",
            "        [-2.9416, -2.7433, -1.6828, -2.1111, -1.5294, -2.1958, -2.1522, -2.0268],\n",
            "        [-2.7036, -2.5586, -2.1107, -2.2694, -1.9327, -1.4140, -1.9666, -2.2707],\n",
            "        [-2.4393, -3.5866, -2.3799, -1.5449, -1.8748, -1.8150, -1.9136, -2.1593],\n",
            "        [-2.4998, -1.7798, -1.7795, -2.2766, -1.7919, -2.4481, -2.5687, -1.9097],\n",
            "        [-2.5766, -3.9839, -1.8869, -1.6175, -1.7680, -2.3147, -2.1670, -1.7636],\n",
            "        [-3.0058, -2.5697, -2.1329, -2.1194, -1.7095, -1.6076, -1.8777, -2.2918],\n",
            "        [-2.8562, -2.0841, -2.0332, -2.0861, -1.7014, -1.8545, -2.0708, -2.3231],\n",
            "        [-1.9421, -3.7392, -2.1769, -1.6415, -2.1717, -2.0331, -1.9638, -1.9625],\n",
            "        [-2.5357, -2.7302, -2.0314, -2.0343, -2.1566, -1.7006, -1.8839, -1.9422],\n",
            "        [-2.7252, -0.9128, -2.6067, -2.8305, -1.8440, -2.4133, -2.3861, -2.8030],\n",
            "        [-2.4434, -2.6338, -1.8961, -1.6406, -1.7844, -2.2098, -2.4625, -2.0064],\n",
            "        [-2.2511, -3.7138, -2.1174, -1.5492, -1.8223, -2.1251, -2.1940, -1.9308],\n",
            "        [-1.9702, -2.8215, -1.9484, -2.0099, -2.1028, -1.9637, -2.3988, -1.7645],\n",
            "        [-3.8597, -0.5442, -2.3239, -3.2046, -1.8885, -3.3356, -3.8874, -2.9419],\n",
            "        [-2.4601, -3.4600, -1.7612, -2.1476, -2.4363, -1.8559, -1.8603, -1.6342],\n",
            "        [-2.4776, -1.8678, -2.2672, -2.2338, -1.6658, -2.1620, -2.0233, -2.1669],\n",
            "        [-2.4443, -2.7115, -2.0383, -1.9681, -1.5858, -2.1171, -2.0020, -2.1491],\n",
            "        [-2.7373, -1.8548, -2.0058, -2.1252, -1.7078, -2.1597, -2.4995, -1.9238],\n",
            "        [-1.9684, -2.7506, -2.1668, -2.1531, -2.1029, -1.9215, -2.0488, -1.7815],\n",
            "        [-3.4476, -3.5948, -2.9968, -2.2704, -2.6906, -0.9451, -1.3387, -2.6759],\n",
            "        [-2.6863, -2.3935, -2.2090, -1.5276, -1.5897, -2.1328, -2.5506, -2.1789],\n",
            "        [-2.9143, -4.4762, -1.8905, -1.5131, -2.0992, -1.8976, -1.8795, -1.9804]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([3, 6, 5, 7, 7, 4, 6, 5, 2, 7, 7, 5, 3, 3, 4, 6, 7, 0, 3, 1, 3, 0, 5, 1,\n",
            "        5, 4, 6, 5, 7, 6, 3, 5], device='cuda:0')\n",
            "tensor([[-2.8577, -1.9851, -1.7650, -1.8769, -1.7762, -2.4567, -2.7823, -1.8073],\n",
            "        [-2.2753, -2.6749, -2.4572, -1.5331, -2.0198, -1.8227, -2.0519, -2.2631],\n",
            "        [-1.9062, -2.5614, -2.0279, -2.0631, -2.1779, -2.2134, -2.3162, -1.6386],\n",
            "        [-2.6872, -2.9182, -2.7515, -2.2439, -2.4485, -1.0809, -1.6625, -2.3791],\n",
            "        [-2.3360, -3.3905, -2.0880, -1.7100, -1.9277, -2.0043, -1.7932, -2.1359],\n",
            "        [-2.0465, -2.6448, -1.9350, -1.7078, -2.1975, -2.0440, -2.3987, -1.9472],\n",
            "        [-2.7531, -3.9404, -2.2080, -1.9775, -2.5254, -1.4129, -1.5108, -2.0850],\n",
            "        [-2.4510, -2.9293, -2.1081, -1.4391, -1.7427, -2.1867, -2.3257, -2.1482],\n",
            "        [-2.4818, -3.0887, -1.9246, -2.1630, -2.5114, -1.4466, -1.9315, -1.9073],\n",
            "        [-2.1245, -3.5856, -1.8429, -1.5734, -2.3011, -2.2027, -2.3709, -1.6980],\n",
            "        [-2.3180, -3.3669, -2.0601, -1.8618, -2.4508, -1.6009, -1.8218, -2.0059],\n",
            "        [-2.3199, -3.7426, -1.9354, -1.2895, -2.0996, -2.3285, -2.1783, -2.0788],\n",
            "        [-2.4684, -3.5901, -2.0348, -1.3551, -2.1139, -1.9107, -2.1801, -2.1433],\n",
            "        [-2.6727, -2.9522, -1.6585, -1.8561, -1.7713, -2.0107, -2.1329, -2.2120],\n",
            "        [-2.2807, -3.5732, -1.6848, -1.6067, -2.1264, -2.2710, -2.2232, -1.8776],\n",
            "        [-2.3877, -3.4534, -2.3623, -1.3318, -1.8542, -1.9669, -2.0465, -2.3791],\n",
            "        [-2.5023, -3.0965, -2.2014, -1.7442, -1.9165, -1.7440, -1.8196, -2.2687],\n",
            "        [-2.8173, -1.8441, -1.5901, -2.1909, -1.8114, -2.4479, -2.6467, -1.9272],\n",
            "        [-2.4676, -2.2925, -1.6954, -2.0947, -1.7527, -2.1779, -2.6926, -1.8756],\n",
            "        [-2.5022, -3.4696, -1.9120, -1.8543, -2.2618, -1.7638, -1.9297, -1.8210],\n",
            "        [-2.9333, -1.8104, -1.9571, -2.0285, -1.5071, -2.1840, -2.3179, -2.5540],\n",
            "        [-2.3976, -1.9969, -1.9684, -1.8757, -1.9005, -2.2966, -2.2837, -2.0528],\n",
            "        [-2.2148, -3.1776, -2.2920, -1.9346, -2.0546, -1.7736, -1.7127, -2.0768],\n",
            "        [-2.6172, -1.9049, -1.7520, -2.0215, -1.8834, -2.4739, -2.4689, -1.8888],\n",
            "        [-2.0747, -3.8282, -2.0580, -1.4730, -2.2398, -2.0848, -2.3983, -1.7486],\n",
            "        [-2.7815, -1.8551, -1.7876, -1.9688, -1.8613, -2.1064, -2.4725, -2.1794],\n",
            "        [-2.7499, -2.3840, -2.1893, -1.9740, -1.9814, -1.6697, -1.7241, -2.4250],\n",
            "        [-2.2325, -3.9949, -2.4770, -1.3090, -2.0956, -1.9243, -1.9093, -2.2723],\n",
            "        [-2.6145, -1.7038, -1.7843, -2.1206, -1.8403, -2.5133, -2.5923, -1.9497],\n",
            "        [-2.4064, -4.5741, -1.9350, -1.2751, -2.1595, -2.0477, -2.2629, -2.0615],\n",
            "        [-2.4374, -1.9501, -2.0160, -1.9840, -1.7941, -2.2058, -2.0951, -2.3011],\n",
            "        [-2.9321, -3.7740, -2.1036, -1.4127, -2.3580, -1.6679, -1.8433, -2.1482]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 5, 7, 5, 6, 7, 0, 6, 7, 7, 5, 3, 5, 6, 7, 5, 7, 5, 7, 5, 4, 5, 6, 7,\n",
            "        7, 5, 6, 5, 7, 0, 6, 6], device='cuda:0')\n",
            "tensor([[-2.3512, -2.3240, -2.0184, -1.9549, -1.9629, -2.1206, -2.3106, -1.7556],\n",
            "        [-2.0865, -2.3157, -2.2923, -1.9130, -2.0574, -1.8573, -2.0636, -2.1404],\n",
            "        [-2.5550, -1.2307, -2.0077, -2.9605, -2.3484, -2.2646, -2.5721, -1.7816],\n",
            "        [-2.0702, -2.2872, -2.0036, -2.0384, -1.9825, -2.1160, -2.1894, -1.9880],\n",
            "        [-2.4934, -1.6765, -2.0665, -2.2115, -2.0119, -2.1433, -2.6552, -1.7551],\n",
            "        [-1.8963, -2.9099, -1.8250, -2.1695, -2.1595, -2.2191, -2.4037, -1.5824],\n",
            "        [-2.8079, -1.2072, -2.0069, -2.2473, -1.7911, -2.6502, -3.0013, -2.1766],\n",
            "        [-2.0168, -3.9814, -2.2751, -1.5508, -2.2684, -2.1612, -1.8785, -1.8208],\n",
            "        [-2.7786, -0.9520, -2.1946, -2.9667, -2.0235, -2.4176, -2.6850, -2.3077],\n",
            "        [-3.3268, -3.2422, -3.1364, -2.2202, -2.9245, -0.8608, -1.4283, -2.8691],\n",
            "        [-2.8087, -2.5821, -1.8924, -2.2886, -2.3569, -1.3997, -1.8838, -2.1322],\n",
            "        [-2.4391, -1.8491, -2.3541, -2.5511, -2.0173, -1.7751, -1.8781, -2.0631],\n",
            "        [-2.4821, -2.3020, -1.9206, -2.1441, -2.0554, -1.7904, -2.2188, -1.9037],\n",
            "        [-2.4890, -2.7723, -2.2357, -1.8758, -2.0065, -1.8573, -1.6148, -2.2551],\n",
            "        [-2.7052, -3.3441, -1.8105, -1.7816, -2.2628, -1.6177, -1.9275, -2.1372],\n",
            "        [-3.5221, -1.0130, -1.9560, -2.3173, -1.7946, -2.6800, -3.3193, -2.3388],\n",
            "        [-2.4295, -2.8159, -2.1567, -1.5902, -1.8508, -2.0141, -2.2877, -1.9632]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 0, 7, 5, 6, 0, 4, 0, 2, 6, 0, 6, 5, 6, 6, 6, 3], device='cuda:0')\n",
            "\n",
            "Evaluating...\n",
            "tensor(1.9952, device='cuda:0')\n",
            "tensor(1.7659, device='cuda:0')\n",
            "\n",
            "Training Loss: 1.866\n",
            "Validation Loss: 1.881\n",
            "\n",
            " Epoch 10 / 10\n",
            "tensor([[-2.1973, -1.7019, -2.3388, -2.0607, -1.9121, -2.0978, -2.1925, -2.2963],\n",
            "        [-2.1870, -2.9298, -2.5561, -1.5856, -1.8345, -1.8805, -2.0157, -2.2399],\n",
            "        [-2.7222, -3.1211, -2.1065, -1.9790, -2.3858, -1.3804, -1.7054, -2.2529],\n",
            "        [-2.0431, -3.2581, -2.2114, -1.5446, -2.6354, -1.9686, -2.1572, -1.7038],\n",
            "        [-2.6761, -1.4711, -1.6429, -2.2658, -2.0628, -2.5465, -3.0859, -1.8761],\n",
            "        [-2.5212, -2.3744, -1.8452, -2.3388, -1.6433, -2.1722, -2.4508, -1.7224],\n",
            "        [-1.9031, -3.3310, -1.9245, -1.6505, -2.2633, -2.4413, -2.3601, -1.6515],\n",
            "        [-2.2910, -1.9109, -1.7326, -2.1489, -1.9036, -2.4479, -2.5344, -1.9474],\n",
            "        [-2.0124, -2.3046, -1.7970, -2.1884, -2.4632, -2.2768, -2.5278, -1.5095],\n",
            "        [-2.1404, -2.2104, -2.2094, -1.8379, -1.7407, -2.2011, -2.1855, -2.2508],\n",
            "        [-2.0239, -3.1478, -2.0377, -1.6612, -2.0748, -2.3285, -2.3624, -1.6741],\n",
            "        [-2.5773, -3.4511, -1.9486, -1.6834, -1.9809, -1.8980, -1.9309, -2.0305],\n",
            "        [-2.0440, -3.5639, -1.8948, -2.0340, -2.3893, -1.6957, -2.0660, -1.8379],\n",
            "        [-1.9596, -3.1803, -2.3798, -1.7789, -2.1834, -1.7749, -1.9201, -2.0606],\n",
            "        [-2.5108, -1.3653, -1.8885, -2.6560, -2.0942, -2.3775, -2.5997, -1.8858],\n",
            "        [-1.9782, -3.3637, -2.0431, -1.6116, -2.2034, -2.1445, -2.2537, -1.8000],\n",
            "        [-1.9184, -3.6069, -2.1124, -1.5523, -2.3552, -2.1941, -2.1833, -1.7470],\n",
            "        [-2.4457, -5.1141, -2.1078, -1.4367, -2.6510, -1.9041, -1.8448, -1.7689],\n",
            "        [-2.2473, -2.8588, -2.0198, -2.1131, -1.9714, -2.0120, -2.0508, -1.7048],\n",
            "        [-2.2933, -3.5787, -2.0475, -1.4885, -1.9858, -2.0206, -1.9546, -2.2547],\n",
            "        [-2.0111, -3.8624, -2.0175, -1.6985, -2.4089, -2.2033, -2.2718, -1.4885],\n",
            "        [-2.5292, -3.9027, -2.3588, -1.6844, -2.2862, -1.6640, -1.6619, -1.9719],\n",
            "        [-2.1115, -2.5028, -1.9361, -1.6523, -2.3426, -2.1894, -2.4022, -1.8163],\n",
            "        [-2.3921, -1.6508, -1.7562, -2.4872, -2.1095, -2.4783, -2.8124, -1.6318],\n",
            "        [-2.0070, -1.8015, -2.2861, -2.5256, -1.9553, -1.8376, -2.3414, -2.1040],\n",
            "        [-2.0409, -2.1831, -2.1370, -1.9127, -2.0323, -2.3453, -2.3650, -1.7666],\n",
            "        [-1.8847, -2.8997, -1.9847, -1.6798, -1.9342, -2.3414, -2.4520, -1.9491],\n",
            "        [-2.3826, -1.7215, -1.8010, -1.9760, -2.0924, -2.3805, -2.7944, -1.9100],\n",
            "        [-2.5327, -2.3207, -1.8359, -1.8016, -1.9300, -2.4405, -2.5745, -1.6639],\n",
            "        [-2.2306, -2.7387, -2.1777, -1.7906, -1.9592, -2.0490, -2.0246, -1.9252],\n",
            "        [-2.2478, -2.1825, -1.9117, -2.3320, -2.1807, -2.0125, -1.9293, -1.9323],\n",
            "        [-1.8900, -3.3738, -2.3061, -1.5068, -2.3615, -2.2114, -2.2330, -1.7017]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([4, 5, 5, 5, 7, 7, 7, 5, 7, 6, 7, 5, 7, 3, 6, 0, 6, 0, 7, 6, 7, 5, 7, 7,\n",
            "        6, 7, 0, 7, 6, 5, 6, 7], device='cuda:0')\n",
            "tensor([[-2.1135, -2.1756, -2.0111, -2.4353, -2.1165, -2.0399, -2.0871, -1.7738],\n",
            "        [-2.0095, -4.0761, -2.4839, -1.5630, -2.2543, -1.8596, -1.9009, -1.9246],\n",
            "        [-2.0401, -3.5630, -2.3480, -1.6800, -2.1362, -1.8929, -1.9986, -1.8614],\n",
            "        [-2.0004, -2.4028, -2.0036, -2.1203, -1.9913, -2.1723, -2.4647, -1.6931],\n",
            "        [-2.0070, -3.4997, -2.2686, -1.6186, -2.1620, -2.1641, -2.1285, -1.6884],\n",
            "        [-2.0364, -2.5717, -2.0472, -1.9608, -1.9909, -2.1306, -2.2181, -1.8382],\n",
            "        [-2.0537, -3.1157, -1.9415, -1.7717, -2.1261, -2.2796, -2.4176, -1.5941],\n",
            "        [-2.0357, -2.6333, -1.9881, -2.0535, -2.0798, -2.2776, -2.3619, -1.5577],\n",
            "        [-2.0296, -3.1292, -2.1940, -1.9734, -2.1339, -1.9240, -1.9832, -1.7581],\n",
            "        [-2.5284, -1.9243, -1.5347, -2.2357, -2.0534, -2.4125, -2.9821, -1.6970],\n",
            "        [-2.6231, -2.5819, -2.6269, -2.5057, -2.8400, -1.1769, -1.4150, -2.4271],\n",
            "        [-2.1123, -1.8671, -2.4529, -2.1596, -2.0574, -2.0301, -2.1452, -1.9179],\n",
            "        [-2.6014, -1.8319, -1.5956, -2.1135, -2.0443, -2.4315, -2.6011, -1.8936],\n",
            "        [-2.1117, -3.5189, -2.1909, -1.8061, -2.0939, -2.0981, -1.7005, -1.9328],\n",
            "        [-1.7533, -3.6675, -2.0720, -1.6733, -2.5707, -2.1411, -2.3991, -1.5951],\n",
            "        [-3.6379, -0.3939, -2.5971, -3.3209, -2.6627, -3.1185, -3.8308, -2.9373],\n",
            "        [-2.5467, -1.6645, -1.5347, -2.4074, -2.1774, -2.6347, -2.6592, -1.7618],\n",
            "        [-2.0826, -2.5131, -1.9059, -2.1745, -2.1022, -2.1965, -2.3645, -1.5865],\n",
            "        [-2.0866, -2.5254, -1.8939, -1.5230, -2.2639, -2.3670, -2.8621, -1.7575],\n",
            "        [-2.2949, -1.7249, -1.7771, -2.6465, -2.0146, -2.3069, -2.6359, -1.7350],\n",
            "        [-5.8420, -5.4840, -5.0570, -3.4593, -4.8071, -2.8166, -0.2104, -2.5657],\n",
            "        [-1.8896, -3.2437, -2.0301, -1.8973, -2.4230, -2.3745, -2.1212, -1.4830],\n",
            "        [-1.8019, -3.8881, -2.4122, -1.4985, -2.5784, -2.0429, -2.1930, -1.6910],\n",
            "        [-2.0252, -3.8325, -2.0503, -1.8211, -2.3276, -1.8230, -1.8566, -1.9620],\n",
            "        [-1.9989, -2.6658, -1.9092, -2.1131, -2.4116, -1.9990, -2.6249, -1.4770],\n",
            "        [-2.4725, -4.2187, -2.4488, -1.7315, -2.5731, -1.5427, -1.4428, -2.1971],\n",
            "        [-1.9713, -3.2647, -1.7161, -2.0655, -2.1983, -1.9442, -2.3689, -1.7820],\n",
            "        [-2.1473, -3.9206, -2.4177, -1.4635, -2.1307, -2.0369, -1.7964, -2.0577],\n",
            "        [-2.1129, -2.8095, -2.2914, -1.7016, -1.9454, -1.9696, -2.0391, -2.0974],\n",
            "        [-1.8147, -1.8013, -2.3059, -2.6242, -2.1067, -2.1246, -2.2450, -1.8786],\n",
            "        [-1.7453, -2.9144, -2.0768, -1.9726, -2.3412, -2.2158, -2.6233, -1.4745],\n",
            "        [-2.3764, -3.1677, -1.8599, -1.9059, -1.9195, -2.1526, -1.9826, -1.8321]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 5, 6, 6, 6, 6, 5, 6, 5, 7, 5, 6, 6, 6, 6, 1, 2, 7, 2, 6, 6, 6, 7, 6,\n",
            "        5, 3, 6, 6, 6, 6, 7, 3], device='cuda:0')\n",
            "tensor([[-1.9992, -3.5762, -2.0058, -1.7717, -2.2264, -2.4653, -2.5265, -1.3504],\n",
            "        [-2.0541, -3.1435, -2.1024, -1.9752, -2.0737, -2.0304, -1.8154, -1.9107],\n",
            "        [-2.3375, -4.1868, -2.2912, -1.6175, -2.5338, -1.4784, -1.7092, -2.2996],\n",
            "        [-1.7394, -3.5572, -2.2271, -1.8012, -2.3567, -2.0107, -2.0457, -1.8019],\n",
            "        [-2.2796, -3.0655, -1.8981, -1.9687, -1.9280, -2.2844, -2.1428, -1.6248],\n",
            "        [-1.9883, -3.0987, -2.1125, -2.4904, -2.5463, -1.6958, -1.8785, -1.6119],\n",
            "        [-1.3960, -3.3956, -2.4338, -1.7301, -2.3784, -2.3043, -2.1381, -1.9412],\n",
            "        [-2.1120, -2.5919, -1.8009, -2.3042, -2.5246, -2.1676, -2.2752, -1.4196],\n",
            "        [-1.9656, -2.6156, -1.8128, -2.2939, -2.2037, -2.2369, -1.9874, -1.7808],\n",
            "        [-2.0201, -3.7516, -2.3629, -1.7609, -2.3561, -1.9960, -1.6550, -1.8575],\n",
            "        [-2.3433, -1.6180, -1.8826, -2.7772, -2.0438, -2.6340, -2.5010, -1.5704],\n",
            "        [-1.8238, -3.7848, -2.2120, -1.9125, -2.2919, -2.1274, -1.7869, -1.7662],\n",
            "        [-2.2323, -3.9876, -2.3895, -1.5038, -2.3766, -1.7287, -1.7885, -2.0988],\n",
            "        [-1.7416, -4.3440, -2.1313, -1.5197, -2.6143, -2.4512, -2.3772, -1.5047],\n",
            "        [-2.4330, -3.5349, -1.9317, -2.0491, -2.1418, -1.8447, -1.6128, -2.0063],\n",
            "        [-2.0904, -2.1420, -2.2626, -2.0932, -2.2696, -1.8403, -2.3607, -1.7424],\n",
            "        [-1.8540, -2.6755, -1.9179, -2.2548, -2.3430, -2.3829, -2.4403, -1.3973],\n",
            "        [-2.0631, -3.0850, -2.3931, -1.4684, -2.2448, -1.9596, -2.1585, -1.9435],\n",
            "        [-1.9498, -2.3056, -1.8432, -2.3171, -2.3260, -2.4098, -2.8274, -1.3687],\n",
            "        [-1.9741, -3.7270, -1.9940, -1.6948, -2.1224, -2.0611, -2.1342, -1.8847],\n",
            "        [-2.0350, -2.1837, -1.9327, -1.9175, -2.1314, -2.2864, -2.3031, -1.9329],\n",
            "        [-2.2067, -1.3944, -1.8578, -2.6286, -2.3669, -2.5504, -2.6058, -1.7833],\n",
            "        [-2.6117, -2.1540, -1.6303, -2.1060, -1.7798, -2.2500, -2.4363, -2.0293],\n",
            "        [-2.1868, -2.7657, -2.1575, -1.9910, -1.8991, -1.8873, -1.9532, -2.0431],\n",
            "        [-2.1473, -2.8780, -1.7626, -1.6729, -2.1040, -2.3753, -2.5696, -1.7366],\n",
            "        [-1.5801, -3.6302, -2.1863, -1.8050, -2.6367, -2.2945, -2.4939, -1.4451],\n",
            "        [-2.0029, -2.6274, -2.0447, -2.4125, -2.2644, -1.6790, -2.0212, -1.8916],\n",
            "        [-1.6004, -3.6986, -2.0767, -1.9266, -2.7952, -2.0876, -2.5036, -1.4457],\n",
            "        [-1.8850, -4.3411, -2.3892, -1.5599, -2.3870, -1.9251, -1.9686, -1.8587],\n",
            "        [-1.6375, -3.4396, -1.9803, -2.0352, -2.3938, -2.1187, -2.2256, -1.6858],\n",
            "        [-2.3562, -2.9412, -1.7611, -2.0313, -2.1754, -2.3118, -2.4359, -1.3893],\n",
            "        [-1.8825, -3.6449, -1.9603, -1.9899, -2.1731, -2.3049, -2.0052, -1.6301]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([5, 6, 5, 5, 5, 7, 0, 5, 6, 6, 7, 3, 5, 7, 6, 5, 7, 6, 7, 7, 0, 7, 4, 6,\n",
            "        3, 0, 5, 6, 6, 3, 5, 6], device='cuda:0')\n",
            "tensor([[-1.9634, -3.4560, -2.1028, -1.9808, -2.2476, -2.0399, -1.7790, -1.8109],\n",
            "        [-1.7062, -2.6179, -2.0572, -2.5524, -2.1940, -2.3932, -2.1352, -1.5199],\n",
            "        [-1.3937, -3.2589, -2.1605, -2.3250, -2.7452, -2.2885, -2.3233, -1.4407],\n",
            "        [-2.7620, -2.2539, -1.4713, -2.1794, -2.1958, -2.3931, -2.9316, -1.4560],\n",
            "        [-1.6488, -2.5503, -1.8759, -2.5127, -2.3782, -2.3711, -2.5122, -1.4775],\n",
            "        [-2.2147, -2.9869, -2.3700, -2.4438, -2.4173, -1.4330, -1.6279, -1.9953],\n",
            "        [-1.5783, -3.8234, -2.2088, -2.0017, -2.4338, -2.2035, -1.7583, -1.8552],\n",
            "        [-2.7480, -3.0726, -2.1366, -2.4978, -2.5890, -1.3683, -1.3984, -2.1830],\n",
            "        [-2.2156, -3.3602, -2.1970, -2.1748, -2.7326, -1.3680, -1.6245, -2.1650],\n",
            "        [-2.3468, -1.8264, -1.8244, -2.6886, -1.9707, -2.2909, -2.2418, -1.7884],\n",
            "        [-2.0260, -3.9067, -2.0189, -2.1079, -2.5596, -1.9518, -1.8927, -1.4974],\n",
            "        [-1.7439, -3.2163, -2.0002, -2.0506, -2.4170, -2.1106, -2.2341, -1.5913],\n",
            "        [-1.9590, -4.4910, -1.8617, -1.7530, -2.3376, -2.3109, -2.3571, -1.4752],\n",
            "        [-1.9576, -2.1201, -1.8503, -2.7567, -2.3537, -2.4144, -2.4389, -1.4008],\n",
            "        [-1.6224, -3.9869, -2.1022, -2.3205, -2.4164, -1.9485, -2.0638, -1.5851],\n",
            "        [-1.9598, -3.9190, -1.9859, -1.9719, -2.4347, -1.8709, -1.8176, -1.8402],\n",
            "        [-1.7001, -3.7393, -2.2872, -1.8385, -2.4397, -1.9295, -1.8587, -1.9332],\n",
            "        [-1.8051, -3.4452, -2.3946, -2.1125, -2.3960, -1.8100, -1.7840, -1.7791],\n",
            "        [-1.7448, -3.5575, -2.2669, -2.1995, -2.6819, -1.9092, -1.8639, -1.5577],\n",
            "        [-1.9149, -2.3482, -1.9015, -2.8690, -2.4615, -1.8794, -2.0636, -1.6818],\n",
            "        [-1.6810, -3.0369, -2.0115, -2.3813, -2.4312, -2.0881, -2.2598, -1.4989],\n",
            "        [-1.8342, -4.6692, -2.3363, -1.6067, -2.3529, -2.0712, -1.7444, -1.9821],\n",
            "        [-1.5811, -2.5647, -2.2712, -2.9420, -2.5146, -1.8704, -1.9859, -1.6653],\n",
            "        [-1.5736, -3.8619, -2.5804, -1.9564, -2.5448, -1.8493, -1.7913, -1.8841],\n",
            "        [-1.8753, -2.2513, -1.9782, -2.5740, -2.3569, -2.2274, -2.4362, -1.4403],\n",
            "        [-4.2331, -4.5472, -3.7104, -3.0939, -3.8242, -2.1564, -0.4818, -1.8980],\n",
            "        [-1.9323, -3.3146, -2.1282, -1.9459, -2.4449, -2.0746, -2.0149, -1.5547],\n",
            "        [-2.1050, -3.4384, -2.0620, -2.0877, -2.5026, -1.5558, -1.7660, -2.0329],\n",
            "        [-1.9790, -2.7966, -1.8738, -2.4880, -2.1867, -2.5417, -1.6650, -1.6931],\n",
            "        [-2.0683, -4.1548, -2.8791, -1.6643, -2.4042, -1.5739, -1.5337, -2.3118],\n",
            "        [-1.5813, -3.0222, -2.4292, -2.2508, -2.2970, -1.9245, -1.9513, -1.8104],\n",
            "        [-2.3864, -4.6315, -2.3810, -1.7682, -2.6065, -1.5325, -1.4970, -2.1069]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 0, 0, 5, 7, 5, 7, 5, 5, 1, 7, 5, 4, 0, 5, 3, 0, 6, 5, 7, 6, 5, 6, 0,\n",
            "        5, 7, 6, 5, 6, 6, 5, 6], device='cuda:0')\n",
            "tensor([[-1.6249, -3.8578, -2.3438, -2.1035, -2.4974, -1.9256, -1.6604, -1.9256],\n",
            "        [-1.7471, -3.0119, -2.2409, -2.3013, -2.0339, -2.1769, -1.9488, -1.6962],\n",
            "        [-1.7769, -2.1495, -2.0471, -2.4072, -2.4747, -2.2429, -2.3403, -1.5679],\n",
            "        [-1.8118, -2.3243, -2.2428, -2.2762, -2.0378, -2.3222, -2.1479, -1.6883],\n",
            "        [-1.7493, -2.7422, -2.7602, -2.7180, -2.5103, -1.6228, -1.4513, -2.1243],\n",
            "        [-1.6292, -2.9837, -2.1335, -2.5059, -2.4564, -2.0763, -2.0704, -1.5324],\n",
            "        [-1.5346, -3.6441, -2.2531, -1.9852, -2.5846, -2.0553, -2.5180, -1.4619],\n",
            "        [-1.4548, -3.5040, -2.4386, -2.4031, -2.5949, -2.1952, -1.9276, -1.4816],\n",
            "        [-1.6819, -2.3113, -1.9631, -2.4028, -2.4771, -2.4256, -2.4435, -1.4930],\n",
            "        [-1.6063, -4.2130, -2.3510, -2.0317, -2.7239, -1.7149, -1.8851, -1.8279],\n",
            "        [-1.4561, -3.3757, -2.4929, -2.3660, -2.6331, -1.9462, -1.8881, -1.6602],\n",
            "        [-1.3732, -3.4230, -2.5843, -2.0005, -2.5019, -1.8563, -1.9540, -2.0916],\n",
            "        [-1.7793, -1.8623, -2.2416, -2.7359, -2.0995, -2.1649, -2.1068, -1.9249],\n",
            "        [-1.5846, -3.3174, -2.1612, -2.2461, -2.3244, -2.1836, -1.9669, -1.6747],\n",
            "        [-1.8125, -2.9764, -2.0802, -2.0223, -2.3845, -2.2278, -2.4103, -1.4320],\n",
            "        [-1.2933, -4.4339, -2.9667, -1.9423, -2.5605, -2.1161, -1.9604, -1.7130],\n",
            "        [-2.5400, -4.8622, -2.4511, -1.7549, -2.8297, -1.2488, -1.5328, -2.3807],\n",
            "        [-1.7313, -2.7100, -2.1186, -2.2964, -2.3339, -2.4105, -2.4489, -1.3375],\n",
            "        [-1.4521, -2.7950, -2.3668, -2.5301, -2.4437, -2.0547, -2.3329, -1.5169],\n",
            "        [-2.0761, -2.3998, -2.0086, -2.3784, -2.1296, -2.1225, -2.0819, -1.6417],\n",
            "        [-1.6082, -3.3677, -2.0763, -2.5410, -2.4914, -2.2030, -2.2577, -1.3347],\n",
            "        [-2.0630, -2.9077, -2.2963, -2.2165, -2.1809, -1.7741, -1.7538, -1.8771],\n",
            "        [-1.9776, -2.0786, -2.2805, -2.7852, -2.0685, -2.0679, -1.8969, -1.7738],\n",
            "        [-1.9231, -4.1283, -2.5776, -1.3989, -2.2085, -1.9116, -1.8649, -2.2800],\n",
            "        [-1.7979, -1.8586, -1.9376, -2.9350, -2.4133, -2.1610, -2.3146, -1.7274],\n",
            "        [-1.5002, -4.5848, -2.4671, -1.9232, -2.7021, -2.2229, -1.8825, -1.5694],\n",
            "        [-1.3986, -3.9944, -2.5066, -2.0041, -2.6355, -1.9466, -2.0296, -1.7575],\n",
            "        [-1.6259, -4.3613, -2.3414, -1.9395, -2.4496, -2.0579, -1.7649, -1.8002],\n",
            "        [-1.9440, -3.7385, -2.0872, -2.2206, -2.5079, -1.7617, -1.6768, -1.8304],\n",
            "        [-1.9665, -2.5273, -2.1398, -2.2946, -2.2403, -1.8579, -2.2015, -1.6680],\n",
            "        [-1.5674, -5.1446, -2.5629, -1.6545, -2.6772, -1.8567, -1.9123, -1.9335],\n",
            "        [-1.7610, -1.9491, -2.2642, -2.5794, -2.5235, -1.9871, -2.1279, -1.7742]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([0, 5, 2, 3, 6, 0, 3, 7, 3, 5, 6, 3, 4, 2, 3, 6, 5, 6, 5, 5, 7, 6, 5, 3,\n",
            "        6, 6, 2, 7, 0, 7, 0, 2], device='cuda:0')\n",
            "tensor([[-1.6642, -4.5574, -2.5657, -1.7984, -2.7042, -1.7541, -1.6841, -2.0238],\n",
            "        [-1.9444, -5.2699, -2.3195, -1.7378, -2.7972, -1.8093, -1.4894, -2.0612],\n",
            "        [-2.3607, -3.9863, -2.4707, -1.9690, -2.2644, -1.5528, -1.2356, -2.8692],\n",
            "        [-1.9033, -1.9896, -1.9791, -2.9992, -2.3249, -1.9658, -1.8984, -1.9768],\n",
            "        [-2.6789, -3.0389, -2.8504, -2.7092, -3.1082, -1.1456, -1.2011, -2.3486],\n",
            "        [-1.8368, -2.1660, -2.2861, -2.4709, -2.1713, -1.9035, -2.0356, -1.9228],\n",
            "        [-1.8102, -3.8605, -2.2067, -2.1360, -2.7174, -1.5482, -1.8095, -1.9330],\n",
            "        [-1.9818, -2.1720, -2.0476, -2.5635, -1.8443, -2.1416, -2.1493, -1.8972],\n",
            "        [-1.6917, -3.2935, -3.1286, -1.9460, -2.2266, -1.7115, -1.5450, -2.4053],\n",
            "        [-1.3297, -3.5438, -2.4124, -2.5023, -2.7746, -2.0304, -1.9358, -1.6242],\n",
            "        [-1.7752, -3.2475, -2.4202, -2.2226, -2.5016, -1.9482, -1.6575, -1.7184],\n",
            "        [-1.1736, -3.1540, -2.3783, -2.3875, -2.3810, -2.2976, -2.3333, -1.7511],\n",
            "        [-1.4609, -4.9048, -2.5986, -1.7910, -2.9304, -1.8967, -1.7885, -1.9056],\n",
            "        [-1.4727, -3.4606, -2.5727, -1.9505, -2.1408, -2.1316, -1.8175, -2.1028],\n",
            "        [-1.1525, -4.7591, -2.5532, -2.1694, -2.9477, -2.2370, -2.1627, -1.5642],\n",
            "        [-1.2868, -3.6251, -2.5166, -2.5130, -2.7492, -1.8438, -1.8794, -1.8290],\n",
            "        [-2.2586, -1.2144, -1.9651, -2.9180, -2.2432, -2.4683, -2.6403, -1.9503],\n",
            "        [-1.4641, -4.1276, -2.4795, -2.0722, -2.5071, -2.0540, -2.1239, -1.5436],\n",
            "        [-1.8063, -4.1565, -2.4529, -1.7894, -2.5243, -1.8185, -1.5948, -2.1067],\n",
            "        [-2.3583, -4.1342, -2.9195, -1.9436, -2.5302, -1.3482, -1.2565, -2.6847],\n",
            "        [-1.9100, -2.8992, -2.1156, -2.4997, -2.4155, -1.6214, -1.6392, -2.1793],\n",
            "        [-1.4712, -3.0986, -2.0494, -2.7339, -2.8113, -1.9009, -2.1493, -1.5832],\n",
            "        [-1.7701, -3.9113, -2.2657, -1.9909, -1.9781, -1.9002, -1.7429, -2.2399],\n",
            "        [-2.5018, -1.3019, -1.7488, -2.8730, -2.1801, -2.3361, -2.6235, -2.0155],\n",
            "        [-1.7605, -5.0134, -2.5812, -1.5635, -2.4793, -1.9022, -1.7102, -2.1003],\n",
            "        [-1.8580, -2.5104, -2.3434, -2.6736, -2.2490, -1.7168, -1.6428, -2.1270],\n",
            "        [-1.7026, -2.8963, -2.4356, -2.4794, -2.3309, -1.9199, -1.7393, -1.7618],\n",
            "        [-2.6542, -0.8540, -2.2321, -3.6940, -2.4346, -2.1329, -2.3778, -2.6192],\n",
            "        [-1.6994, -3.7437, -2.4949, -2.1161, -2.3881, -1.7554, -1.6340, -2.0344],\n",
            "        [-2.2437, -3.6932, -2.8924, -2.3541, -2.9189, -1.0328, -1.5086, -2.4372],\n",
            "        [-1.7720, -3.3769, -2.0084, -2.1034, -2.5250, -1.9955, -2.6607, -1.3716],\n",
            "        [-1.6970, -3.1646, -2.2956, -2.4928, -2.3313, -1.7064, -1.8551, -1.8576]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 6, 6, 6, 6, 6, 7, 1, 6, 7, 6, 0, 6, 4, 0, 7, 1, 7, 5, 6, 7, 7, 4, 4,\n",
            "        5, 7, 5, 1, 5, 5, 7, 7], device='cuda:0')\n",
            "tensor([[-1.3954, -4.2980, -2.3140, -2.0539, -2.7319, -2.3160, -1.9003, -1.6180],\n",
            "        [-1.7136, -3.8011, -2.6922, -1.6703, -2.3941, -1.8011, -1.6500, -2.3742],\n",
            "        [-1.4213, -3.3646, -2.0682, -2.3023, -2.5972, -2.0411, -1.9733, -1.8694],\n",
            "        [-1.5046, -2.9717, -2.1683, -2.2141, -2.4455, -2.2111, -2.1015, -1.6900],\n",
            "        [-1.6081, -2.9213, -2.6878, -2.4690, -2.3168, -1.5341, -1.7019, -2.3373],\n",
            "        [-2.3436, -3.1099, -2.0735, -2.4641, -2.4300, -1.2793, -1.6791, -2.3457],\n",
            "        [-1.7387, -3.0715, -2.5611, -2.1180, -1.8740, -1.8237, -1.7573, -2.3757],\n",
            "        [-1.6113, -4.7872, -2.4060, -1.8353, -2.5004, -1.9422, -1.6544, -2.0742],\n",
            "        [-1.7809, -2.9498, -2.0351, -2.4401, -2.2577, -1.7199, -1.7982, -2.1885],\n",
            "        [-1.4061, -4.4071, -2.3346, -1.8341, -2.7972, -2.2365, -2.1483, -1.6014],\n",
            "        [-2.0933, -5.6362, -3.0924, -1.5729, -3.1574, -1.4530, -1.2825, -2.7097],\n",
            "        [-1.5599, -3.5449, -2.9056, -2.0555, -2.3209, -1.7652, -1.6483, -2.1496],\n",
            "        [-2.2031, -1.3335, -1.7896, -3.4929, -2.2612, -2.2860, -2.3218, -2.0831],\n",
            "        [-1.8079, -4.3442, -2.5698, -1.7714, -2.2631, -1.8372, -1.6916, -2.0491],\n",
            "        [-1.5470, -4.6369, -2.5324, -2.0127, -2.8312, -1.7568, -1.6164, -2.0085],\n",
            "        [-1.3884, -3.0829, -2.2002, -2.3395, -2.4612, -2.1561, -2.1378, -1.7230],\n",
            "        [-1.4008, -3.8730, -2.8254, -2.0773, -2.6116, -1.8916, -1.6260, -2.0614],\n",
            "        [-1.2756, -3.7849, -2.2524, -2.2762, -3.0576, -1.9510, -2.2257, -1.6447],\n",
            "        [-1.1496, -4.3895, -2.8424, -2.2892, -3.0059, -1.7740, -1.9214, -1.9266],\n",
            "        [-2.6312, -3.4386, -2.8666, -2.3883, -3.0335, -1.0533, -1.3077, -2.5277],\n",
            "        [-2.7597, -2.2416, -1.6168, -2.3393, -2.2248, -1.4772, -2.4652, -2.1705],\n",
            "        [-1.4995, -3.8716, -2.1896, -2.1035, -2.6905, -2.0429, -2.2420, -1.5224],\n",
            "        [-2.2440, -1.5083, -2.0387, -3.3515, -2.0988, -1.9005, -2.0310, -2.2621],\n",
            "        [-1.8242, -2.7593, -2.3399, -2.2549, -2.2514, -1.8979, -1.6565, -2.0545],\n",
            "        [-1.4131, -2.8184, -2.1637, -2.5869, -2.5039, -2.0179, -1.9488, -1.8995],\n",
            "        [-1.7570, -3.6905, -2.4616, -2.3216, -2.4064, -1.6299, -1.5117, -2.1854],\n",
            "        [-1.7768, -3.3090, -2.1743, -2.4947, -2.5735, -1.6440, -1.7359, -1.8816],\n",
            "        [-1.5388, -4.3485, -2.7376, -1.8242, -2.4746, -1.9566, -1.5557, -2.2093],\n",
            "        [-1.5834, -3.3273, -2.4378, -2.1648, -2.1059, -1.9984, -1.8677, -1.9314],\n",
            "        [-1.8022, -2.7418, -1.7684, -2.3467, -2.0024, -2.3811, -2.3382, -1.7127],\n",
            "        [-1.5754, -3.9456, -2.8024, -1.8986, -2.3781, -1.8425, -1.5941, -2.2159],\n",
            "        [-2.3740, -1.3161, -2.5985, -3.0250, -2.0317, -1.8368, -1.7422, -2.9918]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([6, 5, 5, 7, 5, 6, 4, 7, 0, 7, 5, 5, 5, 5, 3, 7, 6, 5, 7, 5, 5, 7, 6, 6,\n",
            "        2, 6, 4, 3, 4, 7, 6, 1], device='cuda:0')\n",
            "tensor([[ -1.5433,  -3.7227,  -2.0472,  -2.2655,  -2.3995,  -2.1062,  -1.9892,\n",
            "          -1.7147],\n",
            "        [ -2.4376,  -3.2955,  -2.7558,  -1.8757,  -1.9529,  -1.4837,  -1.4332,\n",
            "          -2.9651],\n",
            "        [ -1.6594,  -3.5526,  -2.2414,  -1.8117,  -2.1649,  -1.9554,  -2.3089,\n",
            "          -1.8593],\n",
            "        [ -5.7311,  -6.2402,  -5.6567,  -4.1389,  -5.1705,  -3.6624,  -0.1399,\n",
            "          -2.5961],\n",
            "        [ -1.4157,  -4.1185,  -2.7283,  -1.8068,  -2.2196,  -2.0882,  -1.8128,\n",
            "          -2.1566],\n",
            "        [ -2.2065,  -4.1663,  -2.7396,  -1.7734,  -2.4996,  -1.2793,  -1.4933,\n",
            "          -2.8990],\n",
            "        [ -1.4714,  -3.2924,  -2.4901,  -2.3409,  -2.4030,  -1.7966,  -1.8137,\n",
            "          -2.0045],\n",
            "        [-11.3955,  -8.5374, -11.9360, -10.0575, -10.7219,  -7.8030,  -0.0288,\n",
            "          -3.5856],\n",
            "        [ -2.3116,  -3.8122,  -2.6264,  -2.5187,  -2.8205,  -1.0066,  -1.4727,\n",
            "          -2.6370],\n",
            "        [ -1.5275,  -3.8390,  -2.5023,  -1.9445,  -1.9606,  -2.1324,  -1.6752,\n",
            "          -2.4094],\n",
            "        [ -1.4720,  -3.3208,  -2.1958,  -2.1352,  -1.9997,  -2.0297,  -2.2013,\n",
            "          -2.0597],\n",
            "        [ -1.7598,  -4.1088,  -2.7536,  -1.9012,  -2.5080,  -1.5150,  -1.5071,\n",
            "          -2.5821],\n",
            "        [ -1.7184,  -3.3654,  -2.3704,  -2.2605,  -2.0132,  -2.1191,  -1.6213,\n",
            "          -1.9876],\n",
            "        [ -1.9864,  -4.3532,  -2.3960,  -1.9349,  -2.3447,  -1.9550,  -1.2716,\n",
            "          -2.3373],\n",
            "        [ -2.0921,  -4.1378,  -2.7980,  -1.9862,  -2.1828,  -1.4872,  -1.4049,\n",
            "          -2.5469],\n",
            "        [ -1.2084,  -4.5374,  -2.5174,  -2.3234,  -2.7228,  -2.1953,  -1.8355,\n",
            "          -1.7403],\n",
            "        [ -2.1170,  -3.5817,  -2.4819,  -2.0376,  -2.1732,  -1.5373,  -1.5452,\n",
            "          -2.3452],\n",
            "        [ -1.8224,  -2.2599,  -1.9204,  -2.6646,  -2.1256,  -2.0984,  -1.9252,\n",
            "          -2.0404],\n",
            "        [ -1.5012,  -4.4934,  -2.3821,  -1.7972,  -2.6554,  -1.9252,  -1.9882,\n",
            "          -1.8658],\n",
            "        [ -1.3348,  -3.7056,  -2.1405,  -2.3086,  -2.6197,  -2.1705,  -1.8760,\n",
            "          -1.8640],\n",
            "        [ -1.6699,  -3.8178,  -2.1790,  -2.4622,  -2.3344,  -1.9171,  -1.5208,\n",
            "          -2.0486],\n",
            "        [ -1.4939,  -2.3343,  -2.4816,  -3.2501,  -2.2402,  -1.8676,  -1.7994,\n",
            "          -2.0408],\n",
            "        [ -1.4817,  -4.0803,  -2.5307,  -1.9877,  -2.4296,  -1.9945,  -1.6455,\n",
            "          -2.1023],\n",
            "        [ -1.2842,  -3.3542,  -2.4548,  -2.2175,  -2.4875,  -2.1480,  -1.8760,\n",
            "          -1.9635],\n",
            "        [ -1.1781,  -3.8485,  -2.8038,  -2.0878,  -2.4359,  -2.0545,  -1.8179,\n",
            "          -2.2234],\n",
            "        [ -1.5534,  -4.7294,  -2.6608,  -1.5562,  -2.2800,  -2.0479,  -1.8503,\n",
            "          -2.2041],\n",
            "        [ -1.4189,  -4.6084,  -2.4287,  -1.7687,  -2.5743,  -2.0859,  -1.7968,\n",
            "          -2.0946],\n",
            "        [ -1.3153,  -4.0747,  -2.8955,  -1.8046,  -2.4508,  -1.9996,  -2.0604,\n",
            "          -1.9257],\n",
            "        [ -3.4810,  -0.3560,  -3.0990,  -4.2288,  -2.3655,  -3.0285,  -3.1888,\n",
            "          -3.6647],\n",
            "        [ -1.4727,  -3.7767,  -2.2675,  -2.3050,  -2.6369,  -1.9257,  -1.8982,\n",
            "          -1.7301],\n",
            "        [ -1.9027,  -3.3990,  -2.0975,  -1.9091,  -1.9496,  -1.8507,  -2.1787,\n",
            "          -2.0114],\n",
            "        [ -1.5480,  -2.7618,  -1.8644,  -2.3453,  -2.2537,  -2.1744,  -2.3434,\n",
            "          -1.8411]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 7, 3, 6, 3, 3, 7, 1, 5, 4, 6, 6, 7, 7, 6, 7, 6, 3, 7, 2, 0, 5, 5, 6,\n",
            "        7, 3, 6, 3, 1, 5, 7, 7], device='cuda:0')\n",
            "tensor([[-2.1590, -1.5701, -1.8966, -2.6652, -1.8860, -2.2662, -2.4019, -2.1988],\n",
            "        [-1.2861, -4.1741, -2.6021, -1.9815, -2.4092, -2.1284, -2.0298, -1.8579],\n",
            "        [-2.0186, -4.2732, -2.5876, -1.8906, -2.8689, -1.3276, -1.5332, -2.4155],\n",
            "        [-1.5845, -3.0952, -2.6989, -2.5309, -2.5551, -1.4816, -1.6712, -2.2087],\n",
            "        [-1.5543, -3.7631, -2.3208, -1.8915, -2.5659, -1.8153, -1.9644, -1.9912],\n",
            "        [-1.9888, -3.3699, -2.3310, -2.5480, -2.4091, -1.2706, -1.7775, -2.1742],\n",
            "        [-1.4692, -3.5811, -1.9692, -2.3534, -2.1134, -2.2403, -2.2035, -1.7734],\n",
            "        [-1.5144, -4.7392, -2.8937, -1.6311, -2.7700, -1.6171, -1.8040, -2.3596],\n",
            "        [-2.0424, -4.9014, -2.3902, -1.6347, -2.1164, -1.8001, -1.5345, -2.5913],\n",
            "        [-1.9579, -2.9693, -2.1820, -2.5173, -2.7046, -1.2688, -1.7504, -2.3832],\n",
            "        [-5.1729, -4.4619, -4.5895, -3.9289, -4.8621, -2.3987, -0.2645, -2.4441],\n",
            "        [-1.2262, -4.4652, -2.7230, -2.0669, -2.5303, -1.9235, -1.7687, -2.2392],\n",
            "        [-1.5315, -4.1328, -2.5153, -2.2635, -2.5308, -1.5932, -1.7195, -2.1127],\n",
            "        [-1.8104, -3.6057, -2.6862, -2.0526, -2.5336, -1.4433, -1.5487, -2.4689],\n",
            "        [-1.9564, -2.9233, -2.2322, -2.5865, -2.2606, -1.7048, -1.5444, -2.0974],\n",
            "        [-1.3934, -2.3551, -2.6865, -2.4694, -2.2177, -1.9827, -1.8633, -2.2787],\n",
            "        [-1.6590, -3.4801, -2.2990, -2.1775, -2.2046, -2.1273, -1.8316, -1.7397]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([7, 7, 5, 7, 7, 5, 7, 0, 2, 5, 5, 0, 7, 3, 6, 7, 3], device='cuda:0')\n",
            "\n",
            "Evaluating...\n",
            "tensor(1.9075, device='cuda:0')\n",
            "tensor(1.7906, device='cuda:0')\n",
            "\n",
            "Training Loss: 1.909\n",
            "Validation Loss: 1.849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yrhUc9kTI5a"
      },
      "source": [
        "# Load Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OacxUyizS8d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0e7930-eec1-4ebf-9607-666f7a37b5ac"
      },
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4SVftkkTZXA"
      },
      "source": [
        "# Get Predictions for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZl0SZmFTRQA"
      },
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms1ObHZxTYSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bb23a6a-5988-4538-cfa9-7d1aeab77722"
      },
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.07      0.50      0.12         4\n",
            "           1       0.29      1.00      0.44         2\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.00      0.00      0.00         5\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.20      0.08      0.11        13\n",
            "           6       0.36      0.27      0.31        15\n",
            "           7       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.15        59\n",
            "   macro avg       0.11      0.23      0.12        59\n",
            "weighted avg       0.15      0.15      0.13        59\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqzLS7rHTp4T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "f34585e7-5060-4497-93bb-00280bc4da69"
      },
      "source": [
        "# confusion matrix\n",
        "pd.crosstab(test_y, preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0   0  1  3  4  5  6\n",
              "row_0                   \n",
              "0       2  1  0  0  0  1\n",
              "1       0  2  0  0  0  0\n",
              "2       1  0  0  1  0  0\n",
              "3       3  1  0  1  0  0\n",
              "4       1  1  0  0  1  0\n",
              "5       5  0  1  1  1  5\n",
              "6       5  1  1  2  2  4\n",
              "7      12  1  0  0  1  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpX1uTwjUPY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fc55c18-3db9-473c-e5a4-7b9e00608c68"
      },
      "source": [
        "!pip install pyirr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyirr\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/fd/b7bd6f7c4034e2b2821039c486ca592fe5e1db04bab104dfa3fac9e3183f/pyirr-0.84.1.1.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyirr) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyirr) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pyirr) (1.1.5)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyirr) (0.10.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pyirr) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pyirr) (2.8.1)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyirr) (0.5.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pyirr) (1.15.0)\n",
            "Building wheels for collected packages: pyirr\n",
            "  Building wheel for pyirr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyirr: filename=pyirr-0.84.1.1-cp37-none-any.whl size=23161 sha256=cbdbe862556f9a0462f166c8b587642c8798e66f89a61f692951d0aeb693e50e\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/fc/a6/f966d32825fcc5cb68c04c4f7fe0f57a6040004538b5651d13\n",
            "Successfully built pyirr\n",
            "Installing collected packages: pyirr\n",
            "Successfully installed pyirr-0.84.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYV5v7E-7iPK",
        "outputId": "c40bdfd8-3c8f-47da-e69b-56f3f112b28c"
      },
      "source": [
        "from pyirr import read_data, intraclass_correlation\n",
        "\n",
        "data = [[0,1,2],[0,1,2]]\n",
        "#data = read_data(\"anxiety\")  # loads example data\n",
        "intraclass_correlation(data, \"twoway\", \"agreement\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyirr/intraclass_correlation.py:110: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  Fvalue = MSr / (a * MSc + b * MSe)\n",
            "/usr/local/lib/python3.7/dist-packages/pyirr/intraclass_correlation.py:113: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  v = (a * MSc + b * MSe)**2 / ((a * MSc)**2 / (nr - 1) + (b * MSe)**2 / ((ns - 1) * (nr - 1)))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==================================================\n",
              "          Intraclass Correlation Results          \n",
              "==================================================\n",
              "Model: twoway\n",
              "Type: agreement\n",
              "\n",
              "Subjects = 2\n",
              "Raters = 3\n",
              "ICC(A,1) = 0.00\n",
              "\n",
              "F-Test, H0: r0 = 0 ; H1 : r0 > 0\n",
              "F(1.00,nan) = nan, p = nan\n",
              "\n",
              "95%-Confidence Interval for ICC Population Values:\n",
              "nan < ICC < nan\n",
              "=================================================="
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB5NxgX88M2G",
        "outputId": "b295f2d7-5de3-4f8b-8c87-d3b0c74f8b0b"
      },
      "source": [
        "import sklearn\n",
        "y1 = [2, 2, 3, 7, 5, 5, 3, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 6, 6, 6, 6, 3, 3, 6, 6, 6, 6, 6, 6, 2, 2, 6, 6, 6, 3, 3, 2, 5, 6, 6, 6, 6, 7, 7, 7, 7, 1, 1, 1, 2, 6, 6, 6, 3, 6, 7, 7, 7, 3, 3, 4, 3, 6, 6, 6, 6, 6, 3, 6, 6, 3, 3, 3, 3, 3, 7, 4, 7, 7, 7, 7, 8, 8, 8, 8, 8, 7, 7, 1, 1, 1, 3, 3, 3, 3, 2, 2, 2, 3, 2, 2, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 6, 6, 6, 2, 3, 6, 6, 6, 6, 6, 7, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 7, 7, 7, 7, 7, 3, 3, 8, 8, 8, 7, 7, 7, 7, 3, 3, 7, 7, 6, 3, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 3, 7, 3, 7, 7, 7, 7, 6, 7, 7, 2, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 2, 2, 2, 2, 2, 2, 4, 3, 4, 3, 3, 3, 6, 6, 7, 7, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 1, 1, 7, 7, 7, 7, 7, 7, 7, 7, 3, 3, 2, 8, 7, 7, 7, 6, 6, 6, 6, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 8, 7, 7, 7, 7, 7, 2, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 2, 4, 4, 4, 4, 4, 4, 7, 8, 6, 6, 6, 6, 6, 6, 6, 3, 3, 8, 8, 7, 8, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 8, 7, 7, 7, 6, 6, 6, 6, 7, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 8, 8, 8, 8, 2, 7, 8, 8, 8, 1, 1, 1, 2, 6, 6, 6, 6, 6, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 3, 3, 3, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 3, 2, 5, 5, 2, 8, 2, 7, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 2, 6, 6, 6, 6, 6, 6, 7, 7, 3, 5, 7, 7, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 7, 5, 5, 5, 5, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 7, 7, 1, 1, 1, 3, 5, 7, 7, 8, 2, 6, 7, 7, 6, 6, 6, 6, 6, 6, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 5, 3, 6, 3, 7, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 7, 8, 8, 1, 1, 1, 7, 7, 7, 8, 2, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 8, 8, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 2, 2, 2, 2, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 6, 6, 6, 5, 3, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 8, 3, 8, 8, 8, 2, 2, 2, 3, 2, 5, 5, 7, 3, 3, 3, 3, 3, 3, 3, 3, 3, 7, 1, 1, 1, 3, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 3, 6, 2, 3, 3, 6, 6, 6, 6, 3, 3, 3, 8, 8, 8, 3, 3, 8, 2, 2, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 6, 6, 6, 6, 6, 3, 6, 2, 2, 5, 6, 6, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 2, 2, 6, 3, 5, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 7, 7, 7, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 6, 6, 7, 7, 7, 7, 3, 3, 3, 7, 3, 3, 3, 7, 7, 7, 7, 7, 8]\n",
        "y2 = [2, 2, 3, 7, 5, 5, 3, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 6, 6, 6, 6, 3, 3, 6, 6, 6, 6, 6, 6, 2, 2, 6, 6, 6, 3, 3, 2, 5, 6, 6, 6, 6, 7, 7, 7, 7, 1, 1, 1, 2, 6, 6, 6, 3, 6, 7, 7, 7, 3, 3, 4, 3, 6, 6, 6, 6, 6, 3, 6, 6, 3, 3, 3, 3, 3, 7, 4, 7, 7, 7, 7, 8, 8, 8, 8, 8, 7, 7, 1, 1, 1, 3, 3, 3, 3, 2, 2, 2, 3, 2, 2, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 6, 6, 6, 2, 3, 6, 6, 6, 6, 6, 7, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 7, 7, 7, 7, 7, 3, 3, 8, 8, 8, 7, 7, 7, 7, 3, 3, 3, 7, 7, 7, 7, 7, 7, 6, 2, 2, 2, 2, 2, 2, 2, 8, 7, 3, 7, 7, 7, 6, 6, 7, 7, 8, 8, 7, 7, 8, 8, 7, 7, 7, 7, 8, 1, 1, 1, 2, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4, 4, 4, 6, 6, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 3, 7, 1, 1, 7, 7, 7, 7, 7, 7, 7, 7, 3, 3, 3, 3, 3, 3, 8, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 5, 5, 7, 7, 7, 7, 7, 7, 1, 1, 1, 2, 4, 4, 4, 4, 4, 4, 7, 2, 5, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8, 7, 5, 7, 7, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 5, 5, 5, 5, 3, 7, 7, 7, 7, 8, 3, 7, 7, 7, 7, 5, 5, 5, 6, 8, 8, 7, 7, 8, 8, 8, 7, 1, 1, 1, 5, 5, 5, 6, 6, 6, 6, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 3, 3, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 6, 5, 5, 5, 5, 5, 5, 7, 6, 7, 7, 7, 3, 6, 7, 6, 7, 7, 7, 8, 8, 7, 7, 7, 7, 7, 2, 2, 4, 4, 4, 7, 8, 8, 5, 6, 6, 5, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 7, 7, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 7, 6, 6, 6, 6, 6, 6, 6, 7, 3, 5, 7, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 7, 5, 5, 5, 5, 5, 6, 6, 6, 6, 3, 3, 6, 6, 6, 6, 6, 6, 7, 6, 6, 3, 7, 7, 7, 7, 7, 2, 8, 7, 5, 5, 5, 5, 5, 5, 5, 7, 7, 1, 1, 1, 3, 7, 7, 7, 8, 3, 7, 7, 7, 3, 7, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 6, 6, 7, 3, 3, 6, 6, 6, 3, 7, 7, 3, 4, 7, 7, 6, 6, 6, 6, 6, 6, 7, 7, 6, 6, 6, 6, 6, 6, 8, 8, 3, 3, 8, 1, 1, 1, 7, 7, 4, 8, 6, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 2, 2, 7, 7, 3, 3, 6, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 3, 3, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 8, 2, 2, 4, 4, 3, 6, 6, 6, 3, 3, 3, 7, 8, 7, 7, 7, 7, 7, 1, 1, 1, 2, 3, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 7, 7, 7, 7, 8, 8, 3, 3, 7, 7, 5, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 3, 3, 3, 7, 7, 7, 3, 7, 7, 5, 5, 5, 7, 7, 5, 5, 5, 5, 1, 1, 1, 1, 1, 2, 2, 2, 3, 5, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 7, 7, 7, 7, 7, 7, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 3, 3, 8, 7, 2, 5, 5, 5, 5, 7, 7, 5, 5, 5, 6, 6, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 2, 2, 7, 7, 8, 7, 7, 7, 3, 3, 3, 3, 3, 3, 3, 8, 8, 8, 8, 8, 8]\n",
        "sklearn.metrics.cohen_kappa_score(y1,y2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5345664312637979"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    }
  ]
}